



# 设计系统考虑哪几个方面

1.数据量

2.并发量

3.时效性

4.容灾性

5.备份数据

6.安全数据加密

7.主键选取

8.成熟的代码框架选取：工作流若依、统一返回码、工具类：糊涂工具包

9.快速开发迭代：糊涂工具包、mybatis-plus

主键选取：返回码/数据库主键/工作流/

# 一、高可用 

### 前言

高可用（High availability，即 HA）的主要目的是为了保障「业务的连续性」，即在用户眼里，业务永远是正常（或者说基本正常）对外提供服务的。高可用主要是针对架构而言，那么要做好高可用，就要首先设计好架构，第一步我们一般会采用分层的思想将一个庞大的 IT 系统拆分成为应用层，中间件，数据存储层等独立的层，每一层再拆分成为更细粒度的组件，第二步就是让每个组件对外提供服务，毕竟每个组件都不是孤立存在的，都需要互相协作，对外提供服务才有意义。

要保证架构的高可用，就要保证架构中所有组件以及其对外暴露服务都要做高可用设计，任何一个组件或其服务没做高可用，都意味着系统存在风险。

那么这么多组件该怎么做高可用设计呢，其实任何组件要做高可用，都离不开「冗余」和「自动故障转移」，众所周知单点是高可用的大敌，所以组件一般是以集群（至少两台机器）的形式存在的，这样只要某台机器出现问题，集群中的其他机器就可以随时顶替，这就是「冗余」。简单计算一下，假设一台机器的可用性为 90%，则两台机器组成的集群可用性为 1-0.1*0.1 = 99%，所以显然冗余的机器越多，可用性越高。

但光有冗余还不够，如果机器出现问题，需要人工切换的话也是费时费力，而且容易出错，所以我们还需要借助第三方工具（即仲裁者）的力量来实现「自动」的故障转移，以达到实现**近实时**的故障转移的目的，**近实时的故障转移才是高可用的主要意义**

怎样的系统可以称之为高可用呢，业界一般用几个九来衡量系统的可用性，如下

| 可用性级别 | 系统可用性% | 宕机时间/年 | 宕机时间/月 | 宕机时间/周 | 宕机时间/天 |
| ---------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| 不可用     | 90%         | 36.5 天     | 73 小时     | 16.8 小时   | 144 分钟    |
| 基本可用   | 99%         | 87.6 小时   | 7.3 小时    | 1.68 小时   | 14.4 分钟   |
| 较高可用   | 99.9%       | 8.76 小时   | 43.8 分钟   | 10.1 分钟   | 1.44 分钟   |
| 高可用     | 99.99%      | 52.56 分钟  | 4.38 分钟   | 1.01 秒     | 8.64 秒     |
| 极高可用   | 99.999%     | 5.26 分钟   | 26.28 秒    | 6.06 秒     | 0.86 秒     |

一般实现两个 9 很简单，毕竟每天宕机 14 分钟已经严重影响业务了，这样的公司迟早歇菜，大厂一般要求 4 个 9，其他要求严苛的业务要达到五个九以上，比如如果因为一个电脑的故障导致所有列车停驶，那么就会有数以万计的人正常生活受到阻碍，这种情况就要求五个九以上

接下来我们就来一起看看架构中的各个组件如何借助「冗余」和「自动故障转移」来实现高可用。

### 互联网架构剖析

目前多数互联网都会采用微服务架构，常见架构如下:

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFF2y5qicTib6bSVPvebnjeAzMMqAWTWB2r5Bx5Vwz2THY50RIic1nBMmgQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

可以看到架构主要分以下几层

1. 接入层：主要由 F5 硬件或 LVS 软件来承载所有的流量入口
2. 反向代理层：Nginx，主要负责根据 url 来分发流量，限流等
3. 网关：主要负责流控，风控，协议转换等
4. 站点层：主要负责调用会员，促销等基本服务来装配 json 等数据并返回给客户端
5. 基础 service：其实与站点层都属于微服务，是平级关系，只不过基础 service 属于基础设施，能被上层的各个业务层 server 调用而已
6. 存储层：也就是 DB，如 MySQL，Oracle 等，一般由基础 service 调用返回给站点层
7. 中间件：ZK，ES，Redis，MQ 等，主要起到加速访问数据等功能，在下文中我们会简单介绍下各个组件的作用

如前所述，要实现整体架构的高可用，必须要实现每一层组件的高可用，接下来我们就来分别看一下每一层的组件都是如何实现高可用的

### 接入层&反向代理层

这两层的高可用都和 keepalived 有关，所以我们结合起来一起看

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFVgylNIdGrhDkSF8FibpNr6eoUGjEibuCFm4bmcz5ibszdZ6XefKTwG9LA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

对外，两个 LVS 以主备的形式对外提供服务，注意只有 master 在工作（即此时的 VIP 在 master 上生效），另外一个 backup 在 master 宕机之后会接管 master 的工作，那么 backup 怎么知道 master 是否正常呢，答案是通过 keepalived，在主备机器上都装上 keepalived 软件，启动后就会通过心跳检测彼此的健康状况，一旦 master 宕机，keepalived 会检测到，从而 backup 自动转成 master 对外提供服务，此时 VIP 地址（即图中的 115.204.94.139）即在 backup 上生效，也就是我们常说的「IP漂移」，通过这样的方式即解决了 LVS 的高可用。

keepalived 的心跳检测主要通过发送 ICMP 报文，或者利用 TCP 的端口连接和扫描检测来检测的，同样的，它也可以用来检测 Nginx 暴露的端口，这样的话如果某些 Nginx 不正常 Keepalived 也能检测到并将其从 LVS 能转发的服务列表中剔出。

借用 keepalived 这个第三方工具，同时实现了 LVS 和 Nginx 的高可用，同时在出现故障时也可以将宕机情况发送到对应开发人员的邮箱以让他们及时收到通知处理，确实很方便，Keepalived 应用广泛，下文我们会看到它也可以用在 MySQL 上来实现 MySQL 的高可用。

### 微服务

接下来我们再来看一下「网关」，「站点层」,「基础服务层」，这三者一般就是我们所说的微服务架构组件，当然这些微服务组件还需要通过一些 RPC 框架如 Dubbo 来支撑才能通信，所以微服务要实现高可用，就意味着 dubbo 这些 RPC 框架也要提供支撑微服务高可用的能力，我们就以 dubbo 为例来看下它是如何实现高可用的

我们先来简单地看下 dubbo 的基本架构

![图片](https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFvmiaryD4ebUrFo6Be22J24afz1w72oyUlyOemjYH7ZBccsV5RpcyCMQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

思路也很简单，首先是 Provider（服务提供者）向 Registry（注册中心，如 ZK 或 Nacos 等）注册服务，然后 Consumer（服务消费者）向注册中心订阅和拉取 Provider 服务列表，获取服务列表后，Consumer 就可以根据其负载均衡策略选择其中一个  Provider 来向其发出请求，当其中某个 Provider 不可用（下线或者因为 GC 阻塞等）时，会被注册中心及时监听（通过心跳机制）到，也会及时推送给 Consumer，这样 Consumer 就能将其从可用的 Provider 列表中剔除，也就实现了故障的自动转移，不难看出，注册中心就起到了类似 keepalived 的作用

### 中间件

我们再来看下这些中间件如 ZK，Redis 等是如何实现高可用的呢

#### ZK

上一节微服务中我们提到了注册中心，那我们就以 ZK（ZooKeeper）为例来看看它的高可用是如何实现的，先来看下它的整体架构图如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGF48MtucWD8DPMCz0mfjqytSlSvljubib3ia1xIR6La51orJIssR1ISmZA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Zookeeper 中的主要角色如下

- Leader: 即领导者，在集群中只有一个 Leader，主要承担了以下的功能

1. 事务请求的唯一调度和处理者，保证集群事务处理的顺序性，所有 Follower 的写请求都会转给 Leader 执行，用来保证事务的一致性
2. 集群内部各服务器的调度者：处理好事务请求后，会将数据广播同步到各个 Follower，统计 Follower 写入成功的数量，超过半数 Follower 写入成功，Leader 就会认为写请求提交成功，通知所有的 Follower commit 这个写操作，保证事后哪怕是集群崩溃恢复或者重启，这个写操作也不会丢失。

- Follower:

1. 处理客户端非事务请求、转发事务请求给 leader 服务器
2. 参与事物请求 Proposal 的投票（需要半数以上服务器通过才能通知 leader commit 数据; Leader 发起的提案，要求 Follower 投票）
3. 参与 Leader 选举的投票

**画外音**：Zookeeper 3.0 之后新增了一种 Observer 的角色，不过与此处讨论的 ZK 高可用关系不是很大，为了简化问题，所以省略

可以看到由于只有一个 Leader，很显然，此 Leader 存在单点隐患，那么 ZK 是怎么解决此问题的呢，首先 Follower 与 Leader 会用心跳机制保持连接，如果 Leader 出现问题了（宕机或者因为 FullGC 等原因无法响应），Follower 就无法感知到 Leader 的心跳，就会认为 Leader 出问题了，于是它们就会发起投票选举，最终在多个 Follower 中选出一个 Leader 来（这里主要用到了 Zookeeper Atomic Broadcast，即 ZAB 协议，它是为 ZK 专门设计的一种支持崩溃恢复的一致性协议），选举的细节不是本文重点，就不在此详述了。

除了 ZAB 协议，业界上常用的还有 Paxos，Raft 等协议算法，也可以用在 Leader 选举上，也就是是在分布式架构中，这些协议算法承担了“第三者”也就是仲裁者的作用，以承担故障的自动转移

#### Redis

Redis 的高可用需要根据它的部署模式来看看，主要分为「主从模式」和「Cluster 分片模式」两种

##### 主从模式

先来看一下主从模式，架构如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFFWlG0mOU7CGJ7PocwSNywKzyqLicoR0dPFSGYSZxeyqpyz4vBib9j39g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)主从模式

主从模式即一主多从（一个或者多个从节点），其中主节点主要负责读和写，然后会将数据同步到多个从节点上，Client 也可以对多个从节点发起读请求，这样可以减轻主节点的压力，但和 ZK 一样，由于只有一个主节点，存在单点隐患，所以必须引入第三方仲裁者的机制来判定主节点是否宕机以及在判定主节点宕机后快速选出某个从节点来充当主节点的角色，这个第三方仲裁者在 Redis 中我们一般称其为「哨兵」（sentinel），当然哨兵进程本身也有可能挂掉，所以为了安全起见，需要部署多个哨兵（即哨兵集群）

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFjCMq4hjcVibRr7ODrhBwMJG1wfAJOaO3F5VGpJ9GyEAgTWhM1yPyEAg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)哨兵集群

这些哨兵通过 gossip（流言） 协议来接收关于主服务器是否下线的信息，并在判定主节点宕机后使用 Raft 协议来选举出新的主节点

##### Cluster 分片集群

主从模式看似完美，但存在以下几个问题

1. 主节点写的压力难以降低：因为只有一个主节点能接收写请求，如果在高并发的情况下，写请求如果很高的话可能会把主节点的网卡打满，造成主节点对外无法服务
2. 主节点的存储能力受到单机存储容量的限制：因为不管是主节点还是从节点，存储的都是**全量**缓存数据，那么随着业务量的增长，缓存数据很可能直线上升，直到达到存储瓶颈
3. 同步风暴：因为数据都是从 master 同步到 slave 的，如果有多个从节点的话，master 节点的压力会很大

为了解决主从模式的以上问题，分片集群应运而生，所谓分片集群即将数据分片，每一个分片数据由相应的主节点负责读写，这样的话就有多个主节点来分担写的压力，并且每个节点只存储**部分数据**，也就解决了单机存储瓶颈的问题，但需要注意的是每个主节点都存在单点问题，所以需要针对每个主节点做高可用，整体架构如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGF14icPLDKtw0iagY9sFicsZrFDibZESUInZXgbAq2J6iaaAtF7z6EEWiaoIOg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

原理也很简单，在 Proxy 收到 client 执行的 redis 的读写命令后，首先会对 key 进行计算得出一个值，如果这个值落在相应 master 负责的数值范围（一般将每个数字称为槽，Redis 一共有 16384 个槽）之内，那就把这条 redis 命令发给对应的 master 去执行，可以看到每个 master 节点只负责处理一部分的 redis 数据，同时为了避免每个 master 的单点问题，也为其配备了多个从节点以组成集群，当主节点宕机时，集群会通过 Raft 算法来从从节点中选举出一个主节点

#### ES

再来看一下 ES 是如何实现高可用的，在 ES 中，数据是以分片（Shard）的形式存在的，如下图所示，一个节点中索引数据共分为三个分片存储

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFicqfXTgHCVicUOE5iaLX0J1ogI140QfpkaQGCRAW6U52VNXeq3gj4DPtQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

但只有一个节点的话，显然存在和 Redis 的主从架构一样的单点问题，这个节点挂了，ES 也就挂了，所以显然需要创建多个节点

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFYLmibg8rMgib2wCwcTicmiaoElKcI3ZnR5UrkHTxaOAFAjg4OAmfQ7h20g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

一旦创建了多个节点，分片（图中 P 为主分片，R 为副本分片）的优势就体现出来了，可以将分片数据分布式存储到其它节点上，极大提升了数据的水平扩展能力，同时每个节点都能承担读写请求，采用负载均衡的形式避免了单点的读写压力

> ES 的写机制与 Redis 和 MySQL 的主从架构有些差别（后两者的写都是直接向 master 节点发起写请求，而 ES 则不是），所以这里稍微解释一下 ES 的工作原理
>
> 
>
> 首先说下节点的工作机制，节点（Node）分为主节点（Master Node）和从结点（Slave Node），主节点的主要职责是负责集群层面的相关操作，管理集群变更，如创建或删除索引，跟踪哪些节点是集群的一部分，并决定哪些分片分配给相关的节点，主节点也只有一个，一般通过类 Bully 算法来选举出来，如果主节点不可用了，则其他从节点也可以通过此算法来选举以实现集群的高可用，任何节点都可以接收读写请求以达到负载均衡的目的
>
> 
>
> 再说一下分片的工作原理，分片分为主分片（Primary Shard，即图中 P0，P1，P2）和副本分片（Replica Shard，即图中 R0，R1，R2），主分片负责数据的写操作，所以虽然任何节点可以接收读写请求，但如果此节点接收的是写请求并且没有写数据所在的主分片话，此节点会将写请求调度到主分片所在的节点上，写入主分片后，主分片再把数据复制到其他节点的副本分片上，以有两个副本的集群为例，写操作如下
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGF693SL8F4eVU8zOQjwcndJIKL38DBIp1ThXwpnDZjSicvibq8N8N0zEcQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### MQ

ES 利用数据分片来提升高可用和水平扩展能力的思想也应用在其他组件的架构设计上，我们以 MQ 中的 Kafka 为例再来看下数据分片的应用

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGF5QticRNDibRbvK5yY68X5bXiaUKboEibtbFBfVHhPBoUXg5K3B17WXkGyw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)Kafka 高可用设计，图片来自《武哥漫谈IT》

如上是 Kafka 集群，可以看到每个 Topic 的 Partition 都分布式存储在其它消息服务器上，这样一旦某个 Partition 不可用，可以从 follower 中选举出 leader 继续服务，不过与 ES 中的数据分片不同的是，follower Partition 属于**冷备**，也就是说在正常情况下不会对外服务，只有在 leader 挂掉之后从 follower 中选举出 leader 后它才能对外提供服务

### 存储层

接下来我们再来看一下最后一层，存储层（DB），这里我们以 MySQL 为例来简单地讨论一下其高可用设计，其实大家如果看完了以上的高可用设计，会发现 MySQL 的高可用也不过如此，思想都是类似的，与 Redis 类似，它也分主从和分片（即我们常说的分库分表）两种架构

主从的话与 LVS 类似，一般使用 keepalived 的形式来实现高可用，如下所示

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFgHR6pzBAx1fEzzgiaaax5JBlcWFXOz4uiaNBBBGlX2YYzGngfYOCpKBg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如果 master 宕机了，Keepalived 也会及时发现，于是从库会升级主库，并且 VIP 也会“漂移”到原从库上生效，所以说大家在工程配置的 MySQL 地址一般是 VIP 以保证高可用

数据量大了之后就要分库分表了，于是就有了多主，就像 Redis 的分片集群一样，需要针对每个主配备多个从，如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFmmhvFuzrI226JU1zyEKGwOdvecu8iaLXLVw2Cko1p5ppByw4Hd8k8tw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

之前有读者问分库分表之后为啥还要做主从，现在我想大家应该都明白了，不是为了解决读写性能问题，主要是为了实现高可用

### 总结

看完了架构层面的高可用设计，相信大家对高可用的核心思想「冗余」和「自动故障转移」会有更深刻的体会，观察以上架构中的组件你会发现冗余的主要原因是因为只有一主，为什么不能有多主呢，也不是不可以，但这样在分布式系统下要保证数据的一致性是非常困难的，尤其是节点多了的话，数据之间的同步更是一大难题，所以多数组件采用一主的形式，然后再在主和多从之间同步，多数组件之所以选择一主本质上是技术上的 tradeoff

那么做好每个组件的高可用之后是否整个架构就真的可用了呢，非也，这只能说迈出了第一步，在生产上还有很多突发情况会让我们的系统面临挑战，比如

1. 瞬时流量问题：比如我们可能会面临秒杀带来的瞬时流量激增导致系统的承载能力被压垮，这种情况可能影响日常交易等核心链路，所以需要做到系统之间的隔离，如单独为秒杀部署一套独立的集群
2. 安全问题：比如 DDOS 攻击，爬虫频繁请求甚至删库跑路等导致系统拒绝服务
3. 代码问题：比如代码 bug 引起内存泄露导致 FullGC 导致系统无法响应等
4. 部署问题：在发布过程中如果贸然中止当前正在运行的服务也是不行的，需要做到优雅停机，平滑发布
5. 第三方问题：比如我们之前的服务依赖第三方系统，第三方可能出问题导致影响我们的核心业务
6. 不可抗力：如机房断电，所以需要做好容灾，异地多活，之前我司业务就由于机房故障导致服务四小时不可用，损失惨重

所以除了做好架构的高可用之外，我们还需要在做好系统隔离，限流，熔断，风控，降级，对关键操作限制操作人权限等措施以保证系统的可用。

这里特别提一下降级，这是为了保证系统可用性采取的常用的措施，简单举几个例子

1. 我们之前对接过一个第三方资金方由于自身原因借款功能出了问题导致无法借款，这种情况为了避免引起用户恐慌，于是我们在用户申请第三方借款的时候返回了一个类似「为了提升你的额度，资金方正在系统升级」这样的文案，避免了客诉
2. 在流媒体领域，当用户观看直播出现严重卡顿时，很多企业的第一选择不是查 log 排查问题，而是为用户自动降码率。因为比起画质降低，卡得看不了显然会让用户更痛苦
3. 双十一零点高峰期，我们把用户的注册登录等非核心功能给停掉了，以保证下单等核心流程的顺利

另外我们最好能做到事前防御，在系统出问题前把它扼杀在摇篮里，所以我们需要做单元测试，做全链路压测等来发现问题，还需要针对 CPU，线程数等做好**监控**，当其达到我们设定的域值时就触发告警以让我们及时发现修复问题（我司之前就碰到过一个类似的[生产事故复盘](https://mp.weixin.qq.com/s?__biz=MzI5MTU1MzM3MQ==&mid=2247483844&idx=1&sn=549aabbf5ba5e5f03a634411c630a6da&scene=21#wechat_redirect)大家可以看一下），此外在做好单元测试的前提下，依然有可能因为代码的潜在 bug 引起线上问题，所以我们需要在关键时间（比如双十一期间）封网（也就是不让发布代码）

此外我们还需要在出事后能快速定位问题，快速回滚，这就需要记录每一次的发布时间，发布人等，这里的发布不仅包括工程的发布，还包括配置中心等的发布

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGFDZduepG2dgaBNDNkI7HVfXQ2l4WMzgHtc2Wiasgm0SHiaLdPZKWbZ4ew/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**画外音**：上图是我司的发布记录，可以看到有代码变更，回滚等，这样如果发现有问题的话可以一键回滚

最后我们以一张图来总结一下高可用的常见手段

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWiadZz9DR96fy1xdNgWkIGF6n4vJibqCjicK5G405dyccnUoPVfU14fp7TtyfiaYbW89nEumuWJkAW7g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# 二、Token设置

## JWT介绍

### JWT概念

JWT ， 全写JSON Web Token, 是开放的行业标准RFC7591，用来实现端到端安全验证.

简单来说， 就是通过一些算法对加密字符串和JSON对象之间进行加解密。

JWT加密JSON，保存在客户端，不需要在服务端保存会话信息，可以应用在前后端分离的用户验证上，后端对前端输入的用户信息进行加密产生一个令牌字符串， 前端再次请求时附加此字符串，后端再使用算法解密。

## JWT流程：

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/VrAGWevWkSTxL3zwEKEOHe8pN7RbWVD1toyLJBaQOQIr78nW8BE3ouib1Cz0zz7wQmUiaYO6u9m8LXYIlWjpoU1A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### JWT的构成

JWT字符串：一段加密的JSON字符串。

包含了三类信息

- Header头部：Token类型和加密算法。加密算法常见的有MD5、SHA、HMAC（ Hash Message Authentication Code）。
- PayLoad负载：存放有效信息，包括

标准的声明，类似开发语言总的关键字。包括

```
iss（Issuser） - 签发者
sub Subject 面向主体
aud Audience 接收方
exp Expiration time 过期时间戳
nbf Not Before, 开始生效时间戳
iat(Issued at) 签发时间
jti(JWT ID)： 唯一标识
```

公共的声明：一般添加业务相关的必要信息，因为可解密，不建议敏感信息。

[私有的声明：提供者和消费者共同定义的声明，Base64对称解密，不建议敏感信息](http://mp.weixin.qq.com/s?__biz=MzA3MjMwMzg2Nw==&mid=2247501926&idx=1&sn=bfae8f0369187e45f6b78ee7fe341c06&chksm=9f22ddf2a85554e4b512353067976913167415dca2b12f6b311f1bdaa09a348b2dd6b1af54ea&scene=21#wechat_redirect)

[Signature签证](http://mp.weixin.qq.com/s?__biz=MzA3MjMwMzg2Nw==&mid=2247501926&idx=1&sn=bfae8f0369187e45f6b78ee7fe341c06&chksm=9f22ddf2a85554e4b512353067976913167415dca2b12f6b311f1bdaa09a348b2dd6b1af54ea&scene=21#wechat_redirect)

[签证信息包括三部分：](http://mp.weixin.qq.com/s?__biz=MzA3MjMwMzg2Nw==&mid=2247501926&idx=1&sn=bfae8f0369187e45f6b78ee7fe341c06&chksm=9f22ddf2a85554e4b512353067976913167415dca2b12f6b311f1bdaa09a348b2dd6b1af54ea&scene=21#wechat_redirect)

Base64加密的header

Base64加密的payload

secret-密钥 使用header中声明的加密算法对Header和payload的加密连接字符串进行加盐secret组合加密。密钥保存在服务端，服务端根据密钥进行解密验证。

### JWT与开发语言 

JWT只是一个标准 可以通过不过的开发语言实现，包括Java，.NET, Python,Node Js, JavaScript,Perl, Ruby,Go等。同一种语言，不同的开发者提供了多种实现库，以Java语言为例有java-jwt、?jose4j、nimbus-jose-jwt、jjwt

### JWT官网

https://jwt.io/

这个网站提供了在线的基于不同算法的字符串和JSON对象的转换工具，同时也收集了不同语言的多种实现库。[23 种设计模式实战（很全）](http://mp.weixin.qq.com/s?__biz=MzA3MjMwMzg2Nw==&mid=2247501926&idx=1&sn=bfae8f0369187e45f6b78ee7fe341c06&chksm=9f22ddf2a85554e4b512353067976913167415dca2b12f6b311f1bdaa09a348b2dd6b1af54ea&scene=21#wechat_redirect)分享一下。

### java-jwt

java-jwt是Java语言中推荐的JWT实现库，使用Maven导入如下：

```
<dependency>
 <groupId>com.auth0</groupId>
 <artifactId>java-jwt</artifactId>
 <version>3.8.3</version>
</dependency>
```

### 产生加密Token

```
String token = JWT.create()
  .withExpiresAt(newDate(System.currentTimeMillis()))  //设置过期时间
  .withAudience("user1") //设置接受方信息，一般时登录用户
  .sign(Algorithm.HMAC256("111111"));  //使用HMAC算法，111111作为密钥加密
```

### 解密Token获取负载信息并验证Token是否有效

```
String userId = JWT.decode(token).getAudience().get(0);
Assertions.assertEquals("user1", userId);
JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256("111111")).build();
jwtVerifier.verify(token);
```

# [三、加密算法(DES,AES,RSA,MD5,SHA1,Base64)比较和项目应用](https://www.cnblogs.com/sochishun/p/7028056.html)

### **加密技术通常分为两大类:"对称式"和"非对称式"。**

**对称性加密算法：**对称式加密就是加密和解密使用同一个密钥。信息接收双方都需事先知道密匙和加解密算法且其密匙是相同的，之后便是对数据进行加解密了。对称加密算法用来对敏感数据等信息进行加密。

**非对称算法：**非对称式加密就是加密和解密所使用的不是同一个密钥，通常有两个密钥，称为"公钥"和"私钥"，它们两个必需配对使用，否则不能打开加密文件。发送双方A,B事先均生成一堆密匙，然后A将自己的公有密匙发送给B，B将自己的公有密匙发送给A，如果A要给B发送消 息，则先需要用B的公有密匙进行消息加密，然后发送给B端，此时B端再用自己的私有密匙进行消息解密，B向A发送消息时为同样的道理。

**散列算法：**散列算法，又称哈希函数，是一种单向加密算法。在信息安全技术中，经常需要验证消息的完整性，散列(Hash)函数提供了这一服务，它对不同长度的输入消息，产生固定长度的输出。这个固定长度的输出称为原输入消息的"散列"或"消息摘要"(Message digest)。散列算法不算加密算法，因为其结果是不可逆的，既然是不可逆的，那么当然不是用来加密的，而是签名。

 

#### **对称性加密算法有：AES、DES、3DES**

用途：对称加密算法用来对敏感数据等信息进行加密

**DES**（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。

 ![img](https://img-blog.csdnimg.cn/20211011100038220.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Yev6IW-5Yev,size_20,color_FFFFFF,t_70,g_se,x_16)

**3DES**（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。

**AES**（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高；AES是一个使用128为分组块的分组加密算法，分组块和128、192或256位的密钥一起作为输入，对4×4的字节数组上进行操作。众所周之AES是种十分高效的算法，尤其在8位架构中，这源于它面向字节的设计。AES 适用于8位的小型单片机或者普通的32位微处理器,并且适合用专门的硬件实现，硬件实现能够使其吞吐量（每秒可以到达的加密/解密bit数）达到十亿量级。同样，其也适用于RFID系统。



![img](https://img-blog.csdnimg.cn/20211011100206331.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Yev6IW-5Yev,size_20,color_FFFFFF,t_70,g_se,x_16)

![img](https://img-blog.csdnimg.cn/20211011100215669.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Yev6IW-5Yev,size_20,color_FFFFFF,t_70,g_se,x_16)



#### **非对称性算法有：RSA、DSA、ECC**

**RSA**：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的。RSA在国外早已进入实用阶段，已研制出多种高速的RSA的专用芯片。

![img](https://img-blog.csdnimg.cn/20211011100308509.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Yev6IW-5Yev,size_20,color_FFFFFF,t_70,g_se,x_16)

**DSA**（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准），严格来说不算加密算法。

**ECC**（Elliptic Curves Cryptography）：椭圆曲线密码编码学。ECC和RSA相比，具有多方面的绝对优势，主要有：抗攻击性强。相同的密钥长度，其抗攻击性要强很多倍。计算量小，处理速度快。ECC总的速度比RSA、DSA要快得多。存储空间占用小。ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多，意味着它所占的存贮空间要小得多。这对于加密算法在IC卡上的应用具有特别重要的意义。带宽要求低。当对长消息进行加解密时，三类密码系统有相同的带宽要求，但应用于短消息时ECC带宽要求却低得多。带宽要求低使ECC在无线网络领域具有广泛的应用前景。

 **加密算法的要求**：1、检查软件的密码算法清单中是否有不安全的加密算法。如果有，则还需检查清单中是否支持可替代的安全算法。如果既使用了不安全的加密算法，又不支持可替代的安全加密算法，则存在问题。（因标准协议定义且没有替代算法、需要与第三方系统对接、兼容老系统等情况除外）
2、参考“安全编码”子项目中CodeDEX的扫描结果，是否存在弱加密算法的相关告警。如果存在，且不满足需求规格的例外条件，则存在问题。
备注：安全及不安全加密算法的举例说明
1）禁止MD5应用在参与生成“数字签名、口令加密保存”这两种场景（HMAC-MD5例外），禁止SHA1应用在参与生成“数字签名”的场景；
2）SHA1算法可用于HMAC、PBKDF2、随机数发生器的场景；
3）推荐使用的密码算法：
  分组密码算法：AES（密钥长度在128位及以上）
  流密码算法：AES（密钥长度在128位及以上）（/*OFB或CTR模式）
  非对称加密算法：RSA（密钥长度在2048位及以上)
  哈希算法：SHA2（256位及以上）
  密钥交换算法：DH（2048位及以上)
  HMAC（基于哈希的消息验证码）算法：HMAC-SHA2
  口令数据在采用散列算法加密时，建议采用Salted Hash技术，如SHA256(口令|Salt)。其中，盐值为密码学安全随机数，由系统随机生成，并按用户区分。

### **散列算法（签名算法）有：MD5、SHA1、HMAC**

用途：主要用于验证，防止信息被修。具体用途如：文件校验、数字签名、鉴权协议

**MD5**：MD5是一种不可逆的加密算法，目前是最牢靠的加密算法之一，尚没有能够逆运算的程序被开发出来，它对应任何字符串都可以加密成一段唯一的固定长度的代码。

**SHA1**：是由NISTNSA设计为同DSA一起使用的，它对长度小于264的输入，产生长度为160bit的散列值，因此抗穷举(brute-force)性更好。SHA-1设计时基于和MD4相同原理,并且模仿了该算法。SHA-1是由美国标准技术局（NIST）颁布的国家标准，是一种应用最为广泛的Hash函数算法，也是目前最先进的加密技术，被政府部门和私营业主用来处理敏感的信息。而SHA-1基于MD5，MD5又基于MD4。

**HMAC**：是密钥相关的哈希运算消息认证码（Hash-based Message Authentication Code）,HMAC运算利用哈希算法，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。也就是说HMAC是需要一个密钥的。所以，HMAC_SHA1也是需要一个密钥的，而SHA1不需要。

 

### **其他常用算法：**

**Base64**：其实不是安全领域下的加密解密算法，只能算是一个编码算法，通常用于把二进制数据编码为可写的字符形式的数据，对数据内容进行编码来适合传输(可以对img图像编码用于传输)。这是一种可逆的编码方式。编码后的数据是一个字符串，其中包含的字符为：A-Z、a-z、0-9、+、/，共64个字符(26 + 26 + 10 + 1 + 1 = 64，其实是65个字符，“=”是填充字符。Base64要求把每三个8Bit的字节转换为四个6Bit的字节(3*8 = 4*6 = 24)，然后把6Bit再添两位高位0，组成四个8Bit的字节，也就是说，转换后的字符串理论上将要比原来的长1/3。原文的字节最后不够3个的地方用0来补足，转换时Base64编码用=号来代替。这就是为什么有些Base64编码会以一个或两个等号结束的原因，中间是不可能出现等号的，但等号最多只有两个。其实不用"="也不耽误解码，之所以用"="，可能是考虑到多段编码后的Base64字符串拼起来也不会引起混淆。)
Base64编码是从二进制到字符的过程，像一些中文字符用不同的编码转为二进制时，产生的二进制是不一样的，所以最终产生的Base64字符也不一样。例如"上网"对应utf-8格式的Base64编码是"5LiK572R"， 对应GB2312格式的Base64编码是"yc/N+A=="。
标准的Base64并不适合直接放在URL里传输，因为URL编码器会把标准Base64中的“/”和“+”字符变为形如“%XX”的形式，而这些“%”号在存入数据库时还需要再进行转换，因为ANSI SQL中已将“%”号用作通配符。
为解决此问题，可采用一种用于URL的改进Base64编码，它不在末尾填充'='号，并将标准Base64中的“+”和“/”分别改成了“-”和“_”，这样就免去了在URL编解码和数据库存储时所要作的转换，避免了编码信息长度在此过程中的增加，并统一了数据库、表单等处对象标识符的格式。
另有一种用于正则表达式的改进Base64变种，它将“+”和“/”改成了“!”和“-”，因为“+”，“*”以及前面在IRCu中用到的“[”和“]”在正则表达式中都可能具有特殊含义。
此外还有一些变种，它们将“+/”改为“_-”或“._”（用作编程语言中的标识符名称）或“.-”（用于XML中的Nmtoken）甚至“_:”（用于XML中的Name）。

**HTTPS**（全称：Hypertext Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL(SSL使用40 位关键字作为RC4流加密算法，这对于商业信息的加密是合适的。)，因此加密的详细内容就需要SSL。https:URL表明它使用了HTTP，但HTTPS存在不同于HTTP的默认端口及一个加密/身份验证层（在HTTP与TCP之间），提供了身份验证与加密通讯方法，现在它被广泛用于万维网上安全敏感的通讯，例如交易支付方面。它的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

 ![img](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.lvcbs.live%2Fwp-content%2Fuploads%2F2018%2F12%2Fb0e45061ce09429aab14b1225fe0ae79-1.jpg&refer=http%3A%2F%2Fwww.lvcbs.live&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1647497691&t=9b40cec2ffe2019f044058a114408d96)

1. 加密算法是可逆的，用来对敏感数据进行保护。散列算法(签名算法、哈希算法)是不可逆的，主要用于身份验证。
2. 称加密算法使用同一个密匙加密和解密，速度快，适合给大量数据加密。对称加密客户端和服务端使用同一个密匙，存在被抓包破解的风险。
3. 非对称加密算法使用公钥加密，私钥解密，私钥签名，公钥验签。安全性比对称加密高，但速度较慢。非对称加密使用两个密匙，服务端和客户端密匙不一样，私钥放在服务端，黑客一般是拿不到的，安全性高。
4. Base64不是安全领域下的加解密算法，只是一个编码算法，通常用于把二进制数据编码为可写的字符形式的数据，特别适合在http，mime协议下的网络快速传输数据。UTF-8和GBK中文的Base64编码结果是不同的。采用Base64编码不仅比较简短，同时也具有不可读性，即所编码的数据不会被人用肉眼所直接看到，但这种方式很初级，很简单。Base64可以对图片文件进行编码传输。
5.  https协议广泛用于万维网上安全敏感的通讯，例如交易支付方面。它的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。
6.  大量数据加密建议采用对称加密算法，提高加解密速度；小量的机密数据，可以采用非对称加密算法。在实际的操作过程中，我们通常采用的方式是：采用非对称加密算法管理对称算法的密钥，然后用对称加密算法加密数据，这样我们就集成了两类加密算法的优点，既实现了加密速度快的优点，又实现了安全方便管理密钥的优点。
7.  MD5标准密钥长度128位（128位是指二进制位。二进制太长，所以一般都改写成16进制，每一位16进制数可以代替4位二进制数，所以128位二进制数写成16进制就变成了128/4=32位。16位加密就是从32位MD5散列中把中间16位提取出来）；sha1标准密钥长度160位(比MD5摘要长32位)，Base64转换后的字符串理论上将要比原来的长1/3。





