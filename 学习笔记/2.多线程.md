### 什么是线程？

线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位，可以使用多线程对进行运算提速。

比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒

### 介绍一下线程的生命周期及状态？

![未命名文件.jpg](https://gitee.com/jiajiales/learningNotes/raw/master/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/media/life.jpg)

 **1.创建** 当程序使用new关键字创建了一个线程之后，该线程就处于一个新建状态（初始状态），此时它和其他Java对象一样，仅仅由Java虚拟机为其分配了内存，并初始化了其成员变量值。此时的线程对象没有表现出任何线程的动态特征，程序也不会执行线程的线程执行体。

 **2.就绪** 当线程对象调用了Thread.start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，处于这个状态的线程并没有开始运行，它只是表示该线程可以运行了。从start()源码中看出，start后添加到了线程列表中，接着在native层添加到VM中，至于该线程何时开始运行，取决于JVM里线程调度器的调度(如果OS调度选中了，就会进入到运行状态)。 

**3.运行** 当线程对象调用了Thread.start()方法之后，该线程处于就绪状态。添加到了线程列表中，如果OS调度选中了，就会进入到运行状态 

**4.阻塞** 阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况大概三种：

- 1、**等待阻塞**：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)
- 2、**同步阻塞**：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
- 3、**其他阻塞**：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁）。
- 线程睡眠：Thread.sleep(long millis)方法，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。
- 线程等待：Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。唤醒线程后，就转为就绪（Runnable）状态。
- 线程让步：Thread.yield() 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。
- 线程加入：join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。
- 线程I/O：线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。比如说监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。
- 线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意性的，并在对实现做出决定时发生。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。

**5.死亡** 线程会以以下三种方式之一结束，结束后就处于死亡状态:

- run()方法执行完成，线程正常结束。
- 线程抛出一个未捕获的Exception或Error。
- 直接调用该线程的stop()方法来结束该线程——该方法容易导致死锁，通常不推荐使用

### 线程的sleep、wait、join、yield如何使用？

**sleep**:让线程睡眠，期间会出让cpu，在同步代码块中，不会释放锁

**wait**(必须先获得对应的锁才能调用):让线程进入等待状态,释放当前线程持有的锁资源线程只有在notify 或者notifyAll方法调用后才会被唤醒,然后去争夺锁.

 **join**:线程之间协同方式,使用场景: 线程A必须等待线程B运行完毕后才可以执行,那么就可以在线程A的代码中加入ThreadB.join(); 

**yield**:让当前正在运行的线程回到可运行状态，以允许具有相同优先级的其他线程获得运行的机会。因此，使用yield()的目的是让具有相同优先级的线程之间能够适当的轮换执行。但是，实际中无法保证yield()达到让步的目的，因为，让步的线程可能被线程调度程序再次选中。

### 创建线程有哪些方式？

1.继承Thread类，重写run方法（其实Thread类本身也实现了Runnable接口）

2.实现Runnable接口，重写run方法

3.实现Callable接口，重写call方法（有返回值）

4.使用线程池（有返回值）

**[详解：Java 实现线程的方式有几种方式？带有返回值的线程怎么实现？](https://baijiahao.baidu.com/s?id=1660848743086888990&wfr=spider&for=pc)**



### 什么是守护线程？

在Java中有两类线程：User Thread(用户线程)、Daemon Thread(守护线程) 任何一个守护线程都是整个JVM中所有非守护线程的保姆： 

只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作。Daemon的作用是为其他线程的运行提供便利服务，守护线程最典型的应用就是 GC (垃圾回收器)，它就是一个很称职的守护者。
User和Daemon两者几乎没有区别，唯一的不同之处就在于虚拟机的离开：如果 User Thread已经全部退出运行了，只剩下Daemon Thread存在了，虚拟机也就退出了。 因为没有了被守护者，Daemon也就没有工作可做了，也就没有继续运行程序的必要了。 

**注意事项:** 

(1) thread.setDaemon(true)必须在thread.start()之前设置，否则会出现一个IllegalThreadStateException异常。只能在线程未开始运行之前设置为守护线程。  
(2) 在Daemon线程中产生的新线程也是Daemon的。  
(3) 不要认为所有的应用都可以分配给Daemon来进行读写操作或者计算逻辑，因为这会可能回到数据不一致的状态。

### 什么是线程安全和线程不安全？

**通俗的说：加锁的就是是线程安全的，不加锁的就是是线程不安全的**

### 线程安全

**线程安全: 就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染**。

一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将**集合类分成两组，线程安全和非线程安全的**。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。

### 线程不安全

**线程不安全：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据**

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

### 什么是自旋锁？

#### 基本概念

**自旋锁是SMP架构中的一种low-level的同步机制**。

当线程A想要获取一把自旋锁而该锁又被其它线程锁持有时，线程A会在一个循环中自旋以检测锁是不是已经可用了。

**自**旋**锁需要注意**：

- **由于自旋时不释放CPU，因而持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直在那里自旋，这就会浪费CPU时间。**
- **持有自旋锁的线程在sleep之前应该释放自旋锁以便其它线程可以获得自旋锁**。（正常情况睡觉拿锁）

### 实现自旋锁


一个简单的while就可以满足你的要求。

目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大。

```java
public class MyWaitNotify3{
 
  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;
 
  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }
 
  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
```


### **【什么是死锁？】**

💥 **死锁**就是指多个进程或线程在运行中互相等待对方释放资源，形成一种“僵局”。
当你遇到死锁时，所有相关进程都被卡住，谁也走不动，除非外力介入！

> **举例**：
>
> - **线程 A**：先锁定资源 **a**，再等待资源 **b**；
> - **线程 B**：先锁定资源 **b**，再等待资源 **a**；
>
> 这样 A 和 B 就相互等待，谁也无法继续，死锁就产生啦～

------

### **【死锁产生的原因】**

死锁的发生主要有两大原因：

1. **竞争资源**
  - 系统中的资源分为 **可剥夺**（如 CPU、内存）和 **不可剥夺**（如打印机、磁带机）。
  - 当多个进程争夺 **不可剥夺资源** 或 **临时资源**（硬件中断、消息、缓冲区消息）时，若资源申请顺序不当，就可能互相卡住～
2. **进程推进顺序非法**
  - 如果进程间彼此持有部分资源，并在申请其它资源时形成了环路等待（例如 P1持有R1请求R2，P2持有R2请求R1），系统就会进入不安全状态，从而导致死锁。

------

### **【死锁产生的4个必要条件】**

死锁必须同时满足以下4个条件：

1. **互斥条件**  
  - 每个资源一次只能被一个进程占用。
2. **请求和保持条件**
  - 进程在等待新资源的同时，保持已获得的资源不释放。
3. **不可剥夺条件**
  - 已分配的资源在使用完之前不能强行收回，只能由进程自己释放。
4. **环路等待条件**
  - 存在一条进程资源的环形链，形成互相等待的状态。

------

### **【如何解决死锁？】**

解决死锁主要有以下策略：

#### 1. **预防死锁**

- **资源一次性分配**：  
  一次性分配所需的所有资源，如果有一个拿不到，就不分配任何资源。（破坏请求条件）
- **资源有序分配**：  
  给每类资源设定固定编号，所有进程按照编号顺序申请资源。  
  👉 小Tip：按照锁对象的 `hashCode` 排序也可，但注意要防止环路等待；当资源多时，可考虑使用【[银行家算法](https://blog.csdn.net/qq_33414271/article/details/80245715) 】确保安全性。

#### 2. **超时放弃**

- 使用 `Lock` 接口的 `tryLock(timeout, TimeUnit)` 方法，线程等待超时后主动放弃已获取的资源，从而打破死锁僵局。

#### 3. **死锁检测与恢复**

- **检测**：通过 [jstack](https://blog.csdn.net/duke_ding2/article/details/131111766) 、[JConsole](https://blog.csdn.net/weixin_43024834/article/details/139247378) 等工具获取线程快照，分析线程等待图，判断是否存在死锁。
- **恢复**：常见方式有剥夺资源或撤消某个进程（或撤销代价最小的进程），释放资源使系统恢复正常。

------

### **【必备高效总结】**

> **Q1：什么是死锁？**
> **A：** 死锁是多个进程因争夺资源而相互等待，形成“僵局”，无外力干预下所有进程都无法推进。

> **Q2：死锁产生的必要条件有哪些？**
> **A：** 互斥、请求和保持、不可剥夺、环路等待四个条件同时成立时就可能产生死锁。

> **Q3：如何解决死锁？**
> **A：** 预防死锁（一次性分配资源、资源有序分配）、超时放弃以及死锁检测与恢复（银行家算法、剥夺资源或撤销进程）。

------

💡 **总结一句话**：  
死锁就是进程间的“僵局”，打破死锁的关键在于破坏其必要条件，如一次性分配、资源有序获取或超时放弃，动动小脑子，避免系统卡壳～



### 高并发下如何保证接口的幂等性？

https://mp.weixin.qq.com/s/7P2KbWjjX5YPZCInoox-xQ



## 什么是CAS？

**CAS（compare and swap）的缩写，中文翻译成比较并交换**。

CAS 不通过JVM,直接利用java本地方 JNI（Java Native Interface为JAVA本地调用）,直接调用CPU 的汇编指令指令,**提供硬件级别的原子操作**。。

**利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法,实现原子操作。其它原子操作都是利用类似的特性完成的**。

整个java.util.concurrent都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。

**CAS是项乐观锁技术**，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

### CAS应用

CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

```java
// 对象、对象的地址、预期值、修改值
public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
```



### CAS优点

确保对内存的读-改-写操作都是原子操作执行

### CAS缺点

CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。

**1.开销大**：在并发量比较高的情况下，如果反复尝试更新某个变量，却又一直更新不成功，会给CPU带来较大的压力

**2.ABA问题**：当变量从A修改为B在修改回A时，变量值等于期望值A，但是无法判断是否修改，CAS操作在ABA修改后依然成功。  
- **如何避免**：Java提供了AtomicStampedReference和AtomicMarkableReference来解决。AtomicStampedReference通过包装[E,Integer]的元组来对对象标记版本戳stamp，对于ABA问题其解决方案是加上版本号，即在每个变量都加上一个版本号，每次改变时加1，即A —> B —> A，变成1A —> 2B —> 3A。

**3.不能保证代码块的原子性**：CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。

### 总结

1. **使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用**。
2. **synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS**。



**synchronized锁升级**：https://blog.csdn.net/heightyzy/article/details/108686132

![锁升级.png](https://img-blog.csdnimg.cn/img_convert/68f0feb3c068681b242fe78eb287d601.png)

- 注意点
  - 锁的状态只有4种，无锁->偏向锁->轻量级锁->重量级锁
  - 升级过程不可逆，不同阶段通过从轻到重的方式获取锁
  - 自旋这个操作是通过线程死循环，而防止被阻塞，试图避免用户态和内核态的切换，所以本身不属于锁的状态，是配合轻量级锁使用的一种方式



### CAS 原子操作在concurrent包的实现

由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：

- A线程写volatile变量，随后B线程读这个volatile变量。
- A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。

Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：  
首先，声明共享变量为volatile；然后，使用CAS的原子条件更新来实现线程之间的同步；  
同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。

AQS，非阻塞数据结构和原子变量类（Java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：

 

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC8zLzE4LzE2MjM4ZTJjNmMyZWFhZWE?x-oss-process=image/format,png)

 

AQS没有锁之类的概念，它有个state变量，是个int类型，在不同场合有着不同含义。

AQS围绕state提供两种基本操作“获取”和“释放”，有条双向队列存放阻塞的等待线程，并提供一系列判断和处理方法，简单说几点：

- state是独占的，还是共享的；
- state被获取后，其他线程需要等待；
- state被释放后，唤醒等待线程；
- 线程等不及时，如何退出等待。

至于线程是否可以获得state，如何释放state，就不是AQS关心的了，要由子类具体实现。

**AQS中还有一个表示状态的字段state，例如ReentrantLocky用它表示线程重入锁的次数，Semaphore用它表示剩余的许可数量，FutureTask用它表示任务的状态。对state变量值的更新都采用CAS操作保证更新操作的原子性**。

AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个类只有一个变量：exclusiveOwnerThread，表示当前占用该锁的线程，并且提供了相应的get，set方法。

 

 

### 什么是乐观锁和悲观锁？

悲观锁和乐观锁并不是某个具体的“锁”而是一种并发编程的基本概念。乐观锁和悲观锁最早出现在数据库的设计当中，后来逐渐被 Java 的并发包所引入。

### 悲观锁

认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观地认为，不加锁的并发操作一定会出问题。

Java在JDK1.5之前都是靠synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。独占锁其实就是一种悲观锁，所以可以说synchronized是悲观锁。

### 乐观锁

正好和悲观锁相反，它获取数据的时候，并不担心数据被修改，每次获取数据的时候也不会加锁，只是在更新数据的时候，通过判断现有的数据是否和原数据一致来判断数据是否被其他线程操作，如果没被其他线程修改则进行数据更新，如果被其他线程修改则不进行数据更新。

乐观锁（ Optimistic Locking）其实是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。memcached使⽤了cas乐观锁技术保证数据⼀致性。

### 什么是AQS？

**AQS**是 **AbstractQueuedSynchronizer**的简称，即 **抽象队列同步器** :

抽象：抽象类，只实现⼀些主要逻辑，有些⽅法由⼦类实现；
队列：使⽤先进先出（FIFO）队列存储数据；
同步：实现了同步的功能。

**AQS是⼀个⽤来构建锁和同步器的框架**，**使⽤AQS能简单且⾼效地构造出应⽤⼴泛的同步器**

事实上concurrent包内许多类都是基于AQS构建，**例如ReentrantLock**，Semaphore，CountDownLatch，ReentrantReadWriteLock，**FutureTask**等。AQS解决了在实现同步容器时设计的大量细节问题。

**AQS使用一个FIFO的双向队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护一个等待状态waitStatus。**

![img](https://upload-images.jianshu.io/upload_images/9307436-f740e1874ed9a45a.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)



**AQS类本身实现的是一个排队和阻塞的机制**，⽐如具体线程等待队列的维护（如获取资源失败⼊队/唤醒出队等）。它内部使⽤了⼀个**先进先出（FIFO）的双端队列，并使⽤了两个指针head和tail⽤于标识队列的头部和尾部**。

**AQS数据结构如图：** 队列并不是直接储存线程，⽽是储存拥有线程的节点。

![img](https://upload-images.jianshu.io/upload_images/25399192-f84f39d68447e17a.png?imageMogr2/auto-orient/strip|imageView2/2/w/758/format/webp)



**核心数据结构：双向链表 + state(锁状态)**


### volatile原理是什么？

此题考察的是`volatile`这个关键字。可以从`volatile`的作用和`volatile`的原理这三个方面来进行回答。**volatile只能保证变量的可见性、有序性，但是不能保证原子性。**

题目回答	
**volatile的作用**  
1.保证内存可见性：一个线程对一个volatile变量的修改，对于其它线程来说是可见的。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。   
2.禁止指令重排序  
**volatile的原理**  
**可见性实现**  
线程本身并不直接与主内存进行数据的交互，而是通过线程的工作内存来完成相应的操作。这也是导致线程间数据不可见的本质原因。对volatile变量的写操作与普通变量的主要区别有两点：

修改volatile变量时会强制将修改后的值刷新的主内存中。  
修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。  
**有序性实现**  
volatile是通过编译器在生成字节码时，在指令序列中添加“内存屏障”来禁止指令重排序的。多核处理器需使用内存屏障指令来确保一致性。  

属性添加了volatile关键字之后，编译之后的属性会被添加ACC_VOLATILE访问标记。  
获取和设置静态属性的字节码是putstatic和getstatic，获取成员变量的字节码是putfield和getfield，在这些字节码的代码中，会先判断字段是否被ACC_VOLATILE修饰，即判断字段是否为volatile字段，若是，则会在操作之后，加上内存屏障。 添加内存屏障之后的代码，内存屏障之后的代码会在内存屏障之前的代码执行完之后再执行。 这样就保证了有序性。





### 什么是原⼦操作？在Java Concurrency API中有哪些原⼦类(atomic classes)？

1. 原⼦操作是指⼀个不受其他操作影响的操作任务单元。原⼦操作是在多线程环境下避免数据不⼀致必须的⼿段。
2. int++并不是⼀个原⼦操作，所以当⼀个线程读取它的值并加1时，另外⼀个线程有可能会读到之前的值，这就会引发错误。
3. 为了解决这个问题，必须保证增加操作是原⼦的，在JDK1.5之前我们可以使⽤同步技术来做到这⼀点。

到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以自动的保证对于他们的操作是原⼦的并且不需要使⽤同步。

### 什么是同步容器和并发容器的实现？

#### 同步容器

1、主要代表有Vector和Hashtable，以及Collections.synchronizedXxx等。

2、锁的粒度为当前对象整体。

3、迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。

##### 并发容器

1、主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。

2、锁的粒度是分散的、细粒度的，即读和写是使⽤不同的锁。

3、迭代器具有弱⼀致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。

> ConcurrentHashMap 采⽤分段锁技术，同步容器中，是⼀个容器⼀个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若⼲段，每段维护⼀个锁，以达到⾼效的并发访问；

**JDK 7 ConcurrentHashMap**  
1.实现原理：  
ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表,同时又是一个ReentrantLock（Segment继承了ReentrantLock）。  
2.内部结构：  
ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：

![img](https://i-blog.csdnimg.cn/blog_migrate/9c0f7c28df06683678f0293c76330773.jpeg)
从上面的结构我们可以了解到，Concu rrentHashMap定位一个元素的过程需要进行两次Hash操作。 第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。

3.该结构的优劣势

**坏处**  
这一种结构的带来的副作用是Hash的过程要比普通的HashMap要长

**好处**  
写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，在最理想的情况下，ConcurrentHashMap可以最高同时支持Segment数量大小的写操作（刚好这些写操作都非常平均地分布在所有的Segment上）。

所以，通过这一种结构，ConcurrentHashMap的并发能力可以大大的提高。

**JDK 8 ConcurrentHashMap**

JDK8中ConcurrentHashMap参考了JDK8 HashMap的实现，采用了数组+链表+红黑树的实现方式来设计，内部大量采用CAS操作。

JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK1.7中的分段锁思想。

Node：保存key，value及key的hash值的数据结构。其中value和next都用volatile修饰，保证并发的可见性。

Java8 ConcurrentHashMap结构基本上和Java8的HashMap一样，不过保证线程安全性。

 

在JDK8中ConcurrentHashMap的结构，由于引入了红黑树，使得ConcurrentHashMap的实现非常复杂，我们都知道，红黑树是一种性能非常好的二叉查找树，其查找性能为O（logN），但是其实现过程也非常复杂，而且可读性也非常差，DougLea的思维能力确实不是一般人能比的，早期完全采用链表结构时Map的查找时间复杂度为O（N），JDK8中ConcurrentHashMap在链表的长度大于某个阈值的时候会将链表转换成红黑树进一步提高其查找性能。
![img](https://upload-images.jianshu.io/upload_images/20782304-f7ba6ac0add69cb6.png?imageMogr2/auto-orient/strip|imageView2/2/w/867/format/webp)
**总结**

其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。

* 1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。
* 2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。
* 3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。
* 4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。
* 5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。 


**📌 1. 核心对比表**

| **对比项**   | **Java 7**                                   | **Java 8**                                |
| ------------ | -------------------------------------------- | ----------------------------------------- |
| **底层结构** | `Segment[]` + `HashEntry[]`（分段锁）        | `Node[]` + 链表 + 红黑树                  |
| **并发控制** | **分段锁 `ReentrantLock`，锁粒度大**         | **CAS + Synchronized，无锁+细粒度锁**     |
| **读操作**   | 直接读取 `volatile` 变量                     | **无锁读**，竞争时 CAS                    |
| **写操作**   | **锁定 `Segment`，多个线程竞争同一块时等待** | **CAS 失败才用 Synchronized，减少锁冲突** |
| **哈希冲突** | **仅链表**，查询 O(n)，冲突严重              | **链表 + 红黑树**，查询 O(log n)          |
| **扩容机制** | **全量扩容**，需锁 `Segment`，影响并发       | **渐进式扩容**，分批迁移，避免大锁        |
| **并发度**   | 受 `Segment` 数量限制（默认 16）             | 理论上可达 `Node[]` 长度                  |
| **适用场景** | **低并发，写多时冲突大**                     | **高并发，读写都适用**                    |

------

 **🔥 2. 重点归纳**

 ❌ **Java 7 的痛点**

- **锁粒度大**：采用 `Segment` 进行分段锁，多个线程竞争同一个 `Segment` 时仍然需要等待，锁冲突大。
- **哈希冲突处理差**：只支持**链表**存储，链表长度大时查询 O(n)，查询速度变慢。
- **扩容性能差**：全量扩容时需要锁定 `Segment`，影响并发吞吐量。

 ✅ **Java 8 的优化**

- **去掉 `Segment`，引入 CAS + Synchronized，提升并发**。
- **链表 + 红黑树**，冲突高时查询优化为 O(log n)，查找更快！
- **渐进式扩容**，避免 Java 7 的全量扩容导致系统卡顿。

------

 **🎯 3. 总结**  

💡 **记住这 3 点，面试稳过！**   
1️⃣ **Java 8 不再使用 `Segment`，改用 CAS + Synchronized，提高并发**  
2️⃣ **引入红黑树，哈希冲突高时查询从 O(n) 提升到 O(log n)**  
3️⃣ **扩容更智能，渐进式迁移，避免一次性扩容的卡顿问题**

🚀 **总结：Java 8 并发性能更强，适合高并发场景，推荐直接使用！**




### 什么是多线程？优缺点？

**什么是多线程？**

多线程：是指从软件或者硬件上实现多个线程的并发技术。

**多线程的好处：**

1. 使用多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视屏的下载
2. 发挥多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好

**多线程的缺点：**

1. 大量的线程降低代码的可读性；
2. 更多的线程需要更多的内存空间
3. 当多个线程对同一个资源出现争夺时候要注意线程安全的问题。

# 什么是多线程的上下文切换？



1、多线程：是指从软件或者硬件上实现多个线程的并发技术。  
2、多线程的好处：

> 使⽤多线程可以把程序中占据时间⻓的任务放到后台去处理，如图⽚、视屏的下载 发挥多核处理器的优势，并发执⾏让系统运⾏的更快、更流畅，⽤户体验更好

3、多线程的缺点：

> ⼤量的线程降低代码的可读性；更多的线程需要更多的内存空间, 当多个线程对同⼀个资源出现争夺时候要注意线程安全的问题。

4、多线程的上下⽂切换：

> CPU通过时间⽚分配算法来循环执⾏任务，当前任务执⾏⼀个时间⽚后会切换到下⼀个任务。但是，在切换前会保存上⼀个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态。





### ThreadLocal的设计理念与作用？



Java中的ThreadLocal类允许我们创建只能被同⼀个线程读写的变量。因此，如果⼀段代码含有⼀个ThreadLocal变量的引⽤，即使两个线程同时执⾏这段代码，它们也⽆法访问到对⽅的ThreadLocal变量。

**概念**：  
线程局部变量。在并发编程的时候，成员变量如果不做任何处理其实是线程不安全的，各个线程都在操作同⼀个变量，显然是不⾏的，并且我们也知道volatile这个关键字也是不能保证线程安全的。那么在有⼀种情况之下，我们需要满⾜这样⼀个条件：变量是同⼀个，但是每个线程都使⽤同⼀个初始值，也就是使⽤同⼀个变量的⼀个新的副本。这种情况之下ThreadLocal就⾮常适⽤，⽐如说DAO的数据库连接，我们知道DAO是单例的，那么他的属性Connection就不是⼀个线程安全的变量。⽽我们每个线程都需要使⽤他，并且各自使⽤各自的。这种情况，ThreadLocal就⽐较好的解决了这个问题。  
**原理**：
* Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap。

* ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。

* 每个线程在往ThreadLocal里设置值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。

**实现机制**：每个Thread对象内部都维护了⼀个ThreadLocalMap这样⼀个ThreadLocal的Map，可以存放若⼲个 ThreadLocal。

![img](https://inews.gtimg.com/newsapp_bt/0/12171948806/1000)



 **ThreadLocal的应用场景**

* 1、方便同一个线程使用某一对象，避免不必要的参数传递；
* 2、线程间数据隔离（每个线程在自己线程里使用自己的局部变量，各线程间的ThreadLocal对象互不响）；

线程隔离的秘密，就在于ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。

* 3、获取数据库连接、Session、关联ID（比如日志的uniqueID，方便串起多个日志）；

* 4、其中spring中的事务管理器就是使用的ThreadLocal：

Spring的事务管理器通过AOP切入业务代码，在进入业务代码前，会依据相应的事务管理器提取出相应的事务对象，假如事务管理器是DataSourceTransactionManager，就会从DataSource中获取一个连接对象，通过一定的包装后将其保存在ThreadLocal中。而且Spring也将DataSource进行了包装，重写了当中的getConnection()方法，或者说该方法的返回将由Spring来控制，这样Spring就能让线程内多次获取到的Connection对象是同一个。

### ThreadLocal有哪些内存泄露问题，如何避免？

每个Thread都有一个ThreadLocal.ThreadLocalMap的map，该map的key为ThreadLocal实例，它为一个弱引用，我们知道弱引用有利于GC回收。当ThreadLocal的key == null时，GC就会回收这部分空间，但是value却不一定能够被回收，因为他还与Current Thread存在一个强引用关系，如下

![img](https://inews.gtimg.com/newsapp_bt/0/12171949025/1000)弱引用：只要垃圾回收机制一运行，不管JVM的内存空间是否充足，都会回收该对象占用的内存。

弱引用比较容易被回收。因此，如果ThreadLocal（ThreadLocalMap的Key）被垃圾回收器回收了，但是因为ThreadLocalMap生命周期和Thread是一样的，它这时候如果不被回收，就会出现这种情况：ThreadLocalMap的key没了，value还在，这就会**「造成了内存泄漏问题」**。

如何 **「解决内存泄漏问题」**？使用完ThreadLocal后，及时调用remove()方法释放内存空间。



### ThreadPool（线程池）用法与优势？

#### 为什么要用线程池:

1. 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
2. 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。
3. Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。

#### new Thread 缺点

1. 每次new Thread新建对象性能差。
2. 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。
3. 缺乏更多功能，如定时执行、定期执行、线程中断。

#### ThreadPool 优点

减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务

可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)

- 减少在创建和销毁线程上所花的时间以及系统资源的开销
- 如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存

**Java提供的四种线程池的好处在于**：

1. 重用存在的线程，减少对象创建、销毁的开销，提高性能。
2. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。
3. 提供定时执行、定期执行、单线程、并发数控制等功能。

### 比较重要的几个类：

| 类                          | 描述                                                         |
| :-------------------------- | :----------------------------------------------------------- |
| ExecutorService             | 真正的线程池接口。                                           |
| ScheduledExecutorService    | 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。    |
| ThreadPoolExecutor          | ExecutorService的默认实现。                                  |
| ScheduledThreadPoolExecutor | 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 |

要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。

### Executors提供四种线程池

**newCachedThreadPool**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

**newFixedThreadPool** 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。

**newScheduledThreadPool** 创建一个定长线程池，支持定时及周期性任务执行。

**newSingleThreadExecutor** 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

### 一般都不用Executors提供的线程创建方式

**使用ThreadPoolExecutor创建线程池**

**ThreadPoolExecutor的构造函数**

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

docc
```

### 线程池核心参数：

1. **corePoolSize**核心线程数大小，当线程数<corePoolSize ，会创建线程执行runnable
2. **maximumPoolSize** 最大线程数， 当线程数 >= corePoolSize的时候，会把runnable放入workQueue中
3. **keepAliveTime** 保持存活时间，当线程数大于corePoolSize的空闲线程能保持的最大时间。
4. **unit** 时间单位
5. **workQueue** 保存任务的阻塞队列
6. **threadFactory** 创建线程的工厂
7. **handler** 拒绝策略

### 任务执行顺序：

1. 当线程数小于corePoolSize时，创建线程执行任务。
2. 当线程数大于等于corePoolSize并且workQueue没有满时，放入workQueue中
3. 线程数大于等于corePoolSize并且当workQueue满时，新任务新建线程运行，线程总数要小于maximumPoolSize
4. 当线程总数等于maximumPoolSize并且workQueue满了的时候执行handler的rejectedExecution。也就是拒绝策略。

Java线程池的核心工作流程如下图所示。

![图片](https://mmbiz.qpic.cn/mmbiz_png/2hHcUic5FEwGul3icvjVIxUPicOOVx3pnTiaibsEVfxgSuxcYsRMgxGXhsS8ACspyK7djQrQGd3GicoZBkXiaLuRzV3Sw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





**为什么先添加队列而不是先创建最大线程**

* 在创建新线程的时候，是要获取全局锁的，这时候其他线程会被阻塞，影响整体效率。
* 在核心线程已满时，如果任务继续增加那么放在队列中，等队列满了而任务还在增加那么就要创建临时线程了，这样代价低。
  

**重点来啦：**

我们说设置线程池大小，主要是设置最大线程的数量，即**maxPoolSize**参数的大小。那这个应该设置成多少合适呢？首先我们要分两种情况，即CPU密集型和IO密集型任务。

**CPU密集型任务**：即需要大量计算的任务，因为计算是由CPU来完成的，所以称之为CPU密集型任务。这个时候设置为**CPU核心数+1**就可以了。

**IO密集型任务**：即需要通过网络来交互的任务，通常是指数据库数据交互、文件上传下载、网络数据传输等任务。这个时候需要设置为**CPU核心数\*2。**但是实际情况中可以通过自己的测试来设置合理的数值，通过与大牛的交流得知，这个数值可以设置为**CPU核心数/（1-阻塞系数），**阻塞系数一般在**0.8~0.9**之间。比如8核CPU可以设置为：8/（1-0.9）=80。

注意：在java中获取CPU核心数可以用以下代码：

```java
Runtime.getRuntime().availableProcessors();1.
```

 

### ThreadPoolExecutor默认有四个拒绝策略：

1. `ThreadPoolExecutor.AbortPolicy()` 直接抛出异常RejectedExecutionException
2. `ThreadPoolExecutor.CallerRunsPolicy()` 直接调用run方法并且阻塞执行
3. `ThreadPoolExecutor.DiscardPolicy()` 直接丢弃后来的任务
4. `ThreadPoolExecutor.DiscardOldestPolicy()` 丢弃在队列中队首的任务

当然可以自己继承 RejectedExecutionHandler 来写拒绝策略.



## 什么是阻塞队列？

阻塞队列是一个在队列基础上又支持了两个附加操作的队列。

2个附加操作：

支持阻塞的**插入**方法：队列满时，队列会阻塞插入元素的线程，直到队列不满。

支持阻塞的**移除**方法：队列空时，获取元素的线程会等待队列变为非空。

 **阻塞队列的作用**

* 一般的队列只能是有限长度的缓冲区，一旦超出缓冲长度，就无法保留了。阻塞队列通过阻塞可以保留住当前想要继续入队的任务。
* 阻塞队列可以在队列中没有任务时，阻塞想要获取任务的线程，使其进入wait状态，释放cpu资源。
* 阻塞队列带有阻塞和唤醒的功能，不需要额外处理，无任务执行时，线程池利用阻塞队列的take方法挂起，从而维持核心线程的存活，不至于一直占用cpu资源。

### 阻塞队列的应用场景

阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。简而言之，阻塞队列是生产者用来存放元素、消费者获取元素的容器。

### 几个方法

在阻塞队列不可用的时候，上述2个附加操作提供了四种处理方法

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| :------------ | :-------- | :--------- | :------- | :----------------- |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     | 不可用   | 不可用             |

### JAVA里的阻塞队列

JDK 7 提供了7个阻塞队列，如下

1、**ArrayBlockingQueue** 数组结构组成的有界阻塞队列。

此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。

2、**LinkedBlockingQueue**一个由链表结构组成的有界阻塞队列，此队列按照先出先进的原则对元素进行排序

3、**PriorityBlockingQueue**支持优先级的无界阻塞队列

4、**DelayQueue**支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素

5、**SynchronousQueue**不存储元素的阻塞队列，每一个put必须等待一个take操作，否则不能继续添加元素。并且他支持公平访问队列。

6、**LinkedTransferQueue**由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，多了tryTransfer和transfer方法

**transfer方法**

如果当前有消费者正在等待接收元素（take或者待时间限制的poll方法），transfer可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的tail节点，并等到该元素被消费者消费了才返回。

**tryTransfer方法**

用来试探生产者传入的元素能否直接传给消费者。，如果没有消费者在等待，则返回false。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。

7、**LinkedBlockingDeque**链表结构的双向阻塞队列，优势在于多线程入队时，减少一半的竞争。

### 比较及适用场景

* 如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；

* 如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；

* 如果需要对队列进行排序，选择PriorityBlockingQueue；

* 如果需要一个快速交换的队列，选择SynchronousQueue；

* 如果需要对队列中的元素进行延时操作，则选择DelayQueue。

### 双端队列

主要代表有ArrayDeque和LinkedBlockingDeque。意义：正如阻塞队列适用于生产者消费者模式，双端队列同样适用与另一种模式，即工作密取。在生产者-消费者设计中，所有消费者共享一个工作队列，而在工作密取中，每个消费者都有各自的双端队列。如果一个消费者完成了自己双端队列中的全部工作，那么他就可以从其他消费者的双端队列末尾秘密的获取工作。具有更好的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。在大多数时候，他们都只是访问自己的双端队列，从而极大的减少了竞争。当工作者线程需要访问另一个队列时，它会从队列的尾部而不是头部获取工作，因此进一步降低了队列上的竞争。适用于：网页爬虫等任务中





###  Concurrent包⾥的其他东⻄：ArrayBlockingQueue、CountDownLatch等等。

1、ArrayBlockingQueue 数组结构组成的有界阻塞队列。

2、CountDownLatch 允许⼀个或多个线程等待其他线程完成操作；join⽤于让当前执⾏线程等待join线程执⾏结束。其实现原理是不停检查join线程是否存活，如果join线程存活则让当前线程永远wait。

#### countDownLatch简介

##### 1.背景：

- countDownLatch是在java1.5被引入，跟它一起被引入的工具类还有CyclicBarrier、Semaphore、concurrentHashMap和BlockingQueue。
- 存在于java.util.cucurrent包下。
- 实现主线程等待子线程执行

##### 2.概念

- countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。
- 是通过一个计数器来实现的，计数器的初始值是线程的数量。每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。

##### 3.源码

- countDownLatch类中只提供了一个构造器：

```java
//参数count为计数值
public CountDownLatch(int count) {  };  
```

- 类中有三个方法是最重要的：

```java
//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行
public void await() throws InterruptedException { };   
//和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行
public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  
//将count值减1
public void countDown() { };  
```

​     

##### 4.实现

引入countDownLatch，实现主线程等待子线程执行

```java
package com.liuzhou.core.test;

import java.util.concurrent.CountDownLatch;

public class MultiThreadToCountDownLatch
{
    public static void main(String[] args) throws InterruptedException
    {
        //1、 创建CountDownLatch 对象， 设定需要计数的子线程数目
        final CountDownLatch latch = new CountDownLatch(3);
        System.out.println("主线程开始执行....");
        for (int i = 0; i < 3; i++)
        {
            new Thread()
            {
                @Override
                public void run()
                {
                    try
                    {
                        System.out.println(Thread.currentThread().getName() + "  开始执行存储过程..");
                        Thread.sleep(2000);
                        System.out.println(Thread.currentThread().getName() + "  存储过程执行完毕...");
                        //2、子线程执行完毕，计数减1
                        latch.countDown();
                    }
                    catch (InterruptedException e)
                    {
                        e.printStackTrace();
                    }
                }

                ;
            }.start();

        }
        System.out.println("等待子线程执行完毕...");
        //3、 当前线程挂起等待
        latch.await();
        System.out.println("主线程执行完毕....");
    }


}
```



执行结果：

```
主线程开始执行....
等待子线程执行完毕...
Thread-0  开始执行存储过程..
Thread-1  开始执行存储过程..
Thread-2  开始执行存储过程..
Thread-1  存储过程执行完毕...
Thread-0  存储过程执行完毕...
Thread-2  存储过程执行完毕...
主线程执行完毕....
```



这时会发现 



### synchronized和ReentrantLock的区别？



**📌 核心区别对比**

| **对比点**     | **synchronized**                               | **ReentrantLock**                                |
| -------------- | ---------------------------------------------- | ------------------------------------------------ |
| **出现时期**   | **JDK 1.0**（1995）                            | **JDK 1.5**（2004，引入 `java.util.concurrent`） |
| **实现方式**   | JVM 内置关键字，依赖 **对象头** 实现           | `java.util.concurrent.locks` 包中的 **显式锁**   |
| **可重入性**   | **支持**（同一线程可多次获得同一锁）           | **支持**（`lock.lock()` 多次调用不会死锁）       |
| **锁的公平性** | **非公平**（默认）                             | **支持公平锁 & 非公平锁**（默认非公平）          |
| **锁的粒度**   | 作用于 **代码块 / 方法**，不可灵活控制         | **更灵活**，可作用于代码块、多个方法             |
| **锁的释放**   | 由 JVM 自动释放（代码执行完毕后释放）          | **需手动释放**（`lock.unlock()`，否则可能死锁）  |
| **尝试获取锁** | **不可尝试**（只能阻塞等待）                   | **可尝试获取**（`tryLock()`，可避免死锁）        |
| **可中断性**   | **不可中断**（除非抛异常）                     | **可中断**（`lock.lockInterruptibly()`）         |
| **性能优化**   | JDK 1.6 之后优化（偏向锁、轻量级锁、自旋锁等） | 适用于高并发场景，**吞吐量更高**                 |


java在编写多线程程序时，为了保证线程安全，需要对数据同步，经常用到两种同步方式就是Synchronized和重入锁ReentrantLock。

### 1.基础知识

- **可重入锁**。可重入锁是指同一个线程可以多次获取同一把锁。**ReentrantLock和synchronized都是可重入锁**。
- **可中断锁**。可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。synchronized是不可中断锁，而ReentrantLock则提供了中断功能。
- **公平锁与非公平锁**。公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。
- **CAS操作(CompareAndSwap)**。CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

### 2.Synchronized

synchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而synchronized也有一定的局限性

例如：

1. 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。
2. 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。

### 3.synchronized (this)原理

涉及两条指令：

（1）**monitorenter**

 每个对象有一个**监视器锁**（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：  

1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。  
2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1。  
3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。



（2）**monitorexit**  
执行monitorexit的线程必须是objectref所对应的monitor的所有者。  
指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor 的所有权。



通过这两段描述，我们应该能很清楚的看出synchronized的实现原理，synchronized的语义底层是通过一个monitor的对象来完成。  
其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

### 4.ReentrantLock

ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。

代码示例

```java
private Lock lock = new ReentrantLock();
public void test(){
 lock.lock();
 try{
 doSomeThing();
 }catch (Exception e){
 // ignored
 }finally {
 lock.unlock();
 }
}
```

- **lock**(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁
- **tryLock()**, 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false；
- **tryLock(long timeout,TimeUnit unit)**，如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false；
- **lockInterruptibly**:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断

**ReentrantLock 一些特性**

1. **等待可中断避免，出现死锁的情况**（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false）
2. **公平锁与非公平锁**多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，**ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁**，但公平锁表现的性能不是很好。

公平锁：线程获取锁的顺序和调用lock的顺序一样，FIFO；

非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。

**Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作**。

#### ReenTrantLock实现的原理：

简单来说，**ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁**。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

#### 总结一下

在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

**synchronized**：

在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。

**ReentrantLock**:

ReentrantLock用起来会复杂一些。在基本的加锁和解锁上，两者是一样的，所以无特殊情况下，推荐使用synchronized。ReentrantLock的优势在于它更灵活、更强大，增加了轮训、超时、中断等高级功能。

ReentrantLock默认**使用非公平锁是基于性能考虑**，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。





### Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。

它的优势有：
- 可以使锁更公平
- 可以使线程在等待锁的时候响应中断
- 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
- 可以在不同的范围，以不同的顺序获取和释放锁

### Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？

同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。

**而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性**

### ConcurrentHashMap的并发度是什么？

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势

### ReentrantReadWriteLock读写锁的使用

Lock比传统线程模型中的synchronized方式更加面向对象，与生活中的锁类似，锁本身也应该是一个对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个Lock对象。

**读写锁**：**分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可**。**如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁**；

如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！

**ReentrantReadWriteLock会使用两把锁来解决问题，一个读锁，一个写锁**

**线程进入读锁的前提条件**：

- **没有其他线程的写锁**
- **没有写请求或者有写请求，但调用线程和持有锁的线程是同一个**

**线程进入写锁的前提条件**：

- **没有其他线程的读锁**
- **没有其他线程的写锁**
- 读锁的重入是允许多个申请读操作的线程的，而写锁同时只允许单个线程占有，该线程的写操作可以重入。
- 如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。
- 对于同时占有读锁和写锁的线程，如果完全释放了写锁，那么它就完全转换成了读锁，以后的写操作无法重入，在写锁未完全释放时写操作是可以重入的。
- 公平模式下无论读锁还是写锁的申请都必须按照AQS锁等待队列先进先出的顺序。非公平模式下读操作插队的条件是锁等待队列head节点后的下一个节点是SHARED型节点，写锁则无条件插队。
- 读锁不允许newConditon获取Condition接口，而写锁的newCondition接口实现方法同ReentrantLock。




### Java程序占用 CPU 过高怎么排查
线上一台服务器 CPU 使用率100% 了，如果你碰到这样的情况，如何排查并找到问题原因？  
这就是一个套路题，所谓套路题就是有标准的套路解法的，掌握了套路，不仅能解决面试官，还能解决问题。不然真的就掉进套路里了。  
当我们真碰到这个问题的时候应该怎么排查呢？
模拟一个高 CPU 场景  
先用一段程序创建几个线程，将其中一个线程设置成高 CPU 使用率的。

```java
public static void main(String[] args)  {
  for (int i = 0; i < 10; i++) {
    Thread thread = new Thread(() -> {
      System.out.println(Thread.currentThread().getName());
      try {
        Thread.sleep(30 * 60 * 1000);
      }catch (Exception e){
        e.printStackTrace();
      }
    });
    thread.setName("thread-" + i);
    thread.start();
  }

  Thread highCpuThread = new Thread(() -> {
    int i = 0;
    while (true) {
      i++;
    }
  });
  highCpuThread.setName("HighCpu");
  highCpuThread.start();
}

```
运行这段程序后，前面 10 个线程都处于休眠状态，只有最后一个线程会持续的占用 CPU 。

运行这段程序，然后就可以开始一些列的操作来发现问题原因了。

排查步骤

##### **第一步，使用 top 找到占用 CPU 最高的 Java 进程**

在真实环境中，首先要确认是不是 Java 程序造成的，如果有系统监控工具，可能会直接在预警信息里告诉你是有哪个进程造成的，但也有可能不知道，需要我们手动排查。

如果是在面试场景中，这个问题可能不需要确认，毕竟 Java 面试，面试官可能直接就告诉你是 Java 占用的 CPU 过高。

这一步也非常简单，就是一个 top命令而已，基本上所有同学都用过这个命令吧。

![img](https://img-blog.csdnimg.cn/img_convert/8aba5a1048152f8aecc8ced960f6dee4.png)



使用 top命令发现占用 CPU 99.7% 的线程是 Java 进程，进程 PID 为 13731。

##### **第二步，用 top -Hp 命令查看占用 CPU 最高的线程**

上一步用 top命令找到了那个 Java 进程。那一个进程中有那么多线程，不可能所有线程都一直占着 CPU 不放，这一步要做的就是揪出这个罪魁祸首，当然有可能不止一个。

执行top -Hp pid命令，pid 就是前面的 Java 进程，我这个例子中就是 13731 ，完整命令为：

top -Hp 13731，执行之后的效果如下

![img](https://img-blog.csdnimg.cn/img_convert/c67f03a2de66654a5fafeae402d66e28.png)



可以看到占用 CPU 最高的那个线程 PID 为 13756。

然后将 13756转换为 16 进制的，后面会用到，可以用在线进制转换的网站直接转换，转换结果为 0x35bc

##### **第三步，保存线程栈信息**

​	当前 Java 程序的所有线程信息都可以通过 jstack命令查看，我们用jstack命令将第一步找到的 Java 进程的线程栈保存下来。

```python
jstack 13731 > thread_stack.log
```

##### **第四步，在线程栈中查找最贵祸首的线程**

第二步已经找到了这个罪魁祸首的线程 PID，并把它转换成了 16 进制的，第三步保存下来的线程栈中有所有线程的 PID 16 进制信息，我们在线程栈中查找这个16进制的线程 id （0x35bc）。

![img](https://img-blog.csdnimg.cn/img_convert/30f3c16bb3bb16fb5b7278f33294f1d6.png)

怎么样，现在一目了然了，线程名称、线程状态、以及哪行代码消耗了最多的 CPU 都很清楚了。 

