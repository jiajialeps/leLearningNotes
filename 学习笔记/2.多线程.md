### 什么是线程？

线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位，可以使用多线程对进行运算提速。

比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒

### 介绍一下线程的生命周期及状态？



![未命名文件.jpg](https://gitee.com/jiajiales/learningNotes/raw/master/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/media/life.jpg)

 **1.创建** 当程序使用new关键字创建了一个线程之后，该线程就处于一个新建状态（初始状态），此时它和其他Java对象一样，仅仅由Java虚拟机为其分配了内存，并初始化了其成员变量值。此时的线程对象没有表现出任何线程的动态特征，程序也不会执行线程的线程执行体。

 **2.就绪** 当线程对象调用了Thread.start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和程序计数器，处于这个状态的线程并没有开始运行，它只是表示该线程可以运行了。从start()源码中看出，start后添加到了线程列表中，接着在native层添加到VM中，至于该线程何时开始运行，取决于JVM里线程调度器的调度(如果OS调度选中了，就会进入到运行状态)。 

**3.运行** 当线程对象调用了Thread.start()方法之后，该线程处于就绪状态。添加到了线程列表中，如果OS调度选中了，就会进入到运行状态 

**4.阻塞** 阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况大概三种：

- 1、**等待阻塞**：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)
- 2、**同步阻塞**：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
- 3、**其他阻塞**：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁）。
- 线程睡眠：Thread.sleep(long millis)方法，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。
- 线程等待：Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。唤醒线程后，就转为就绪（Runnable）状态。
- 线程让步：Thread.yield() 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。
- 线程加入：join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。
- 线程I/O：线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。比如说监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。
- 线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意性的，并在对实现做出决定时发生。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。

**5.死亡** 线程会以以下三种方式之一结束，结束后就处于死亡状态:

- run()方法执行完成，线程正常结束。
- 线程抛出一个未捕获的Exception或Error。
- 直接调用该线程的stop()方法来结束该线程——该方法容易导致死锁，通常不推荐使用

### 线程的sleep、wait、join、yield如何使用？

**sleep**:让线程睡眠，期间会出让cpu，在同步代码块中，不会释放锁

**wait**(必须先获得对应的锁才能调用):让线程进入等待状态,释放当前线程持有的锁资源线程只有在notify 或者notifyAll方法调用后才会被唤醒,然后去争夺锁.

 **join**:线程之间协同方式,使用场景: 线程A必须等待线程B运行完毕后才可以执行,那么就可以在线程A的代码中加入ThreadB.join(); 

**yield**:让当前正在运行的线程回到可运行状态，以允许具有相同优先级的其他线程获得运行的机会。因此，使用yield()的目的是让具有相同优先级的线程之间能够适当的轮换执行。但是，实际中无法保证yield()达到让步的目的，因为，让步的线程可能被线程调度程序再次选中。

### 创建线程有哪些方式？

1.继承Thread类，重写run方法（其实Thread类本身也实现了Runnable接口）

2.实现Runnable接口，重写run方法

3.实现Callable接口，重写call方法（有返回值）

4.使用线程池（有返回值）

**[详解：Java 实现线程的方式有几种方式？带有返回值的线程怎么实现？](https://baijiahao.baidu.com/s?id=1660848743086888990&wfr=spider&for=pc)**



### 什么是守护线程？

在Java中有两类线程：User Thread(用户线程)、Daemon Thread(守护线程) 任何一个守护线程都是整个JVM中所有非守护线程的保姆： 

只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作。Daemon的作用是为其他线程的运行提供便利服务，守护线程最典型的应用就是 GC (垃圾回收器)，它就是一个很称职的守护者。
User和Daemon两者几乎没有区别，唯一的不同之处就在于虚拟机的离开：如果 User Thread已经全部退出运行了，只剩下Daemon Thread存在了，虚拟机也就退出了。 因为没有了被守护者，Daemon也就没有工作可做了，也就没有继续运行程序的必要了。 

**注意事项:** 

(1) thread.setDaemon(true)必须在thread.start()之前设置，否则会出现一个IllegalThreadStateException异常。只能在线程未开始运行之前设置为守护线程。  
(2) 在Daemon线程中产生的新线程也是Daemon的。  
(3) 不要认为所有的应用都可以分配给Daemon来进行读写操作或者计算逻辑，因为这会可能回到数据不一致的状态。

### 什么是线程安全和线程不安全？

**通俗的说：加锁的就是是线程安全的，不加锁的就是是线程不安全的**

### 线程安全

**线程安全: 就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染**。

一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将**集合类分成两组，线程安全和非线程安全的**。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。

### 线程不安全

**线程不安全：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据**

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

### 什么是自旋锁？

#### 基本概念

**自旋锁是SMP架构中的一种low-level的同步机制**。

当线程A想要获取一把自旋锁而该锁又被其它线程锁持有时，线程A会在一个循环中自旋以检测锁是不是已经可用了。

**自**旋**锁需要注意**：

- **由于自旋时不释放CPU，因而持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直在那里自旋，这就会浪费CPU时间。**
- **持有自旋锁的线程在sleep之前应该释放自旋锁以便其它线程可以获得自旋锁**。（正常情况睡觉拿锁）

### 实现自旋锁

 

一个简单的while就可以满足你的要求。

目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大。

```java
public class MyWaitNotify3{
 
  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;
 
  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }
 
  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
```



### 什么是死锁？

什么是死锁？
所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 因此我们举个例子来描述，如果此时有一个线程A，按照先锁a再获得锁b的的顺序获得锁，而在此同时又有另外一个线程B，按照先锁b再锁a的顺序获得锁。如下图所示：

![img](https://img-blog.csdn.net/20180922173936964?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



产生死锁的原因？
可归结为如下两点：

a. 竞争资源

系统中的资源可以分为两类：
1.可剥夺资源，是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺，CPU和主存均属于可剥夺性资源；
2.另一类资源是不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。

> 产生死锁中的竞争资源之一指的是竞争不可剥夺资源（例如：系统中只有一台打印机，可供进程P1使用，假定P1已占用了打印机，若P2继续要求打印机打印将阻塞）

> 产生死锁中的竞争资源另外一种资源指的是竞争临时资源（临时资源包括硬件中断、信号、消息、缓冲区内的消息等），通常消息通信顺序进行不当，则会产生死锁
> b. 进程间推进顺序非法

> 若P1保持了资源R1,P2保持了资源R2，系统处于不安全状态，因为这两个进程再向前推进，便可能发生死锁

> 例如，当P1运行到P1：Request（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2：Request（R1）时，也将因R1已被P1占用而阻塞，于是发生进程死锁

#### 死锁产生的4个必要条件？

产生死锁的必要条件：

1.互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。 

2.请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。 

3.不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。

4.环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链。

#### 解决死锁的基本方法

预防死锁：
资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）

只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请保持条件）

可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）

资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）  
1、以确定的顺序获得锁

如果必须获取多个锁，那么在设计的时候需要充分考虑不同线程之前获得锁的顺序。按照上面的例子，两个线程获得锁的时序图如下：

![img](https://img-blog.csdn.net/20180922174807514?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

 如果此时把获得锁的时序改成：

![img](https://img-blog.csdn.net/20180922174829303?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

 那么死锁就永远不会发生。 针对两个特定的锁，开发者可以尝试按照锁对象的hashCode值大小的顺序，分别获得两个锁，这样锁总是会以特定的顺序获得锁，那么死锁也不会发生。问题变得更加复杂一些，如果此时有多个线程，都在竞争不同的锁，简单按照锁对象的hashCode进行排序（单纯按照hashCode顺序排序会出现“环路等待”），可能就无法满足要求了，这个时候开发者可以使用银行家算法，所有的锁都按照特定的顺序获取，同样可以防止死锁的发生，该算法在这里就不再赘述了，有兴趣的可以自行了解一下。

2、超时放弃

当使用synchronized关键词提供的内置锁时，只要线程没有获得锁，那么就会永远等待下去，然而Lock接口提供了boolean tryLock(long time, TimeUnit unit) throws InterruptedException方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。 还是按照之前的例子，时序图如下：

![img](https://img-blog.csdn.net/20180922174924551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



避免死锁:

预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。

银行家算法：首先需要定义状态和安全状态的概念。系统的状态是当前给进程分配的资源情况。因此，状态包含两个向量Resource（系统中每种资源的总量）和Available（未分配给进程的每种资源的总量）及两个矩阵Claim（表示进程对资源的需求）和Allocation（表示当前分配给进程的资源）。安全状态是指至少有一个资源分配序列不会导致死锁。**当进程请求一组资源时，假设同意该请求，确定其结果是否还处于安全状态。如果是，同意这个请求；如果不是，阻塞该进程直到同意该请求后系统状态仍然是安全的**。 

检测死锁
首先为每个进程和每个资源指定一个唯一的号码；   
然后建立资源分配表和进程等待表。  
解除死锁:
当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：  
剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；
撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。
死锁检测  
1、Jstack命令

jstack是java虚拟机自带的一种堆栈跟踪工具。jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。 Jstack工具可以用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。

2、JConsole工具

Jconsole是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。



### 高并发下如何保证接口的幂等性？

https://mp.weixin.qq.com/s/7P2KbWjjX5YPZCInoox-xQ



## 什么是CAS？

**CAS（compare and swap）的缩写，中文翻译成比较并交换**。

CAS 不通过JVM,直接利用java本地方 JNI（Java Native Interface为JAVA本地调用）,直接调用CPU 的汇编指令指令,**提供硬件级别的原子操作**。。

**利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法,实现原子操作。其它原子操作都是利用类似的特性完成的**。

整个java.util.concurrent都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。

**CAS是项乐观锁技术**，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

### CAS应用

CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

```java
// 对象、对象的地址、预期值、修改值
public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
```



### CAS优点

确保对内存的读-改-写操作都是原子操作执行

### CAS缺点

CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。

**1.开销大**：在并发量比较高的情况下，如果反复尝试更新某个变量，却又一直更新不成功，会给CPU带来较大的压力

**2.ABA问题**：当变量从A修改为B在修改回A时，变量值等于期望值A，但是无法判断是否修改，CAS操作在ABA修改后依然成功。  
- **如何避免**：Java提供了AtomicStampedReference和AtomicMarkableReference来解决。AtomicStampedReference通过包装[E,Integer]的元组来对对象标记版本戳stamp，对于ABA问题其解决方案是加上版本号，即在每个变量都加上一个版本号，每次改变时加1，即A —> B —> A，变成1A —> 2B —> 3A。

**3.不能保证代码块的原子性**：CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。

### 总结

1. **使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用**。
2. **synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS**。



**synchronized锁升级**：https://blog.csdn.net/heightyzy/article/details/108686132

![锁升级.png](https://img-blog.csdnimg.cn/img_convert/68f0feb3c068681b242fe78eb287d601.png)

- 注意点
  - 锁的状态只有4种，无锁->偏向锁->轻量级锁->重量级锁
  - 升级过程不可逆，不同阶段通过从轻到重的方式获取锁
  - 自旋这个操作是通过线程死循环，而防止被阻塞，试图避免用户态和内核态的切换，所以本身不属于锁的状态，是配合轻量级锁使用的一种方式



### CAS 原子操作在concurrent包的实现

由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：

- A线程写volatile变量，随后B线程读这个volatile变量。
- A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。

Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：  
首先，声明共享变量为volatile；然后，使用CAS的原子条件更新来实现线程之间的同步；  
同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。

AQS，非阻塞数据结构和原子变量类（Java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：

 

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC8zLzE4LzE2MjM4ZTJjNmMyZWFhZWE?x-oss-process=image/format,png)

 

AQS没有锁之类的概念，它有个state变量，是个int类型，在不同场合有着不同含义。

AQS围绕state提供两种基本操作“获取”和“释放”，有条双向队列存放阻塞的等待线程，并提供一系列判断和处理方法，简单说几点：

- state是独占的，还是共享的；
- state被获取后，其他线程需要等待；
- state被释放后，唤醒等待线程；
- 线程等不及时，如何退出等待。

至于线程是否可以获得state，如何释放state，就不是AQS关心的了，要由子类具体实现。

**AQS中还有一个表示状态的字段state，例如ReentrantLocky用它表示线程重入锁的次数，Semaphore用它表示剩余的许可数量，FutureTask用它表示任务的状态。对state变量值的更新都采用CAS操作保证更新操作的原子性**。

AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个类只有一个变量：exclusiveOwnerThread，表示当前占用该锁的线程，并且提供了相应的get，set方法。

 

 

### 什么是乐观锁和悲观锁？

悲观锁和乐观锁并不是某个具体的“锁”而是一种并发编程的基本概念。乐观锁和悲观锁最早出现在数据库的设计当中，后来逐渐被 Java 的并发包所引入。

### 悲观锁

认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观地认为，不加锁的并发操作一定会出问题。

Java在JDK1.5之前都是靠synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。独占锁其实就是一种悲观锁，所以可以说synchronized是悲观锁。

### 乐观锁

正好和悲观锁相反，它获取数据的时候，并不担心数据被修改，每次获取数据的时候也不会加锁，只是在更新数据的时候，通过判断现有的数据是否和原数据一致来判断数据是否被其他线程操作，如果没被其他线程修改则进行数据更新，如果被其他线程修改则不进行数据更新。

乐观锁（ Optimistic Locking）其实是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。memcached使⽤了cas乐观锁技术保证数据⼀致性。

### 什么是AQS？

**AQS**是 **AbstractQueuedSynchronizer**的简称，即 **抽象队列同步器** :

抽象：抽象类，只实现⼀些主要逻辑，有些⽅法由⼦类实现；
队列：使⽤先进先出（FIFO）队列存储数据；
同步：实现了同步的功能。

**AQS是⼀个⽤来构建锁和同步器的框架**，**使⽤AQS能简单且⾼效地构造出应⽤⼴泛的同步器**

事实上concurrent包内许多类都是基于AQS构建，**例如ReentrantLock**，Semaphore，CountDownLatch，ReentrantReadWriteLock，**FutureTask**等。AQS解决了在实现同步容器时设计的大量细节问题。

**AQS使用一个FIFO的双向队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护一个等待状态waitStatus。**

![img](https://upload-images.jianshu.io/upload_images/9307436-f740e1874ed9a45a.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)



**AQS类本身实现的是一个排队和阻塞的机制**，⽐如具体线程等待队列的维护（如获取资源失败⼊队/唤醒出队等）。它内部使⽤了⼀个**先进先出（FIFO）的双端队列，并使⽤了两个指针head和tail⽤于标识队列的头部和尾部**。

**AQS数据结构如图：** 队列并不是直接储存线程，⽽是储存拥有线程的节点。

![img](https://upload-images.jianshu.io/upload_images/25399192-f84f39d68447e17a.png?imageMogr2/auto-orient/strip|imageView2/2/w/758/format/webp)



**核心数据结构：双向链表 + state(锁状态)**


### volatile原理是什么？

此题考察的是`volatile`这个关键字。可以从`volatile`的作用和`volatile`的原理这三个方面来进行回答。**volatile只能保证变量的可见性、有序性，但是不能保证原子性。**

题目回答	
**volatile的作用**  
1.保证内存可见性：一个线程对一个volatile变量的修改，对于其它线程来说是可见的。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。   
2.禁止指令重排序  
**volatile的原理**  
**可见性实现**  
线程本身并不直接与主内存进行数据的交互，而是通过线程的工作内存来完成相应的操作。这也是导致线程间数据不可见的本质原因。对volatile变量的写操作与普通变量的主要区别有两点：

修改volatile变量时会强制将修改后的值刷新的主内存中。  
修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。  
**有序性实现**  
volatile是通过编译器在生成字节码时，在指令序列中添加“内存屏障”来禁止指令重排序的。多核处理器需使用内存屏障指令来确保一致性。  

属性添加了volatile关键字之后，编译之后的属性会被添加ACC_VOLATILE访问标记。  
获取和设置静态属性的字节码是putstatic和getstatic，获取成员变量的字节码是putfield和getfield，在这些字节码的代码中，会先判断字段是否被ACC_VOLATILE修饰，即判断字段是否为volatile字段，若是，则会在操作之后，加上内存屏障。 添加内存屏障之后的代码，内存屏障之后的代码会在内存屏障之前的代码执行完之后再执行。 这样就保证了有序性。





### 什么是原⼦操作？在Java Concurrency API中有哪些原⼦类(atomic classes)？

1. 原⼦操作是指⼀个不受其他操作影响的操作任务单元。原⼦操作是在多线程环境下避免数据不⼀致必须的⼿段。
2. int++并不是⼀个原⼦操作，所以当⼀个线程读取它的值并加1时，另外⼀个线程有可能会读到之前的值，这就会引发错误。
3. 为了解决这个问题，必须保证增加操作是原⼦的，在JDK1.5之前我们可以使⽤同步技术来做到这⼀点。

到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以自动的保证对于他们的操作是原⼦的并且不需要使⽤同步。

### 什么是同步容器和并发容器的实现？

#### 同步容器

1、主要代表有Vector和Hashtable，以及Collections.synchronizedXxx等。

2、锁的粒度为当前对象整体。

3、迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。

##### 并发容器

1、主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。

2、锁的粒度是分散的、细粒度的，即读和写是使⽤不同的锁。

3、迭代器具有弱⼀致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。

> ConcurrentHashMap 采⽤分段锁技术，同步容器中，是⼀个容器⼀个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若⼲段，每段维护⼀个锁，以达到⾼效的并发访问；

**JDK 7 ConcurrentHashMap**  
1.实现原理：  
ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表,同时又是一个ReentrantLock（Segment继承了ReentrantLock）。  
2.内部结构：  
ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：

![img](https://imgconvert.csdnimg.cn/aHR0cDovL3AzLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlL2VlZWQ2NTk5OWRkYzRkYTA5YTc0ODk4NmViYjY4ZmE3?x-oss-process=image/format,png)

从上面的结构我们可以了解到，ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。 第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。

3.该结构的优劣势

**坏处**  
这一种结构的带来的副作用是Hash的过程要比普通的HashMap要长

**好处**  
写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，在最理想的情况下，ConcurrentHashMap可以最高同时支持Segment数量大小的写操作（刚好这些写操作都非常平均地分布在所有的Segment上）。

所以，通过这一种结构，ConcurrentHashMap的并发能力可以大大的提高。

**JDK 8 ConcurrentHashMap**

JDK8中ConcurrentHashMap参考了JDK8 HashMap的实现，采用了数组+链表+红黑树的实现方式来设计，内部大量采用CAS操作。

JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK1.7中的分段锁思想。

Node：保存key，value及key的hash值的数据结构。其中value和next都用volatile修饰，保证并发的可见性。

Java8 ConcurrentHashMap结构基本上和Java8的HashMap一样，不过保证线程安全性。

 

在JDK8中ConcurrentHashMap的结构，由于引入了红黑树，使得ConcurrentHashMap的实现非常复杂，我们都知道，红黑树是一种性能非常好的二叉查找树，其查找性能为O（logN），但是其实现过程也非常复杂，而且可读性也非常差，DougLea的思维能力确实不是一般人能比的，早期完全采用链表结构时Map的查找时间复杂度为O（N），JDK8中ConcurrentHashMap在链表的长度大于某个阈值的时候会将链表转换成红黑树进一步提高其查找性能。

![并发编程系列：ConcurrentHashMap的实现原理(JDK1.7和JDK1.8)](https://imgconvert.csdnimg.cn/aHR0cDovL3A5OS5wc3RhdHAuY29tL2xhcmdlL3BnYy1pbWFnZS8wMzNhZDQ1MmM2NTM0N2JjYWE3ZjNjNGE2MzAyNzQzMw?x-oss-process=image/format,png)

**总结**

其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。

* 1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。
* 2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。
* 3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。
* 4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。
* 5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。 







### 什么是多线程？优缺点？

**什么是多线程？**

多线程：是指从软件或者硬件上实现多个线程的并发技术。

**多线程的好处：**

1. 使用多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视屏的下载
2. 发挥多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好

**多线程的缺点：**

1. 大量的线程降低代码的可读性；
2. 更多的线程需要更多的内存空间
3. 当多个线程对同一个资源出现争夺时候要注意线程安全的问题。

# 什么是多线程的上下文切换？



1、多线程：是指从软件或者硬件上实现多个线程的并发技术。  
2、多线程的好处：

> 使⽤多线程可以把程序中占据时间⻓的任务放到后台去处理，如图⽚、视屏的下载 发挥多核处理器的优势，并发执⾏让系统运⾏的更快、更流畅，⽤户体验更好

3、多线程的缺点：

> ⼤量的线程降低代码的可读性；更多的线程需要更多的内存空间, 当多个线程对同⼀个资源出现争夺时候要注意线程安全的问题。

4、多线程的上下⽂切换：

> CPU通过时间⽚分配算法来循环执⾏任务，当前任务执⾏⼀个时间⽚后会切换到下⼀个任务。但是，在切换前会保存上⼀个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态。





### ThreadLocal的设计理念与作用？



Java中的ThreadLocal类允许我们创建只能被同⼀个线程读写的变量。因此，如果⼀段代码含有⼀个ThreadLocal变量的引⽤，即使两个线程同时执⾏这段代码，它们也⽆法访问到对⽅的ThreadLocal变量。

**概念**：  
线程局部变量。在并发编程的时候，成员变量如果不做任何处理其实是线程不安全的，各个线程都在操作同⼀个变量，显然是不⾏的，并且我们也知道volatile这个关键字也是不能保证线程安全的。那么在有⼀种情况之下，我们需要满⾜这样⼀个条件：变量是同⼀个，但是每个线程都使⽤同⼀个初始值，也就是使⽤同⼀个变量的⼀个新的副本。这种情况之下ThreadLocal就⾮常适⽤，⽐如说DAO的数据库连接，我们知道DAO是单例的，那么他的属性Connection就不是⼀个线程安全的变量。⽽我们每个线程都需要使⽤他，并且各自使⽤各自的。这种情况，ThreadLocal就⽐较好的解决了这个问题。  
**原理**：
* Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap。

* ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。

* 每个线程在往ThreadLocal里设置值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。

**实现机制**：每个Thread对象内部都维护了⼀个ThreadLocalMap这样⼀个ThreadLocal的Map，可以存放若⼲个 ThreadLocal。

![img](https://inews.gtimg.com/newsapp_bt/0/12171948806/1000)



 **ThreadLocal的应用场景**

* 1、方便同一个线程使用某一对象，避免不必要的参数传递；
* 2、线程间数据隔离（每个线程在自己线程里使用自己的局部变量，各线程间的ThreadLocal对象互不响）；

线程隔离的秘密，就在于ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。

* 3、获取数据库连接、Session、关联ID（比如日志的uniqueID，方便串起多个日志）；

* 4、其中spring中的事务管理器就是使用的ThreadLocal：

Spring的事务管理器通过AOP切入业务代码，在进入业务代码前，会依据相应的事务管理器提取出相应的事务对象，假如事务管理器是DataSourceTransactionManager，就会从DataSource中获取一个连接对象，通过一定的包装后将其保存在ThreadLocal中。而且Spring也将DataSource进行了包装，重写了当中的getConnection()方法，或者说该方法的返回将由Spring来控制，这样Spring就能让线程内多次获取到的Connection对象是同一个。

### ThreadLocal有哪些内存泄露问题，如何避免？

每个Thread都有一个ThreadLocal.ThreadLocalMap的map，该map的key为ThreadLocal实例，它为一个弱引用，我们知道弱引用有利于GC回收。当ThreadLocal的key == null时，GC就会回收这部分空间，但是value却不一定能够被回收，因为他还与Current Thread存在一个强引用关系，如下

![img](https://inews.gtimg.com/newsapp_bt/0/12171949025/1000)弱引用：只要垃圾回收机制一运行，不管JVM的内存空间是否充足，都会回收该对象占用的内存。

弱引用比较容易被回收。因此，如果ThreadLocal（ThreadLocalMap的Key）被垃圾回收器回收了，但是因为ThreadLocalMap生命周期和Thread是一样的，它这时候如果不被回收，就会出现这种情况：ThreadLocalMap的key没了，value还在，这就会**「造成了内存泄漏问题」**。

如何 **「解决内存泄漏问题」**？使用完ThreadLocal后，及时调用remove()方法释放内存空间。



### ThreadPool（线程池）用法与优势？

#### 为什么要用线程池:

1. 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
2. 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。
3. Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。

#### new Thread 缺点

1. 每次new Thread新建对象性能差。
2. 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。
3. 缺乏更多功能，如定时执行、定期执行、线程中断。

#### ThreadPool 优点

减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务

可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)

- 减少在创建和销毁线程上所花的时间以及系统资源的开销
- 如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存

**Java提供的四种线程池的好处在于**：

1. 重用存在的线程，减少对象创建、销毁的开销，提高性能。
2. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。
3. 提供定时执行、定期执行、单线程、并发数控制等功能。

### 比较重要的几个类：

| 类                          | 描述                                                         |
| :-------------------------- | :----------------------------------------------------------- |
| ExecutorService             | 真正的线程池接口。                                           |
| ScheduledExecutorService    | 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。    |
| ThreadPoolExecutor          | ExecutorService的默认实现。                                  |
| ScheduledThreadPoolExecutor | 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 |

要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。

### Executors提供四种线程池

**newCachedThreadPool**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

**newFixedThreadPool** 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。

**newScheduledThreadPool** 创建一个定长线程池，支持定时及周期性任务执行。

**newSingleThreadExecutor** 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

### 一般都不用Executors提供的线程创建方式

**使用ThreadPoolExecutor创建线程池**

**ThreadPoolExecutor的构造函数**

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

docc
```

### 线程池核心参数：

1. **corePoolSize**核心线程数大小，当线程数<corePoolSize ，会创建线程执行runnable
2. **maximumPoolSize** 最大线程数， 当线程数 >= corePoolSize的时候，会把runnable放入workQueue中
3. **keepAliveTime** 保持存活时间，当线程数大于corePoolSize的空闲线程能保持的最大时间。
4. **unit** 时间单位
5. **workQueue** 保存任务的阻塞队列
6. **threadFactory** 创建线程的工厂
7. **handler** 拒绝策略

### 任务执行顺序：

1. 当线程数小于corePoolSize时，创建线程执行任务。
2. 当线程数大于等于corePoolSize并且workQueue没有满时，放入workQueue中
3. 线程数大于等于corePoolSize并且当workQueue满时，新任务新建线程运行，线程总数要小于maximumPoolSize
4. 当线程总数等于maximumPoolSize并且workQueue满了的时候执行handler的rejectedExecution。也就是拒绝策略。

Java线程池的核心工作流程如下图所示。

![图片](https://mmbiz.qpic.cn/mmbiz_png/2hHcUic5FEwGul3icvjVIxUPicOOVx3pnTiaibsEVfxgSuxcYsRMgxGXhsS8ACspyK7djQrQGd3GicoZBkXiaLuRzV3Sw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





**为什么先添加队列而不是先创建最大线程**

* 在创建新线程的时候，是要获取全局锁的，这时候其他线程会被阻塞，影响整体效率。
* 在核心线程已满时，如果任务继续增加那么放在队列中，等队列满了而任务还在增加那么就要创建临时线程了，这样代价低。
  

**重点来啦：**

我们说设置线程池大小，主要是设置最大线程的数量，即**maxPoolSize**参数的大小。那这个应该设置成多少合适呢？首先我们要分两种情况，即CPU密集型和IO密集型任务。

**CPU密集型任务**：即需要大量计算的任务，因为计算是由CPU来完成的，所以称之为CPU密集型任务。这个时候设置为**CPU核心数+1**就可以了。

**IO密集型任务**：即需要通过网络来交互的任务，通常是指数据库数据交互、文件上传下载、网络数据传输等任务。这个时候需要设置为**CPU核心数\*2。**但是实际情况中可以通过自己的测试来设置合理的数值，通过与大牛的交流得知，这个数值可以设置为**CPU核心数/（1-阻塞系数），**阻塞系数一般在**0.8~0.9**之间。比如8核CPU可以设置为：8/（1-0.9）=80。

注意：在java中获取CPU核心数可以用以下代码：

```java
Runtime.getRuntime().availableProcessors();1.
```

 

### ThreadPoolExecutor默认有四个拒绝策略：

1. `ThreadPoolExecutor.AbortPolicy()` 直接抛出异常RejectedExecutionException
2. `ThreadPoolExecutor.CallerRunsPolicy()` 直接调用run方法并且阻塞执行
3. `ThreadPoolExecutor.DiscardPolicy()` 直接丢弃后来的任务
4. `ThreadPoolExecutor.DiscardOldestPolicy()` 丢弃在队列中队首的任务

当然可以自己继承 RejectedExecutionHandler 来写拒绝策略.



## 什么是阻塞队列？

阻塞队列是一个在队列基础上又支持了两个附加操作的队列。

2个附加操作：

支持阻塞的**插入**方法：队列满时，队列会阻塞插入元素的线程，直到队列不满。

支持阻塞的**移除**方法：队列空时，获取元素的线程会等待队列变为非空。

 **阻塞队列的作用**

* 一般的队列只能是有限长度的缓冲区，一旦超出缓冲长度，就无法保留了。阻塞队列通过阻塞可以保留住当前想要继续入队的任务。
* 阻塞队列可以在队列中没有任务时，阻塞想要获取任务的线程，使其进入wait状态，释放cpu资源。
* 阻塞队列带有阻塞和唤醒的功能，不需要额外处理，无任务执行时，线程池利用阻塞队列的take方法挂起，从而维持核心线程的存活，不至于一直占用cpu资源。

### 阻塞队列的应用场景

阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。简而言之，阻塞队列是生产者用来存放元素、消费者获取元素的容器。

### 几个方法

在阻塞队列不可用的时候，上述2个附加操作提供了四种处理方法

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| :------------ | :-------- | :--------- | :------- | :----------------- |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     | 不可用   | 不可用             |

### JAVA里的阻塞队列

JDK 7 提供了7个阻塞队列，如下

1、**ArrayBlockingQueue** 数组结构组成的有界阻塞队列。

此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。

2、**LinkedBlockingQueue**一个由链表结构组成的有界阻塞队列，此队列按照先出先进的原则对元素进行排序

3、**PriorityBlockingQueue**支持优先级的无界阻塞队列

4、**DelayQueue**支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素

5、**SynchronousQueue**不存储元素的阻塞队列，每一个put必须等待一个take操作，否则不能继续添加元素。并且他支持公平访问队列。

6、**LinkedTransferQueue**由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，多了tryTransfer和transfer方法

**transfer方法**

如果当前有消费者正在等待接收元素（take或者待时间限制的poll方法），transfer可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的tail节点，并等到该元素被消费者消费了才返回。

**tryTransfer方法**

用来试探生产者传入的元素能否直接传给消费者。，如果没有消费者在等待，则返回false。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。

7、**LinkedBlockingDeque**链表结构的双向阻塞队列，优势在于多线程入队时，减少一半的竞争。

### 比较及适用场景

* 如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；

* 如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；

* 如果需要对队列进行排序，选择PriorityBlockingQueue；

* 如果需要一个快速交换的队列，选择SynchronousQueue；

* 如果需要对队列中的元素进行延时操作，则选择DelayQueue。

### 双端队列

主要代表有ArrayDeque和LinkedBlockingDeque。意义：正如阻塞队列适用于生产者消费者模式，双端队列同样适用与另一种模式，即工作密取。在生产者-消费者设计中，所有消费者共享一个工作队列，而在工作密取中，每个消费者都有各自的双端队列。如果一个消费者完成了自己双端队列中的全部工作，那么他就可以从其他消费者的双端队列末尾秘密的获取工作。具有更好的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。在大多数时候，他们都只是访问自己的双端队列，从而极大的减少了竞争。当工作者线程需要访问另一个队列时，它会从队列的尾部而不是头部获取工作，因此进一步降低了队列上的竞争。适用于：网页爬虫等任务中





###  Concurrent包⾥的其他东⻄：ArrayBlockingQueue、CountDownLatch等等。

1、ArrayBlockingQueue 数组结构组成的有界阻塞队列。

2、CountDownLatch 允许⼀个或多个线程等待其他线程完成操作；join⽤于让当前执⾏线程等待join线程执⾏结束。其实现原理是不停检查join线程是否存活，如果join线程存活则让当前线程永远wait。

#### countDownLatch简介

##### 1.背景：

- countDownLatch是在java1.5被引入，跟它一起被引入的工具类还有CyclicBarrier、Semaphore、concurrentHashMap和BlockingQueue。
- 存在于java.util.cucurrent包下。
- 实现主线程等待子线程执行

##### 2.概念

- countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。
- 是通过一个计数器来实现的，计数器的初始值是线程的数量。每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。

##### 3.源码

- countDownLatch类中只提供了一个构造器：

```java
//参数count为计数值
public CountDownLatch(int count) {  };  
```

- 类中有三个方法是最重要的：

```java
//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行
public void await() throws InterruptedException { };   
//和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行
public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  
//将count值减1
public void countDown() { };  
```

​     

##### 4.实现

引入countDownLatch，实现主线程等待子线程执行

```java
package com.liuzhou.core.test;

import java.util.concurrent.CountDownLatch;

public class MultiThreadToCountDownLatch
{
    public static void main(String[] args) throws InterruptedException
    {
        //1、 创建CountDownLatch 对象， 设定需要计数的子线程数目
        final CountDownLatch latch = new CountDownLatch(3);
        System.out.println("主线程开始执行....");
        for (int i = 0; i < 3; i++)
        {
            new Thread()
            {
                @Override
                public void run()
                {
                    try
                    {
                        System.out.println(Thread.currentThread().getName() + "  开始执行存储过程..");
                        Thread.sleep(2000);
                        System.out.println(Thread.currentThread().getName() + "  存储过程执行完毕...");
                        //2、子线程执行完毕，计数减1
                        latch.countDown();
                    }
                    catch (InterruptedException e)
                    {
                        e.printStackTrace();
                    }
                }

                ;
            }.start();

        }
        System.out.println("等待子线程执行完毕...");
        //3、 当前线程挂起等待
        latch.await();
        System.out.println("主线程执行完毕....");
    }


}
```



执行结果：

```
主线程开始执行....
等待子线程执行完毕...
Thread-0  开始执行存储过程..
Thread-1  开始执行存储过程..
Thread-2  开始执行存储过程..
Thread-1  存储过程执行完毕...
Thread-0  存储过程执行完毕...
Thread-2  存储过程执行完毕...
主线程执行完毕....
```



这时会发现 



### synchronized和ReentrantLock的区别？



![image](https://img2020.cnblogs.com/other/268922/202003/268922-20200327191054403-345194463.jpg)

![img](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg-blog.csdnimg.cn%2F2020071210243333.png%3Fx-oss-process%3Dimage%2Fwatermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5ncWlhbmcxODA%3D%2Csize_16%2Ccolor_FFFFFF%2Ct_70&refer=http%3A%2F%2Fimg-blog.csdnimg.cn&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1648085768&t=ba741ece801321970be24b98c3413c96)

java在编写多线程程序时，为了保证线程安全，需要对数据同步，经常用到两种同步方式就是Synchronized和重入锁ReentrantLock。

### 1.基础知识

- **可重入锁**。可重入锁是指同一个线程可以多次获取同一把锁。**ReentrantLock和synchronized都是可重入锁**。
- **可中断锁**。可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。synchronized是不可中断锁，而ReentrantLock则提供了中断功能。
- **公平锁与非公平锁**。公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。
- **CAS操作(CompareAndSwap)**。CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

### 2.Synchronized

synchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而synchronized也有一定的局限性

例如：

1. 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。
2. 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。

### 3.synchronized (this)原理

涉及两条指令：

（1）**monitorenter**

 每个对象有一个**监视器锁**（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：  

1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。  
2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1。  
3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。



（2）**monitorexit**  
执行monitorexit的线程必须是objectref所对应的monitor的所有者。  
指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor 的所有权。



通过这两段描述，我们应该能很清楚的看出synchronized的实现原理，synchronized的语义底层是通过一个monitor的对象来完成。  
其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

### 4.ReentrantLock

ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。

代码示例

```java
private Lock lock = new ReentrantLock();
public void test(){
 lock.lock();
 try{
 doSomeThing();
 }catch (Exception e){
 // ignored
 }finally {
 lock.unlock();
 }
}
```

- **lock**(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁
- **tryLock()**, 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false；
- **tryLock(long timeout,TimeUnit unit)**，如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false；
- **lockInterruptibly**:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断

**ReentrantLock 一些特性**

1. **等待可中断避免，出现死锁的情况**（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false）
2. **公平锁与非公平锁**多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，**ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁**，但公平锁表现的性能不是很好。

公平锁：线程获取锁的顺序和调用lock的顺序一样，FIFO；

非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。

**Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作**。

#### ReenTrantLock实现的原理：

简单来说，**ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁**。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

#### 总结一下

在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

**synchronized**：

在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。

**ReentrantLock**:

ReentrantLock用起来会复杂一些。在基本的加锁和解锁上，两者是一样的，所以无特殊情况下，推荐使用synchronized。ReentrantLock的优势在于它更灵活、更强大，增加了轮训、超时、中断等高级功能。

ReentrantLock默认**使用非公平锁是基于性能考虑**，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。





### Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。

它的优势有：
- 可以使锁更公平
- 可以使线程在等待锁的时候响应中断
- 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
- 可以在不同的范围，以不同的顺序获取和释放锁

### Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？

同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。

**而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性**

### ConcurrentHashMap的并发度是什么？

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势

### ReentrantReadWriteLock读写锁的使用

Lock比传统线程模型中的synchronized方式更加面向对象，与生活中的锁类似，锁本身也应该是一个对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个Lock对象。

**读写锁**：**分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可**。**如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁**；

如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！

**ReentrantReadWriteLock会使用两把锁来解决问题，一个读锁，一个写锁**

**线程进入读锁的前提条件**：

- **没有其他线程的写锁**
- **没有写请求或者有写请求，但调用线程和持有锁的线程是同一个**

**线程进入写锁的前提条件**：

- **没有其他线程的读锁**
- **没有其他线程的写锁**
- 读锁的重入是允许多个申请读操作的线程的，而写锁同时只允许单个线程占有，该线程的写操作可以重入。
- 如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。
- 对于同时占有读锁和写锁的线程，如果完全释放了写锁，那么它就完全转换成了读锁，以后的写操作无法重入，在写锁未完全释放时写操作是可以重入的。
- 公平模式下无论读锁还是写锁的申请都必须按照AQS锁等待队列先进先出的顺序。非公平模式下读操作插队的条件是锁等待队列head节点后的下一个节点是SHARED型节点，写锁则无条件插队。
- 读锁不允许newConditon获取Condition接口，而写锁的newCondition接口实现方法同ReentrantLock。

### 同步编程与异步编程

Java异步编程极大的节省了主程序执行时间，提升了计算资源利用效率，是Java高级工程师的必备技能之一。本文围绕什么是异步，异步解决了什么问题，怎么异步编程来展开。

![img](https://pic1.zhimg.com/80/v2-dfcc9d2fc1750a29820811396d85af0c_720w.jpg)

#### **什么是异步**

在解释异步编程之前，我们先来看同步编程的定义。同步编程，即是一种典型的请求-响应模型，当请求调用一个函数或方法后，需等待其响应返回，然后执行后续代码。同步的最大特征便是「**有序**」，当各个过程都执行完毕，最后返回结果。如图

![img](https://pic2.zhimg.com/80/v2-f2784dd82159fd16e2896602a2303ded_720w.jpg)

异步编程则是只发送了调用的指令，调用者无需等待被调用的方法执行完毕，而是继续执行下面的流程。在一个多处理器或多核的环境中，异步调用是真正的并行执行。如图

![img](https://pic3.zhimg.com/80/v2-a1efa71ee1e605b1249c2ab28e254e7a_720w.jpg)

#### **异步解决了什么问题**

Java异步编程的目的是充分利用计算机CPU资源，不让主程序阻塞在某个长时间运行的任务上，从而优化主程序的执行时间。这类耗时的任务可以是 IO操作、远程调用以及高密度计算任务。

如果不使用多线程异步编程，我们的系统就会阻塞在耗时的子任务上，会导致极大延长完成主函数任务的时间。Java以及提供了丰富的API，来完成多线程异步编程。从NIO、Future，CompletableFuture、Fork/Join以及parrallelStream。另外google的guava框架提供了ListenableFuture和Spring的@Async来简化异步编程。

#### **怎么异步编程**

本文会使用最常用的 Spring @Async说明异步编程。

![img](https://pic3.zhimg.com/80/v2-e6211095a8fa59f3d132f06da035d2d2_720w.jpg)

##### **@Async异步调用**

- @Async也是通过AOP（切面）实现的，与@Transactional相同
- 添加@Async注释的方法必须是public。因为AOP的本质是动态代理，动态代理要求方法必须是public
- @Async必须是跨类调用，原因也是同类直接调用无法被动态代理
- 需要添加@EnableAsync注解

@Async异步调用分为两种，一种是无返回值调用，一种是有返回值调用。我们先来看最简单的无返回值调用。

TestAsyncService 调用 AsyncService中的 testAsyncSimple函数

```java
public class TestAsyncService {
    private final AsyncService asyncService;

    public TestAsyncService(AsyncService asyncService) {
        this.asyncService = asyncService;
    }

    public void testAsyncSimple() throws InterruptedException {
        System.out.println("-----start-----");
        asyncService.testAsyncSimple();
        System.out.println("-----end-----");
    }
}

    @Async
    public void testAsyncSimple() throws InterruptedException {
        Thread.sleep(1000);
        System.out.println("async success");
    }
```

单元测试

```java
@SpringBootTest
@RunWith(SpringRunner.class)
@Slf4j
class TestAsyncServiceTest {

    @Autowired
    private TestAsyncService testAsyncService;

    @Test
    void testAsyncSimple() throws InterruptedException {
        testAsyncService.testAsyncSimple();

        Thread.sleep(5000); //阻塞测试用例，等待异步调用结束
    }
}
```

测试结果, end被打印出来说明主程序已经跑完。而 end在 async success之前打印出来，说明 testAsyncSimple函数确实是异步完成。

```text
-----start-----
-----end-----
-----async success-----
```

有返回值调用需要用到`Future`类。简单地说，Future类表示异步计算的未来结果 - 这个结果最终将在处理完成后出现在Future中。换句话说，Future表示**在未来某个时间点获取执行结果**，返回数据类型可以自定义。

我们先定义一个异步函数，它在3秒后将返回一个「hello world」字符串。

```java
    @Async
    public Future<String> testAsyncWithResult() throws InterruptedException {
        Thread.sleep(3000);
        return new AsyncResult<String>("hello world !!!!");
    }
```

在测试函数中定义 `Future` 接受未来某个时间点返回的「hello world」。`while (true)`阻塞线程等待`Future`返回，`future.isDone()`确认异步线程是否结束，如果结束，通过`future.get()`获取返回值。当然，你也有可能会获得一个`exception`异常。

```java
public String testAsyncWithResult() throws ExecutionException, InterruptedException {
        Future<String> future = asyncService.testAsyncWithResult();
        while (true) {
            if (future.isDone()) {
                System.out.println("Result from asynchronous process - " + future.get());
                return future.get();
            }
            System.out.println("Continue doing something else. ");
        }
    }
```

### **@Async线程池**

默认情况下，Spring 使用 `SimpleAsyncTaskExecutor`初始化线程池。每次执行客户提交给它的任务时，它会启动新的线程，并允许开发者控制并发线程的上限（concurrencyLimit），从而起到一定的资源节流作用。默认时，concurrencyLimit取值为-1，即不启用资源节流。

```java
    @Async
    public void testAsyncSimple() {}
```

@Async也支持使用指定线程池，你可以指定线程池的各项参数，如下。

```java
@Configuration
@EnableAsync
public class ThreadPoolConfig {

    @Bean(ConfigConstant.TEST_EXECUTOR)
    @Primary
    public TaskExecutor testTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        initTaskExecutor(ConfigConstant.TEST_EXECUTOR, executor);
        return executor;
    }

    private ThreadPoolTaskExecutor initTaskExecutor(String name, ThreadPoolTaskExecutor executor) {
        executor.setThreadNamePrefix(name + "-task-");
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(20);
        executor.setQueueCapacity(1000);
        /* 60 seconds */
        executor.setKeepAliveSeconds(60);
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }
}
```

@Async使用指定线程池示例

```java
    @Async(ConfigConstant.TEST_EXECUTOR)
    public void testAsyncWithExecutor() {}
```

### **@Async事务**

- **@Transactional 调用具有 @Async 的子函数，事务不生效**
- **@Async 调用具有 @Transactional 的子函数，事务生效**

先说第一点，如果@Transactional先于@Async切面执行，但由于spring事务管理依赖的是`ThreadLocal`，所以在开启的异步线程里面感知不到事务，说细点就是在Spring开启事务之后，会设置一个连接到当前线程，但这个时候又开启了一个新线程，执行实际的SQL代码时，通过ThreadLocal获取不到连接就会开启新连接，也不会设置`autoCommit`，所以这个函数整体将没有事务。

这样第二点也就很容易理解，@Async先执行，@Transactional使用的ThreadLocal依然是@Async开启的新线程中的ThreadLocal，所以事务生效。

### **@Async异常处理**

异常处理分为无返回值和有返回值两种。

- 无返回值通过实现`AsyncConfigurer`接口来处理异常
- 有返回值通过`Future.get()`返回异常，通过正常的try...catch捕获异常即可

先来看无返回值的情况，定义异常捕获配置类`AsyncExceptionConfig`，配置类里面定义SpringAsyncExceptionHandler 方法实现`AsyncUncaughtExceptionHandler` 接口。

```java
@Configuration
public class AsyncExceptionConfig implements AsyncConfigurer {

    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return new SpringAsyncExceptionHandler();
    }

    class SpringAsyncExceptionHandler implements AsyncUncaughtExceptionHandler {
        @Override
        public void handleUncaughtException(Throwable throwable, Method method, Object... objects) {
            System.out.println("------我是Async无返回方法的异常处理方法---------");
        }
    }
}
```

我们在异步代码中抛出RuntimeException()测试

```java
    @Async
    public void testAsyncWithException() throws InterruptedException {
        Thread.sleep(1000);
        throw new RuntimeException();
    }
```

测试结果

```text
-----start-----
-----end-----
------我是Async无返回方法的异常处理方法---------
```

有返回值通过Future.get()返回异常，TestService调用上面的异常代码

```java
public void testAsyncWithException() throws ExecutionException, InterruptedException {
        System.out.println("start");
        Future<String> future = asyncService.testAsyncWithException();
        while (true) {
            if (future.isDone()) {
                System.out.println("Result from asynchronous process - " + future.get());
                System.out.println("end");
            }
            System.out.println("Continue doing something else. ");
        }
    }
```

测试结果，异常抛出，通过正常的try...catch捕获处理即可。

```text
Continue doing something else. 
Continue doing something else. 
Continue doing something else. 
Continue doing something else. 

java.util.concurrent.ExecutionException: java.lang.RuntimeException

 at java.util.concurrent.FutureTask.report(FutureTask.java:122)
 at java.util.concurrent.FutureTask.get(FutureTask.java:192)
 at com.example.springbootexample.service.AsyncService.TestAsyncService.testAsyncWithException(TestAsyncService.java:54)
 at com.example.springbootexample.service.AsyncService.TestAsyncServiceTest.testAsyncWithException(TestAsyncServiceTest.java:50)
```

#### **总结**

Java异步编程极大的节省了主程序执行时间，不让主程序阻塞在某个长时间运行的任务上，从而优化主程序的执行时间。本文从最常用的Spring @Async来介绍Java异步编程。

异步函数必须是public，被跨类调用才能生效。调用分为无返回值与有返回值两种情况。有返回值通过Future类来接受返回值。通过Future.isDone()来确认异步线程是否结束。

异步线程池可以使用默认线程池，也可以初始化一个自定义线程池。

异步事务方面，@Async 调用具有 @Transactional 的子函数，事务生效。@Transactional 调用具有 @Async 的子函数，事务不生效。

异常处理方面，同样分为无返回值与有返回值两种情况。无返回值可以定义异常捕获配置类AsyncExceptionConfig处理异常。有返回值可以通过Future.get()抛出异常，随后try...catch正常捕获处理即可。







### Java程序占用 CPU 过高怎么排查
线上一台服务器 CPU 使用率100% 了，如果你碰到这样的情况，如何排查并找到问题原因？  
这就是一个套路题，所谓套路题就是有标准的套路解法的，掌握了套路，不仅能解决面试官，还能解决问题。不然真的就掉进套路里了。  
当我们真碰到这个问题的时候应该怎么排查呢？
模拟一个高 CPU 场景  
先用一段程序创建几个线程，将其中一个线程设置成高 CPU 使用率的。

```java
public static void main(String[] args)  {
  for (int i = 0; i < 10; i++) {
    Thread thread = new Thread(() -> {
      System.out.println(Thread.currentThread().getName());
      try {
        Thread.sleep(30 * 60 * 1000);
      }catch (Exception e){
        e.printStackTrace();
      }
    });
    thread.setName("thread-" + i);
    thread.start();
  }

  Thread highCpuThread = new Thread(() -> {
    int i = 0;
    while (true) {
      i++;
    }
  });
  highCpuThread.setName("HighCpu");
  highCpuThread.start();
}

```
运行这段程序后，前面 10 个线程都处于休眠状态，只有最后一个线程会持续的占用 CPU 。

运行这段程序，然后就可以开始一些列的操作来发现问题原因了。

排查步骤

##### **第一步，使用 top 找到占用 CPU 最高的 Java 进程**

在真实环境中，首先要确认是不是 Java 程序造成的，如果有系统监控工具，可能会直接在预警信息里告诉你是有哪个进程造成的，但也有可能不知道，需要我们手动排查。

如果是在面试场景中，这个问题可能不需要确认，毕竟 Java 面试，面试官可能直接就告诉你是 Java 占用的 CPU 过高。

这一步也非常简单，就是一个 top命令而已，基本上所有同学都用过这个命令吧。

![img](https://img-blog.csdnimg.cn/img_convert/8aba5a1048152f8aecc8ced960f6dee4.png)



使用 top命令发现占用 CPU 99.7% 的线程是 Java 进程，进程 PID 为 13731。

##### **第二步，用 top -Hp 命令查看占用 CPU 最高的线程**

上一步用 top命令找到了那个 Java 进程。那一个进程中有那么多线程，不可能所有线程都一直占着 CPU 不放，这一步要做的就是揪出这个罪魁祸首，当然有可能不止一个。

执行top -Hp pid命令，pid 就是前面的 Java 进程，我这个例子中就是 13731 ，完整命令为：

top -Hp 13731，执行之后的效果如下

![img](https://img-blog.csdnimg.cn/img_convert/c67f03a2de66654a5fafeae402d66e28.png)



可以看到占用 CPU 最高的那个线程 PID 为 13756。

然后将 13756转换为 16 进制的，后面会用到，可以用在线进制转换的网站直接转换，转换结果为 0x35bc

##### **第三步，保存线程栈信息**

​	当前 Java 程序的所有线程信息都可以通过 jstack命令查看，我们用jstack命令将第一步找到的 Java 进程的线程栈保存下来。

```python
jstack 13731 > thread_stack.log
```

##### **第四步，在线程栈中查找最贵祸首的线程**

第二步已经找到了这个罪魁祸首的线程 PID，并把它转换成了 16 进制的，第三步保存下来的线程栈中有所有线程的 PID 16 进制信息，我们在线程栈中查找这个16进制的线程 id （0x35bc）。

![img](https://img-blog.csdnimg.cn/img_convert/30f3c16bb3bb16fb5b7278f33294f1d6.png)

怎么样，现在一目了然了，线程名称、线程状态、以及哪行代码消耗了最多的 CPU 都很清楚了。 



# 高并发下如何保证接口的幂等性？



 接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条．．．,这就没有保证接口的幂等性



使用token机制实现接口幂等性,通用性强的实现方法

   token机制实现步骤:

1. 生成全局唯一的token,token放到redis或jvm内存,token会在页面跳转时获取.存放到pageScope中,支付请求提交先获取token

2. 提交后后台校验token，执行提交逻辑,提交成功同时删除token，生成新的token更新redis ,这样当第一次提交后token更新了,页面再次提交携带的token是已删除的token后台验证会失败不让提交  
token特点：  要申请，一次有效性，可以限流  

注意： redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用
#### 下面是其他方案：
`接口幂等性`问题，对于开发人员来说，是一个跟语言无关的公共问题。本文分享了一些解决这类问题非常实用的办法，绝大部分内容我在项目中实践过的，给有需要的小伙伴一个参考。

不知道你有没有遇到过这些场景：  
1. 有时我们在填写某些`form表单`时，保存按钮不小心快速点了两次，表中竟然产生了两条重复的数据，只是id不一样。
2. 我们在项目中为了解决`接口超时`问题，通常会引入了`重试机制`。第一次请求接口超时了，请求方没能及时获取返回结果（此时有可能已经成功了），为了避免返回错误的结果（这种情况不可能直接返回失败吧？），于是会对该请求重试几次，这样也会产生重复的数据。
3. mq消费者在读取消息时，有时候会读取到`重复消息`（至于什么原因这里先不说，有兴趣的小伙伴，可以找我私聊），如果处理不好，也会产生重复的数据。

没错，这些都是幂等性问题。

`接口幂等性`是指用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。

这类问题多发于接口的：

- `insert`操作，这种情况下多次请求，可能会产生重复数据。
- `update`操作，如果只是单纯的更新数据，比如：`update user set status=1 where id=1`，是没有问题的。如果还有计算，比如：`update user set status=status+1 where id=1`，这种情况下多次请求，可能会导致数据错误。



#### 1. 加悲观锁

在支付场景中，用户A的账号余额有150元，想转出100元，正常情况下用户A的余额只剩50元。一般情况下，sql是这样的：

```
update user amount = amount-100 where id=123;
```

如果出现多次相同的请求，可能会导致用户A的余额变成负数。这种情况，用户A来可能要哭了。于此同时，系统开发人员可能也要哭了，因为这是很严重的系统bug。

为了解决这个问题，可以加悲观锁，将用户A的那行数据锁住，在同一时刻只允许一个请求获得锁，更新数据，其他的请求则等待。

通常情况下通过如下sql锁住单行数据：

```
select * from user id=123 for update;
```

具体流程如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrlFMScuviaupFRboxZnOVWkojRVNxya7e2a0BUvnU7cwcAw9jYMLvJXw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 多个请求同时根据id查询用户信息。
2. 判断余额是否不足100，如果余额不足，则直接返回余额不足。
3. 如果余额充足，则通过for update再次查询用户信息，并且尝试获取锁。
4. 只有第一个请求能获取到行锁，其余没有获取锁的请求，则等待下一次获取锁的机会。
5. 第一个请求获取到锁之后，判断余额是否不足100，如果余额足够，则进行update操作。
6. 如果余额不足，说明是重复请求，则直接返回成功。



> 需要特别注意的是：如果使用的是mysql数据库，存储引擎必须用innodb，因为它才支持事务。此外，这里id字段一定要是主键或者唯一索引，不然会锁住整张表。

悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。

此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。

在这里顺便说一下，`防重设计` 和 `幂等设计`，其实是有区别的。防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。

## 2. 加乐观锁

既然悲观锁有性能问题，为了提升接口性能，我们可以使用乐观锁。需要在表中增加一个`timestamp`或者`version`字段，这里以`version`字段为例。

在更新数据之前先查询一下数据：

```
select id,amount,version from user id=123;

```

如果数据存在，假设查到的`version`等于`1`，再使用`id`和`version`字段作为查询条件更新数据：

```
update user set amount=amount+100,version=version+1where id=123 and version=1;
```

更新数据的同时`version+1`，然后判断本次`update`操作的影响行数，如果大于0，则说明本次更新成功，如果等于0，则说明本次更新没有让数据变更。

由于第一次请求`version`等于`1`是可以成功的，操作成功后`version`变成`2`了。这时如果并发的请求过来，再执行相同的sql：

```
 update user set amount=amount+100,version=version+1where id=123 and version=1;
```

该`update`操作不会真正更新数据，最终sql的执行结果影响行数是`0`，因为`version`已经变成`2`了，`where`中的`version=1`肯定无法满足条件。但为了保证接口幂等性，接口可以直接返回成功，因为`version`值已经修改了，那么前面必定已经成功过一次，后面都是重复的请求。

具体流程如下：![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrVUKwejvF2k3OTVPD2JPAiaV5diaMl16ictoclcWwgcvJsMV8mibVOartVg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 先根据id查询用户信息，包含version字段
2. 根据id和version字段值作为where条件的参数，更新用户信息，同时version+1
3. 判断操作影响行数，如果影响1行，则说明是一次请求，可以做其他数据操作。
4. 如果影响0行，说明是重复请求，则直接返回成功。

## 3. 加唯一索引

绝大数情况下，为了防止重复数据的产生，我们都会在表中加唯一索引，这是一个非常简单，并且有效的方案。

```
alter table `order` add UNIQUE KEY `un_code` (`code`);
```

加了唯一索引之后，第一次请求数据可以插入成功。但后面的相同请求，插入数据时会报`Duplicate entry '002' for key 'order.un_code`异常，表示唯一索引有冲突。

虽说抛异常对数据来说没有影响，不会造成错误数据。但是为了保证接口幂等性，我们需要对该异常进行捕获，然后返回成功。

如果是`java`程序需要捕获：`DuplicateKeyException`异常，如果使用了`spring`框架还需要捕获：`MySQLIntegrityConstraintViolationException`异常。

具体流程图如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrs24WBMr0ktqAewryz7neZsASO9B8Qseqb8ict8CyLyia8lzv2YlY5LQQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 用户通过浏览器发起请求，服务端收集数据。
2. 将该数据插入mysql
3. 判断是否执行成功，如果成功，则操作其他数据（可能还有其他的业务逻辑）。
4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。

## 4. 建防重表

有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许。这时候，直接在表中加唯一索引，显然是不太合适的。

针对这种情况，我们可以通过`建防重表`来解决问题。

该表可以只包含两个字段：`id` 和 `唯一索引`，唯一索引可以是多个字段比如：name、code等组合起来的唯一标识，例如：susan_0001。

具体流程图如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrbAGE1PLlnV6ibnZcTeNeyic7bv6jewYbu1Tfo7KO99iciaZcbf5icgSPovA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 用户通过浏览器发起请求，服务端收集数据。
2. 将该数据插入mysql防重表
3. 判断是否执行成功，如果成功，则做mysql其他的数据操作（可能还有其他的业务逻辑）。
4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功。

> 需要特别注意的是：防重表和业务表必须在同一个数据库中，并且操作要在同一个事务中。

## 5. 根据状态机

很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。

假如id=123的订单状态是`已支付`，现在要变成`完成`状态。

```
update `order` set status=3 where id=123 and status=2;
```

第一次请求时，该订单的状态是`已支付`，值是`2`，所以该`update`语句可以正常更新数据，sql执行结果的影响行数是`1`，订单状态变成了`3`。

后面有相同的请求过来，再执行相同的sql时，由于订单状态变成了`3`，再用`status=2`作为条件，无法查询出需要更新的数据，所以最终sql执行结果的影响行数是`0`，即不会真正的更新数据。但为了保证接口幂等性，影响行数是`0`时，接口也可以直接返回成功。

具体流程图如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrWHME47uFVibJDCibIPILsuFib5nq3batoka8m58tN42JdX4HgKSrKiaF9A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 用户通过浏览器发起请求，服务端收集数据。
2. 根据id和当前状态作为条件，更新成下一个状态
3. 判断操作影响行数，如果影响了1行，说明当前操作成功，可以进行其他数据操作。
4. 如果影响了0行，说明是重复请求，直接返回成功。

> 主要特别注意的是，该方案仅限于要更新的`表有状态字段`，并且刚好要更新`状态字段`的这种特殊情况，并非所有场景都适用。

## 6. 加分布式锁

其实前面介绍过的`加唯一索引`或者`加防重表`，本质是使用了`数据库`的`分布式锁`，也属于分布式锁的一种。但由于`数据库分布式锁`的性能不太好，我们可以改用：`redis`或`zookeeper`。

鉴于现在很多公司分布式配置中心改用`apollo`或`nacos`，已经很少用`zookeeper`了，我们以`redis`为例介绍分布式锁。

目前主要有三种方式实现redis的分布式锁：

1. setNx命令
2. set命令
3. Redission框架

每种方案各有利弊，具体实现细节我就不说了，有兴趣的朋友可以加我微信找我私聊。

具体流程图如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrkm3ibIJnLzKpwSdxcSPGh8lfuCCGLO2QVnYp2msIvLgoLuHsyOjHdWQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

具体步骤：

1. 用户通过浏览器发起请求，服务端会收集数据，并且生成订单号code作为唯一业务字段。
2. 使用redis的set命令，将该订单code设置到redis中，同时设置超时时间。
3. 判断是否设置成功，如果设置成功，说明是第一次请求，则进行数据操作。
4. 如果设置失败，说明是重复请求，则直接返回成功。

> 需要特别注意的是：分布式锁一定要设置一个合理的过期时间，如果设置过短，无法有效的防止重复请求。如果设置过长，可能会浪费`redis`的存储空间，需要根据实际业务情况而定。

## 7. 获取token

除了上述方案之外，还有最后一种使用`token`的方案。该方案跟之前的所有方案都有点不一样，需要两次请求才能完成一次业务操作。

1. 第一次请求获取`token`
2. 第二次请求带着这个`token`，完成业务操作。

具体流程图如下：

第一步，先获取token。

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNria8KH0Xlc6tLA05Dgn3FB3Nh7ly35Opicr00B1r0TXmnySicxz9udYTvw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



第二步，做具体业务操作。

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNrZ9rr3cexBOlVKicQgyzt45GyzrTZuJsvyvFJtxiaD0DRQqzJBPDgQarg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



具体步骤：

1. 用户访问页面时，浏览器自动发起获取token请求。
2. 服务端生成token，保存到redis中，然后返回给浏览器。
3. 用户通过浏览器发起请求时，携带该token。
4. 在redis中查询该token是否存在，如果不存在，说明是第一次请求，做则后续的数据操作。
5. 如果存在，说明是重复请求，则直接返回成功。
6. 在redis中token会在过期时间之后，被自动删除。

以上方案是针对幂等设计的。

如果是防重设计，流程图要改改：

![图片](https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEulLjl08cXVC1y0sFSlxNre6icZQjbP3KBARnjq206CBPiaDnUT8EGlgW47MmbXlEMZLY3ApMCkDmw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 需要特别注意的是：token必须是全局唯一的。

