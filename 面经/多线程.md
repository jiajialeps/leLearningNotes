# 什么是线程？

线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位，可以使用多线程对进行运算提速。

比如，如果一个线程完成一个任务要100毫秒，那么用十个线程完成改任务只需10毫秒

# 什么是线程安全和线程不安全？

**通俗的说：加锁的就是是线程安全的，不加锁的就是是线程不安全的**

### 线程安全

**线程安全: 就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染**。

一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将**集合类分成两组，线程安全和非线程安全的**。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。

### 线程不安全

**线程不安全：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据**

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

# 什么是自旋锁？

### 基本概念

**自旋锁是SMP架构中的一种low-level的同步机制**。

当线程A想要获取一把自旋锁而该锁又被其它线程锁持有时，线程A会在一个循环中自旋以检测锁是不是已经可用了。

**自**旋**锁需要注意**：

- **由于自旋时不释放CPU，因而持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直在那里自旋，这就会浪费CPU时间。**
- **持有自旋锁的线程在sleep之前应该释放自旋锁以便其它线程可以获得自旋锁**。（正常情况睡觉拿锁）

### 实现自旋锁

 

一个简单的while就可以满足你的要求。

目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大。

```java
public class MyWaitNotify3{
 
  MonitorObject myMonitorObject = new MonitorObject();
  boolean wasSignalled = false;
 
  public void doWait(){
    synchronized(myMonitorObject){
      while(!wasSignalled){
        try{
          myMonitorObject.wait();
         } catch(InterruptedException e){...}
      }
      //clear signal and continue running.
      wasSignalled = false;
    }
  }
 
  public void doNotify(){
    synchronized(myMonitorObject){
      wasSignalled = true;
      myMonitorObject.notify();
    }
  }
}
```



# 什么是CAS？

**CAS（compare and swap）的缩写，中文翻译成比较并交换**。

CAS 不通过JVM,直接利用java本地方 JNI（Java Native Interface为JAVA本地调用）,直接调用CPU 的汇编指令指令,**提供硬件级别的原子操作**。。

**利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法,实现原子操作。其它原子操作都是利用类似的特性完成的**。

整个java.util.concurrent都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。

**CAS是项乐观锁技术**，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

### CAS应用

CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

```java
// 对象、对象的地址、预期值、修改值
public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);
```



### CAS优点

确保对内存的读-改-写操作都是原子操作执行

### CAS缺点

CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。

**1.开销大**：在并发量比较高的情况下，如果反复尝试更新某个变量，却又一直更新不成功，会给CPU带来较大的压力

**2.ABA问题**：当变量从A修改为B在修改回A时，变量值等于期望值A，但是无法判断是否修改，CAS操作在ABA修改后依然成功。

- **如何避免**：Java提供了AtomicStampedReference和AtomicMarkableReference来解决。AtomicStampedReference通过包装[E,Integer]的元组来对对象标记版本戳stamp，对于ABA问题其解决方案是加上版本号，即在每个变量都加上一个版本号，每次改变时加1，即A —> B —> A，变成1A —> 2B —> 3A。

**3.不能保证代码块的原子性**：CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。

### 总结

1. **使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用**。
2. **synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS**。

## CAS 原子操作在concurrent包的实现

由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：

- A线程写volatile变量，随后B线程读这个volatile变量。
- A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
- A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。

Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：

首先，声明共享变量为volatile；然后，使用CAS的原子条件更新来实现线程之间的同步；

同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。

AQS，非阻塞数据结构和原子变量类（Java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下：

 

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC8zLzE4LzE2MjM4ZTJjNmMyZWFhZWE?x-oss-process=image/format,png)

 

AQS没有锁之类的概念，它有个state变量，是个int类型，在不同场合有着不同含义。

AQS围绕state提供两种基本操作“获取”和“释放”，有条双向队列存放阻塞的等待线程，并提供一系列判断和处理方法，简单说几点：

- state是独占的，还是共享的；
- state被获取后，其他线程需要等待；
- state被释放后，唤醒等待线程；
- 线程等不及时，如何退出等待。

至于线程是否可以获得state，如何释放state，就不是AQS关心的了，要由子类具体实现。

**AQS中还有一个表示状态的字段state，例如ReentrantLocky用它表示线程重入锁的次数，Semaphore用它表示剩余的许可数量，FutureTask用它表示任务的状态。对state变量值的更新都采用CAS操作保证更新操作的原子性**。

AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个类只有一个变量：exclusiveOwnerThread，表示当前占用该锁的线程，并且提供了相应的get，set方法。

ReentrantLock实现原理

[www.cnblogs.com/maypattis/p…](https://link.juejin.im/?target=https%3A%2F%2Fwww.cnblogs.com%2Fmaypattis%2Fp%2F6403682.html)

# 什么是乐观锁和悲观锁？

### 悲观锁

Java在JDK1.5之前都是靠synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。独占锁其实就是一种悲观锁，所以可以说synchronized是悲观锁。

### 乐观锁

乐观锁（ Optimistic Locking）其实是一种思想。相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。

# 什么是AQS？

**AQS**是 **AbstractQueuedSynchronizer**的简称，即 **抽象队列同步器** :

抽象：抽象类，只实现⼀些主要逻辑，有些⽅法由⼦类实现；
队列：使⽤先进先出（FIFO）队列存储数据；
同步：实现了同步的功能。

**AQS是⼀个⽤来构建锁和同步器的框架**，**使⽤AQS能简单且⾼效地构造出应⽤⼴泛的同步器**

事实上concurrent包内许多类都是基于AQS构建，**例如ReentrantLock**，Semaphore，CountDownLatch，ReentrantReadWriteLock，**FutureTask**等。AQS解决了在实现同步容器时设计的大量细节问题。

**AQS使用一个FIFO的双向队列表示排队等待锁的线程，队列头节点称作“哨兵节点”或者“哑节点”，它不与任何线程关联。其他的节点与等待线程关联，每个节点维护一个等待状态waitStatus。**

![img](https://upload-images.jianshu.io/upload_images/9307436-f740e1874ed9a45a.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)



**AQS类本身实现的是一个排队和阻塞的机制**，⽐如具体线程等待队列的维护（如获取资源失败⼊队/唤醒出队等）。它内部使⽤了⼀个**先进先出（FIFO）的双端队列，并使⽤了两个指针head和tail⽤于标识队列的头部和尾部**。

**AQS数据结构如图：** 队列并不是直接储存线程，⽽是储存拥有线程的节点。

![img](https://upload-images.jianshu.io/upload_images/25399192-f84f39d68447e17a.png?imageMogr2/auto-orient/strip|imageView2/2/w/758/format/webp)



**核心数据结构：双向链表 + state(锁状态)**





# volatile原理是什么？

此题考察的是`volatile`这个关键字。可以从`volatile`的作用和`volatile`的原理这三个方面来进行回答。**volatile只能保证变量的可见性、有序性，但是不能保证原子性。**

题目回答
**volatile的作用**
1.保证内存可见性：一个线程对一个volatile变量的修改，对于其它线程来说是可见的。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。
2.禁止指令重排序
**volatile的原理**
**可见性实现**
线程本身并不直接与主内存进行数据的交互，而是通过线程的工作内存来完成相应的操作。这也是导致线程间数据不可见的本质原因。对volatile变量的写操作与普通变量的主要区别有两点：

修改volatile变量时会强制将修改后的值刷新的主内存中。
修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。
**有序性实现**
volatile是通过编译器在生成字节码时，在指令序列中添加“内存屏障”来禁止指令重排序的。多核处理器需使用内存屏障指令来确保一致性。

属性添加了volatile关键字之后，编译之后的属性会被添加ACC_VOLATILE访问标记。
获取和设置静态属性的字节码是putstatic和getstatic，获取成员变量的字节码是putfield和getfield，在这些字节码的代码中，会先判断字段是否被ACC_VOLATILE修饰，即判断字段是否为volatile字段，若是，则会在操作之后，加上内存屏障。
添加内存屏障之后的代码，内存屏障之后的代码会在内存屏障之前的代码执行完之后再执行。
这样就保证了有序性。





# 什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？

原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。

int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。

为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。

到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。  

# 什么是Executors框架？

Executor框架同java.util.concurrent.Executor 接口在Java 5中被引入。

Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。

无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。

利用Executors框架可以非常方便的创建一个线程池，

Java通过Executors提供四种线程池，分别为：

**newCachedThreadPool**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

**newFixedThreadPool** 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。

**newScheduledThreadPool** 创建一个定长线程池，支持定时及周期性任务执行。

**newSingleThreadExecutor** 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。  

##  什么是阻塞队列？

阻塞队列是一个在队列基础上又支持了两个附加操作的队列。

2个附加操作：

支持阻塞的**插入**方法：队列满时，队列会阻塞插入元素的线程，直到队列不满。

支持阻塞的**移除**方法：队列空时，获取元素的线程会等待队列变为非空。

### 阻塞队列的应用场景

阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。简而言之，阻塞队列是生产者用来存放元素、消费者获取元素的容器。

### 几个方法

在阻塞队列不可用的时候，上述2个附加操作提供了四种处理方法

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| :------------ | :-------- | :--------- | :------- | :----------------- |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     | 不可用   | 不可用             |

### JAVA里的阻塞队列

JDK 7 提供了7个阻塞队列，如下

1、**ArrayBlockingQueue** 数组结构组成的有界阻塞队列。

此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。

2、**LinkedBlockingQueue**一个由链表结构组成的有界阻塞队列

此队列按照先出先进的原则对元素进行排序

3、**PriorityBlockingQueue**支持优先级的无界阻塞队列

4、**DelayQueue**支持延时获取元素的无界阻塞队列，即可以指定多久才能从队列中获取当前元素

5、**SynchronousQueue**不存储元素的阻塞队列，每一个put必须等待一个take操作，否则不能继续添加元素。并且他支持公平访问队列。

6、**LinkedTransferQueue**由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，多了tryTransfer和transfer方法

**transfer方法**

如果当前有消费者正在等待接收元素（take或者待时间限制的poll方法），transfer可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的tail节点，并等到该元素被消费者消费了才返回。

**tryTransfer方法**

用来试探生产者传入的元素能否直接传给消费者。，如果没有消费者在等待，则返回false。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。

7、**LinkedBlockingDeque**链表结构的双向阻塞队列，优势在于多线程入队时，减少一半的竞争。

## 如何使用阻塞队列来实现生产者-消费者模型？

通知模式实现：所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。

## 使用BlockingQueue解决生产者消费者问题

**为什么BlockingQueue适合解决生产者消费者问题**

任何有效的生产者-消费者问题解决方案都是通过控制生产者put()方法（生产资源）和消费者take()方法（消费资源）的调用来实现的，一旦你实现了对方法的阻塞控制，那么你将解决该问题。

Java通过BlockingQueue提供了开箱即用的支持来控制这些方法的调用（一个线程创建资源，另一个消费资源）。java.util.concurrent包下的BlockingQueue接口是一个线程安全的可用于存取对象的队列。

**BlockingQueue是一种数据结构，支持一个线程往里存资源，另一个线程从里取资源。这正是解决生产者消费者问题所需要的，那么让我们开始解决该问题吧。**

**生产者**

以下代码用于生产者线程

```java
package io.ymq.example.thread;
 
import java.util.concurrent.BlockingQueue;
 
/**
 * 描述:生产者
 *
 * @author yanpenglei
 * @create 2018-03-14 15:52
 **/
class Producer implements Runnable {
 
    protected BlockingQueue<Object> queue;
 
    Producer(BlockingQueue<Object> theQueue) {
        this.queue = theQueue;
    }
 
    public void run() {
        try {
            while (true) {
                Object justProduced = getResource();
                queue.put(justProduced);
                System.out.println("生产者资源队列大小= " + queue.size());
            }
        } catch (InterruptedException ex) {
            System.out.println("生产者 中断");
        }
    }
 
    Object getResource() {
        try {
            Thread.sleep(100);
        } catch (InterruptedException ex) {
            System.out.println("生产者 读 中断");
        }
        return new Object();
    }
}
```



**消费者**

以下代码用于消费者线程

```java
package io.ymq.example.thread;
 
import java.util.concurrent.BlockingQueue;
 
/**
 * 描述: 消费者
 *
 * @author yanpenglei
 * @create 2018-03-14 15:54
 **/
class Consumer implements Runnable {
    protected BlockingQueue<Object> queue;
 
    Consumer(BlockingQueue<Object> theQueue) {
        this.queue = theQueue;
    }
 
    public void run() {
        try {
            while (true) {
                Object obj = queue.take();
                System.out.println("消费者 资源 队列大小 " + queue.size());
                take(obj);
            }
        } catch (InterruptedException ex) {
            System.out.println("消费者 中断");
        }
    }
 
    void take(Object obj) {
        try {
            Thread.sleep(100); // simulate time passing
        } catch (InterruptedException ex) {
            System.out.println("消费者 读 中断");
        }
        System.out.println("消费对象 " + obj);
    }
}
```



**测试该解决方案是否运行正常**

```java
package io.ymq.example.thread;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
 
/**
 * 描述: 测试
 *
 * @author yanpenglei
 * @create 2018-03-14 15:58
 **/
public class ProducerConsumerExample {
 
    public static void main(String[] args) throws InterruptedException {
 
        int numProducers = 4;
        int numConsumers = 3;
 
        BlockingQueue<Object> myQueue = new LinkedBlockingQueue<Object>(5);
 
        for (int i = 0; i < numProducers; i++) {
            new Thread(new Producer(myQueue)).start();
        }
 
        for (int i = 0; i < numConsumers; i++) {
            new Thread(new Consumer(myQueue)).start();
        }
 
        Thread.sleep(1000);
 
        System.exit(0);
    }
}
```





**运行结果**

```python
生产者资源队列大小= 1
生产者资源队列大小= 1
消费者 资源 队列大小 1
生产者资源队列大小= 1
消费者 资源 队列大小 1
消费者 资源 队列大小 1
生产者资源队列大小= 1
生产者资源队列大小= 3
消费对象 java.lang.Object@1e1aa52b
生产者资源队列大小= 2
生产者资源队列大小= 5
消费对象 java.lang.Object@6e740a76
消费对象 java.lang.Object@697853f6
 
......
 
消费对象 java.lang.Object@41a10cbc
消费对象 java.lang.Object@4963c8d1
消费者 资源 队列大小 5
生产者资源队列大小= 5
生产者资源队列大小= 5
消费者 资源 队列大小 4
消费对象 java.lang.Object@3e49c35d
消费者 资源 队列大小 4
生产者资源队列大小= 5
```



**从输出结果中,我们可以发现队列大小永远不会超过5，消费者线程消费了生产者生产的资源**。

# 什么是Callable和Future?

**Callable 和 Future 是比较有趣的一对组合。当我们需要获取线程的执行结果时，就需要用到它们。Callable用于产生结果，Future用于获取结果**。

**Callable接口使用泛型去定义它的返回类型**。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，必须等待它返回的结果。java.util.concurrent.Future对象解决了这个问题。

**在线程池提交Callable任务后返回了一个Future对象**，使用它可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法，等待Callable结束并获取它的执行结果。

**代码示例**

**Callable 是一个接口，它只包含一个call()方法。Callable是一个返回结果并且可能抛出异常的任务**。

**为了便于理解，我们可以将Callable比作一个Runnable接口，而Callable的call()方法则类似于Runnable的run()方法**。

```java
public class CallableFutureTest {
 
    public static void main(String[] args) throws InterruptedException, ExecutionException {
 
        System.out.println("start main thread ");
 
        ExecutorService exec = Executors.newFixedThreadPool(2);
 
        //新建一个Callable 任务，并将其提交到一个ExecutorService. 将返回一个描述任务情况的Future.
        Callable<String> call = new Callable<String>() {
 
            @Override
            public String call() throws Exception {
                System.out.println("start new thread ");
                Thread.sleep(5000);
                System.out.println("end new thread ");
                return "我是返回的内容";
            }
        };
 
        Future<String> task = exec.submit(call);
        Thread.sleep(1000);
        String retn = task.get();
        //关闭线程池
        exec.shutdown();
        System.out.println(retn + "--end main thread");
    }
}
```





控制台打印

```java
start main thread 
start new thread 
end new thread 
我是返回的内容--end main thread
```





# 什么是FutureTask?

FutureTask可用于异步获取执行结果或取消执行任务的场景。通过传入Runnable或者Callable的任务给FutureTask，直接调用其run方法或者放入线程池执行，之后可以在外部通过FutureTask的get方法异步获取执行结果，因此，FutureTask非常适合用于耗时的计算，主线程可以在完成自己的任务后，再去获取结果。另外，FutureTask还可以确保即使调用了多次run方法，它都只会执行一次Runnable或者Callable任务，或者通过cancel取消FutureTask的执行等。

## 1.执行多任务计算

FutureTask执行多任务计算的使用场景

利用FutureTask和ExecutorService，可以用多线程的方式提交计算任务，主线程继续执行其他任务，当主线程需要子线程的计算结果时，在异步获取子线程的执行结果。

```java
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.*;
 
public class FutureTaskForMultiCompute {
 
    public static void main(String[] args) {
 
        FutureTaskForMultiCompute inst = new FutureTaskForMultiCompute();
        // 创建任务集合
        List<FutureTask<Integer>> taskList = new ArrayList<FutureTask<Integer>>();
        // 创建线程池
        ExecutorService exec = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 10; i++) {
            // 传入Callable对象创建FutureTask对象
            FutureTask<Integer> ft = new FutureTask<Integer>(inst.new ComputeTask(i, "" + i));
            taskList.add(ft);
            // 提交给线程池执行任务，也可以通过exec.invokeAll(taskList)一次性提交所有任务;
            exec.submit(ft);
        }
 
        System.out.println("所有计算任务提交完毕, 主线程接着干其他事情！");
 
        // 开始统计各计算线程计算结果
        Integer totalResult = 0;
        for (FutureTask<Integer> ft : taskList) {
            try {
                //FutureTask的get方法会自动阻塞,直到获取计算结果为止
                totalResult = totalResult + ft.get();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (ExecutionException e) {
                e.printStackTrace();
            }
        }
 
        // 关闭线程池
        exec.shutdown();
        System.out.println("多任务计算后的总结果是:" + totalResult);
 
    }
 
    private class ComputeTask implements Callable<Integer> {
 
        private Integer result = 0;
        private String taskName = "";
 
        public ComputeTask(Integer iniResult, String taskName) {
            result = iniResult;
            this.taskName = taskName;
            System.out.println("生成子线程计算任务: " + taskName);
        }
 
        public String getTaskName() {
            return this.taskName;
        }
 
        @Override
        public Integer call() throws Exception {
            // TODO Auto-generated method stub
 
            for (int i = 0; i < 100; i++) {
                result = +i;
            }
            // 休眠5秒钟，观察主线程行为，预期的结果是主线程会继续执行，到要取得FutureTask的结果是等待直至完成。
            Thread.sleep(5000);
            System.out.println("子线程计算任务: " + taskName + " 执行完成!");
            return result;
        }
    }
}
```



```python
生成子线程计算任务: 0
生成子线程计算任务: 1
生成子线程计算任务: 2
生成子线程计算任务: 3
生成子线程计算任务: 4
生成子线程计算任务: 5
生成子线程计算任务: 6
生成子线程计算任务: 7
生成子线程计算任务: 8
生成子线程计算任务: 9
所有计算任务提交完毕, 主线程接着干其他事情！
子线程计算任务: 0 执行完成!
子线程计算任务: 2 执行完成!
子线程计算任务: 3 执行完成!
子线程计算任务: 4 执行完成!
子线程计算任务: 1 执行完成!
子线程计算任务: 8 执行完成!
子线程计算任务: 7 执行完成!
子线程计算任务: 6 执行完成!
子线程计算任务: 9 执行完成!
子线程计算任务: 5 执行完成!
多任务计算后的总结果是:990
```





## 2.高并发环境下

FutureTask在高并发环境下确保任务只执行一次

在很多高并发的环境下，往往我们只需要某些任务只执行一次。这种使用情景FutureTask的特性恰能胜任。举一个例子，假设有一个带key的连接池，当key存在时，即直接返回key对应的对象；当key不存在时，则创建连接。对于这样的应用场景，通常采用的方法为使用一个Map对象来存储key和连接池对应的对应关系，典型的代码如下面所示： 



```java
  private Map<String, Connection> connectionPool = new HashMap<String, Connection>();
    private ReentrantLock lock = new ReentrantLock();
 
    public Connection getConnection(String key) {
        try {
            lock.lock();
            if (connectionPool.containsKey(key)) {
                return connectionPool.get(key);
            } else {
                //创建 Connection  
                Connection conn = createConnection();
                connectionPool.put(key, conn);
                return conn;
            }
        } finally {
            lock.unlock();
        }
    }
 
    //创建Connection  
    private Connection createConnection() {
        return null;
    }
 
```





在上面的例子中，我们通过加锁确保高并发环境下的线程安全，也确保了connection只创建一次，然而确牺牲了性能。改用ConcurrentHash的情况下，几乎可以避免加锁的操作，性能大大提高，但是在高并发的情况下有可能出现Connection被创建多次的现象。这时最需要解决的问题就是当key不存在时，创建Connection的动作能放在connectionPool之后执行，这正是FutureTask发挥作用的时机，基于ConcurrentHashMap和FutureTask的改造代码如下：

```java
  private ConcurrentHashMap<String, FutureTask<Connection>> connectionPool = new ConcurrentHashMap<String, FutureTask<Connection>>();
 
    public Connection getConnection(String key) throws Exception {
        FutureTask<Connection> connectionTask = connectionPool.get(key);
        if (connectionTask != null) {
            return connectionTask.get();
        } else {
            Callable<Connection> callable = new Callable<Connection>() {
                @Override
                public Connection call() throws Exception {
                    // TODO Auto-generated method stub  
                    return createConnection();
                }
            };
            FutureTask<Connection> newTask = new FutureTask<Connection>(callable);
            connectionTask = connectionPool.putIfAbsent(key, newTask);
            if (connectionTask == null) {
                connectionTask = newTask;
                connectionTask.run();
            }
            return connectionTask.get();
        }
    }
 
    //创建Connection  
    private Connection createConnection() {
        return null;
    }

```

**经过这样的改造，可以避免由于并发带来的多次创建连接及锁的出现。**

# 什么是同步容器和并发容器的实现？

### 一、同步容器

主要代表有Vector和Hashtable，以及Collections.synchronizedXxx等。锁的粒度为当前对象整体。迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。

### 二、并发容器

主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。锁的粒度是分散的、细粒度的，即读和写是使用不同的锁。迭代器具有弱一致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。

**JDK 7 ConcurrentHashMap**

ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表,同时又是一个ReentrantLock（Segment继承了ReentrantLock）。



2.内部结构

ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：

![img](https://imgconvert.csdnimg.cn/aHR0cDovL3AzLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlL2VlZWQ2NTk5OWRkYzRkYTA5YTc0ODk4NmViYjY4ZmE3?x-oss-process=image/format,png)

从上面的结构我们可以了解到，ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。

第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。

3.该结构的优劣势

**坏处**

这一种结构的带来的副作用是Hash的过程要比普通的HashMap要长

好处

写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，在最理想的情况下，ConcurrentHashMap可以最高同时支持Segment数量大小的写操作（刚好这些写操作都非常平均地分布在所有的Segment上）。

所以，通过这一种结构，ConcurrentHashMap的并发能力可以大大的提高。



**JDK 8 ConcurrentHashMap**

JDK8中ConcurrentHashMap参考了JDK8 HashMap的实现，采用了数组+链表+红黑树的实现方式来设计，内部大量采用CAS操作。



JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK1.7中的分段锁思想。

Node：保存key，value及key的hash值的数据结构。其中value和next都用volatile修饰，保证并发的可见性。

Java8 ConcurrentHashMap结构基本上和Java8的HashMap一样，不过保证线程安全性。

 

在JDK8中ConcurrentHashMap的结构，由于引入了红黑树，使得ConcurrentHashMap的实现非常复杂，我们都知道，红黑树是一种性能非常好的二叉查找树，其查找性能为O（logN），但是其实现过程也非常复杂，而且可读性也非常差，DougLea的思维能力确实不是一般人能比的，早期完全采用链表结构时Map的查找时间复杂度为O（N），JDK8中ConcurrentHashMap在链表的长度大于某个阈值的时候会将链表转换成红黑树进一步提高其查找性能。

![并发编程系列：ConcurrentHashMap的实现原理(JDK1.7和JDK1.8)](https://imgconvert.csdnimg.cn/aHR0cDovL3A5OS5wc3RhdHAuY29tL2xhcmdlL3BnYy1pbWFnZS8wMzNhZDQ1MmM2NTM0N2JjYWE3ZjNjNGE2MzAyNzQzMw?x-oss-process=image/format,png)

## 总结

其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树。

1.数据结构：取消了Segment分段锁的数据结构，取而代之的是数组+链表+红黑树的结构。
2.保证线程安全机制：JDK1.7采用segment的分段锁机制实现线程安全，其中segment继承自ReentrantLock。JDK1.8采用CAS+Synchronized保证线程安全。
3.锁的粒度：原来是对需要进行数据操作的Segment加锁，现调整为对每个数组元素加锁（Node）。
4.链表转化为红黑树:定位结点的hash算法简化会带来弊端,Hash冲突加剧,因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。
5.查询时间复杂度：从原来的遍历链表O(n)，变成遍历红黑树O(logN)。 

### 三、阻塞队列

主要代表有LinkedBlockingQueue、ArrayBlockingQueue、PriorityBlockingQueue(Comparable,Comparator)、SynchronousQueue。提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。适用于生产者、消费者模式（线程池和工作队列-Executor），同时也是同步容器

### 四、双端队列

主要代表有ArrayDeque和LinkedBlockingDeque。意义：正如阻塞队列适用于生产者消费者模式，双端队列同样适用与另一种模式，即工作密取。在生产者-消费者设计中，所有消费者共享一个工作队列，而在工作密取中，每个消费者都有各自的双端队列。如果一个消费者完成了自己双端队列中的全部工作，那么他就可以从其他消费者的双端队列末尾秘密的获取工作。具有更好的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。在大多数时候，他们都只是访问自己的双端队列，从而极大的减少了竞争。当工作者线程需要访问另一个队列时，它会从队列的尾部而不是头部获取工作，因此进一步降低了队列上的竞争。适用于：网页爬虫等任务中

### 五、比较及适用场景

如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；如果需要对队列进行排序，选择PriorityBlockingQueue；如果需要一个快速交换的队列，选择SynchronousQueue；如果需要对队列中的元素进行延时操作，则选择DelayQueue。

# 什么是多线程？优缺点？

**什么是多线程？**

多线程：是指从软件或者硬件上实现多个线程的并发技术。

**多线程的好处：**

1. 使用多线程可以把程序中占据时间长的任务放到后台去处理，如图片、视屏的下载
2. 发挥多核处理器的优势，并发执行让系统运行的更快、更流畅，用户体验更好

**多线程的缺点：**

1. 大量的线程降低代码的可读性；
2. 更多的线程需要更多的内存空间
3. 当多个线程对同一个资源出现争夺时候要注意线程安全的问题。

# 什么是多线程的上下文切换？

即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）

**上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行**

**CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态**

- **从任务保存到再加载的过程就是一次上下文切换**

# ThreadLocal的设计理念与作用？

Java中的ThreadLocal类允许我们创建只能被同一个线程读写的变量。因此，如果一段代码含有一个ThreadLocal变量的引用，即使两个线程同时执行这段代码，它们也无法访问到对方的ThreadLocal变量

### ThreadLocal

**如何创建ThreadLocal变量**

以下代码展示了如何创建一个ThreadLocal变量：

```
private ThreadLocal myThreadLocal = new ThreadLocal();
```

通过这段代码实例化了一个ThreadLocal对象。我们只需要实例化对象一次，并且也不需要知道它是被哪个线程实例化。虽然**所有的线程都能访问到这个ThreadLocal实例，但是每个线程却只能访问到自己通过调用ThreadLocal的set()方法设置的值。即使是两个不同的线程在同一个ThreadLocal对象上设置了不同的值，他们仍然无法访问到对方的值**。

**如何访问ThreadLocal变量**

一旦创建了一个ThreadLocal变量，你可以通过如下代码设置某个需要保存的值：

```java
myThreadLocal.set("A thread local value”);
```

可以通过下面方法读取保存在ThreadLocal变量中的值：

```java
String threadLocalValue = (String) myThreadLocal.get();
```

get()方法返回一个Object对象，set()对象需要传入一个Object类型的参数。

**为ThreadLocal指定泛型类型**

```java
public static ThreadLocal<String> myThreadLocal = new ThreadLocal<String>();
```

我们可以创建一个指定泛型类型的ThreadLocal对象，这样我们就不需要每次对使用get()方法返回的值作强制类型转换了。下面展示了指定泛型类型的ThreadLocal例子：

**ThreadLocal的设计理念与作用**

 

### InheritableThreadLocal

```
public static ThreadLocal<Integer> threadLocal = new InheritableThreadLocal<Integer>();
```

InheritableThreadLocal类是ThreadLocal类的子类。ThreadLocal中每个线程拥有它自己的值，与ThreadLocal不同的是，**InheritableThreadLocal允许一个线程以及该线程创建的所有子线程都可以访问它保存的值**。

 

 **ThreadLocal的应用场景**

1、方便同一个线程使用某一对象，避免不必要的参数传递；
2、线程间数据隔离（每个线程在自己线程里使用自己的局部变量，各线程间的ThreadLocal对象互不影响）；

线程隔离的秘密，就在于ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。

3、获取数据库连接、Session、关联ID（比如日志的uniqueID，方便串起多个日志）；
其中spring中的事务管理器就是使用的ThreadLocal：
　　Spring的事务管理器通过AOP切入业务代码，在进入业务代码前，会依据相应的事务管理器提取出相应的事务对象，假如事务管理器是DataSourceTransactionManager，
就会从DataSource中获取一个连接对象，通过一定的包装后将其保存在ThreadLocal中。而且Spring也将DataSource进行了包装，重写了当中的getConnection()方法，或者说
该方法的返回将由Spring来控制，这样Spring就能让线程内多次获取到的Connection对象是同一个。





# ThreadPool（线程池）用法与优势？

### 为什么要用线程池:

1. 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。
2. 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。
3. Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。

### new Thread 缺点

1. 每次new Thread新建对象性能差。
2. 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。
3. 缺乏更多功能，如定时执行、定期执行、线程中断。

### ThreadPool 优点

减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务

可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)

- 减少在创建和销毁线程上所花的时间以及系统资源的开销
- 如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存

**Java提供的四种线程池的好处在于**：

1. 重用存在的线程，减少对象创建、销毁的开销，提高性能。
2. 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。
3. 提供定时执行、定期执行、单线程、并发数控制等功能。

### 比较重要的几个类：

| 类                          | 描述                                                         |
| :-------------------------- | :----------------------------------------------------------- |
| ExecutorService             | 真正的线程池接口。                                           |
| ScheduledExecutorService    | 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。    |
| ThreadPoolExecutor          | ExecutorService的默认实现。                                  |
| ScheduledThreadPoolExecutor | 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 |

要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。

### Executors提供四种线程池

**newCachedThreadPool**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。

**newFixedThreadPool** 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。

**newScheduledThreadPool** 创建一个定长线程池，支持定时及周期性任务执行。

**newSingleThreadExecutor** 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

### 一般都不用Executors提供的线程创建方式

**使用ThreadPoolExecutor创建线程池**

**ThreadPoolExecutor的构造函数**

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

docc
```

### 参数：

1. **corePoolSize**核心线程数大小，当线程数<corePoolSize ，会创建线程执行runnable
2. **maximumPoolSize** 最大线程数， 当线程数 >= corePoolSize的时候，会把runnable放入workQueue中
3. **keepAliveTime** 保持存活时间，当线程数大于corePoolSize的空闲线程能保持的最大时间。
4. **unit** 时间单位
5. **workQueue** 保存任务的阻塞队列
6. **threadFactory** 创建线程的工厂
7. **handler** 拒绝策略

### 任务执行顺序：

1. 当线程数小于corePoolSize时，创建线程执行任务。
2. 当线程数大于等于corePoolSize并且workQueue没有满时，放入workQueue中
3. 线程数大于等于corePoolSize并且当workQueue满时，新任务新建线程运行，线程总数要小于maximumPoolSize
4. 当线程总数等于maximumPoolSize并且workQueue满了的时候执行handler的rejectedExecution。也就是拒绝策略。

**重点来啦：**

我们说设置线程池大小，主要是设置最大线程的数量，即**maxPoolSize**参数的大小。那这个应该设置成多少合适呢？首先我们要分两种情况，即CPU密集型和IO密集型任务。

**CPU密集型任务**：即需要大量计算的任务，因为计算是由CPU来完成的，所以称之为CPU密集型任务。这个时候设置为**CPU核心数+1**就可以了。

**IO密集型任务**：即需要通过网络来交互的任务，通常是指数据库数据交互、文件上传下载、网络数据传输等任务。这个时候需要设置为**CPU核心数\*2。**但是实际情况中可以通过自己的测试来设置合理的数值，通过与大牛的交流得知，这个数值可以设置为**CPU核心数/（1-阻塞系数），**阻塞系数一般在**0.8~0.9**之间。比如8核CPU可以设置为：8/（1-0.9）=80。

注意：在java中获取CPU核心数可以用以下代码：

```java
Runtime.getRuntime().availableProcessors();1.
```

 

### ThreadPoolExecutor默认有四个拒绝策略：

1. `ThreadPoolExecutor.AbortPolicy()` 直接抛出异常RejectedExecutionException
2. `ThreadPoolExecutor.CallerRunsPolicy()` 直接调用run方法并且阻塞执行
3. `ThreadPoolExecutor.DiscardPolicy()` 直接丢弃后来的任务
4. `ThreadPoolExecutor.DiscardOldestPolicy()` 丢弃在队列中队首的任务

当然可以自己继承 RejectedExecutionHandler 来写拒绝策略.

### java 四种线程池的使用

 https://www.cnblogs.com/zincredible/p/10984459.html

## 说一下线程池内部工作原理



随着cpu核数越来越多，不可避免的利用多线程技术以充分利用其计算能力。所以，多线程技术是服务端开发人员必须掌握的技术。

线程的创建和销毁，都涉及到系统调用，比较消耗系统资源，所以就引入了线程池技术，避免频繁的线程创建和销毁。

在Java中有一个Executors工具类，可以为我们创建一个线程池，其本质就是new了一个ThreadPoolExecutor对象。线程池几乎也是面试必考问题。本节结合源代码，说说ThreadExecutor的工作原理

## 一、线程池创建

先看一下ThreadPoolExecutor参数最全的构造方法：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43ia0NogFsxqodmSo9Kyh97WBLxG6rYicCDwEK9QZZ7gvLfncLP1ERZ178A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- **corePoolSize：**线程池的核心线程数，说白了就是，即便是线程池里没有任何任务，也会有corePoolSize个线程在候着等任务。
- **maximumPoolSize：**最大线程数，不管你提交多少任务，线程池里最多工作线程数就是maximumPoolSize。
- **keepAliveTime：**线程的存活时间。当线程池里的线程数大于corePoolSize时，如果等了keepAliveTime时长还没有任务可执行，则线程退出。
- **unit：**这个用来指定keepAliveTime的单位，比如秒:TimeUnit.SECONDS。
- **workQueue：**一个阻塞队列，提交的任务将会被放到这个队列里。
- **threadFactory：**线程工厂，用来创建线程，主要是为了给线程起名字，默认工厂的线程名字：pool-1-thread-3。
- **handler：**拒绝策略，当线程池里线程被耗尽，且队列也满了的时候会调用。

以上就是创建线程池时用到的参数，面试中经常会有面试官问到这个问题。

## 二、线程池执行流程

这里用一个图来说明线程池的执行流程

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43iaGBlLqcpJSeNGOiaFQ3iaSluicWFsKGmSuUmJpUXm3D94V3JYmKyQkGy7g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

任务被提交到线程池，会先判断当前线程数量是否小于corePoolSize，如果小于则创建线程来执行提交的任务，否则将任务放入workQueue队列，如果workQueue满了，则判断当前线程数量是否小于maximumPoolSize,如果小于则创建线程执行任务，否则就会调用handler，以表示线程池拒绝接收任务。

这里以jdk1.8.0_111的源代码为例，看一下具体实现。

### 1、先看一下线程池的executor方法

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43iaOW3ictsa4wwib7YbDduFibfY8MXhQ1iabuPmfDsNFj33J5yQ4dOYaibfBrg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



- 判断当前活跃线程数是否小于corePoolSize,如果小于，则调用addWorker创建线程执行任务
- 如果不小于corePoolSize，则将任务添加到workQueue队列。
- 如果放入workQueue失败，则创建线程执行任务，如果这时创建线程失败(当前线程数不小于maximumPoolSize时)，就会调用reject(内部调用handler)拒绝接受任务。

### 2、再看下addWorker的方法实现

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43iaLVAtnq260ejxXYaeDE5duApRdbwOIO7AZUMoUGvvEgNK6cEdtBKgFg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这块代码是在创建非核心线程时，即core等于false。判断当前线程数是否大于等于maximumPoolSize，如果大于等于则返回false，即上边说到的③中创建线程失败的情况。

addWorker方法的下半部分：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43iahmubTaVhnxqpsicwgZVxy9X37yA3ibZwsl8N8lib5n48EEbibNf7yq3eYw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 创建Worker对象，同时也会实例化一个Thread对象。
- 启动启动这个线程

### 3、再到Worker里看看其实现

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43iaibMQAlmdm48sMOhNIUtWglrAlFkMrr5j7sOJugSKVV094S2iaprJfQEw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

可以看到在创建Worker时会调用threadFactory来创建一个线程。上边的②中启动一个线程就会触发Worker的run方法被线程调用。

### 4、接下来咱们看看runWorker方法的逻辑

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43ia6XZaNuibOtKFicg7v0Jeq62MKSsBpFF4USSTMhX1hQILk95XCnoFyFdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

线程调用runWoker，会while循环调用getTask方法从workerQueue里读取任务，然后执行任务。只要getTask方法不返回null,此线程就不会退出。

### 5、最后在看看getTask方法实现

![图片](https://mmbiz.qpic.cn/mmbiz_png/8KKrHK5ic6XC9fichbCQOicmPHVDYHTm43ia740l9ULUpKG841hmuSicYRibShHVibPAK4Pp4x1yQ2ibHtc7sz6jwodeRw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



- 咱们先不管allowCoreThreadTimeOut，这个变量默认值是false。wc>corePoolSize则是判断当前线程数是否大于corePoolSize。
- 如果当前线程数大于corePoolSize，则会调用workQueue的poll方法获取任务，超时时间是keepAliveTime。如果超过keepAliveTime时长，poll返回了null，上边提到的while循序就会退出，线程也就执行完了。

如果当前线程数小于corePoolSize，则会调用workQueue的take方法阻塞在当前。



# Concurrent包里的其他东西：ArrayBlockingQueue、CountDownLatch等等。

**阻塞队列**

1、**ArrayBlockingQueue** 数组结构组成的有界阻塞队列。

此队列按照先进先出（FIFO）的原则对元素进行排序，但是默认情况下不保证线程公平的访问队列，即如果队列满了，那么被阻塞在外面的线程对队列访问的顺序是不能保证线程公平（即先阻塞，先插入）的。

### CountDownLatch

CountDownLatch 允许一个或多个线程等待其他线程完成操作。

**应用场景**

假如有这样一个需求，当我们需要解析一个Excel里多个sheet的数据时，可以考虑使用多线程，每个线程解析一个sheet里的数据，等到所有的sheet都解析完之后，程序需要提示解析完成。

在这个需求中，要实现主线程等待所有线程完成sheet的解析操作，最简单的做法是使用join。代码如下：

```java
public class JoinCountDownLatchTest {
 
	public static void main(String[] args) throws InterruptedException {
		Thread parser1 = new Thread(new Runnable() {
			@Override
			public void run() {
			}
		});
 
		Thread parser2 = new Thread(new Runnable() {
			@Override
			public void run() {
				System.out.println("parser2 finish");
			}
		});
 
		parser1.start();
		parser2.start();
		parser1.join();
		parser2.join();
		System.out.println("all parser finish");
	}
 
}
```

join用于让当前执行线程等待join线程执行结束。其实现原理是不停检查join线程是否存活，如果join线程存活则让当前线程永远wait，代码片段如下，wait(0)表示永远等待下去。

```java
while (isAlive()) {
 wait(0);
}
```

- 方法isAlive()功能是判断当前线程是否处于活动状态。
- 活动状态就是线程启动且尚未终止，比如正在运行或准备开始运行。

### CountDownLatch用法

```java
public class Test {
     public static void main(String[] args) {   
	 
         final CountDownLatch latch = new CountDownLatch(2);
 
         new Thread(){
             public void run() {
                 try {
                     System.out.println("子线程"+Thread.currentThread().getName()+"正在执行");
                    Thread.sleep(3000);
                    System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕");
                    latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
             };
         }.start();
 
         new Thread(){
             public void run() {
                 try {
                     System.out.println("子线程"+Thread.currentThread().getName()+"正在执行");
                     Thread.sleep(3000);
                     System.out.println("子线程"+Thread.currentThread().getName()+"执行完毕");
                     latch.countDown();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
             };
         }.start();
 
         try {
             System.out.println("等待2个子线程执行完毕...");
            latch.await();
            System.out.println("2个子线程已经执行完毕");
            System.out.println("继续执行主线程");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
     }
 }
```

```
线程Thread-0正在执行
线程Thread-1正在执行
等待2个子线程执行完毕...
线程Thread-0执行完毕
线程Thread-1执行完毕
2个子线程已经执行完毕
继续执行主线程
```





new CountDownLatch(2)的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N。

当我们调用一次CountDownLatch的countDown()方法时，N就会减1，CountDownLatch的await()会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，你只需要把这个CountDownLatch的引用传递到线程里。

 

# synchronized和ReentrantLock的区别？



![image](https://img2020.cnblogs.com/other/268922/202003/268922-20200327191054403-345194463.jpg)

java在编写多线程程序时，为了保证线程安全，需要对数据同步，经常用到两种同步方式就是Synchronized和重入锁ReentrantLock。

### 基础知识

- **可重入锁**。可重入锁是指同一个线程可以多次获取同一把锁。**ReentrantLock和synchronized都是可重入锁**。
- **可中断锁**。可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。synchronized是不可中断锁，而ReentrantLock则提供了中断功能。
- **公平锁与非公平锁**。公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。
- **CAS操作(CompareAndSwap)**。CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

### Synchronized

synchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而synchronized也有一定的局限性

例如：

1. 当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。
2. 如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。

### synchronized (this)原理

涉及两条指令：

（1）**monitorenter**

> 每个对象有一个**监视器锁**（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：
>
> 1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。
>
> 2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1。
>
> 3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。



（2）**monitorexit**

> 执行monitorexit的线程必须是objectref所对应的monitor的所有者。
>
> 指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个
>  monitor 的所有权。



通过这两段描述，我们应该能很清楚的看出synchronized的实现原理，synchronized的语义底层是通过一个monitor的对象来完成。
 其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

### ReentrantLock

ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。

代码示例

```java
private Lock lock = new ReentrantLock();
public void test(){
 lock.lock();
 try{
 doSomeThing();
 }catch (Exception e){
 // ignored
 }finally {
 lock.unlock();
 }
}
```

- **lock**(), 如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁
- **tryLock()**, 如果获取了锁立即返回true，如果别的线程正持有锁，立即返回false；
- **tryLock(long timeout,TimeUnit unit)**，如果获取了锁定立即返回true，如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false；
- **lockInterruptibly**:如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断

**ReentrantLock 一些特性**

1. **等待可中断避免，出现死锁的情况**（如果别的线程正持有锁，会等待参数给定的时间，在等待的过程中，如果获取了锁定，就返回true，如果等待超时，返回false）
2. **公平锁与非公平锁**多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，**ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁**，但公平锁表现的性能不是很好。

公平锁：线程获取锁的顺序和调用lock的顺序一样，FIFO；

非公平锁：线程获取锁的顺序和调用lock的顺序无关，全凭运气。

**Java并发包(java.util.concurrent)中大量使用了CAS操作,涉及到并发的地方都调用了sun.misc.Unsafe类方法进行CAS操作**。

### ReenTrantLock实现的原理：

简单来说，**ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁**。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

### 总结一下

在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

**synchronized**：

在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。

**ReentrantLock**:

ReentrantLock用起来会复杂一些。在基本的加锁和解锁上，两者是一样的，所以无特殊情况下，推荐使用synchronized。ReentrantLock的优势在于它更灵活、更强大，增加了轮训、超时、中断等高级功能。

ReentrantLock默认**使用非公平锁是基于性能考虑**，公平锁为了保证线程规规矩矩地排队，需要增加阻塞和唤醒的时间开销。如果直接插队获取非公平锁，跳过了对队列的处理，速度会更快。

**ReentrantLock实现原理**

https://blog.csdn.net/qq_20597727/article/details/86263237

**分析ReentrantLock的实现原理**(ReentrantLock和同步工具类的实现基础都是AQS)

 https://blog.csdn.net/qq_27264789/article/details/100129347

# Semaphore有什么作用？

1. Semaphore就是一个信号量，**它的作用是限制某段代码块的并发数**。
2. Semaphore有一个构造函数，可以**传入一个int型整数n，表示某段代码最多只有n个线程可以访问**，
3. **如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入**。
4. 由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。

Semaphore类位于java.util.concurrent包下，它提供了2个构造器：

```java
//参数permits表示许可数目，即同时可以允许多少线程进行访问  
public Semaphore(int permits) {  
    sync = new NonfairSync(permits);  
}  
//这个多了一个参数fair表示是否是公平的，即等待时间越久的越先获取许可  
public Semaphore(int permits, boolean fair) {  
    sync = (fair)? new FairSync(permits) : new NonfairSync(permits);  
}  
```

- Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：
- acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。
- release()用来释放许可。注意，在释放许可之前，必须先获获得许可。

```java
Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：
acquire()用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许可。
release()用来释放许可。注意，在释放许可之前，必须先获获得许可。
```

这4个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法：

```java
//尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false  
public boolean tryAcquire() { };  
//尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false  
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { };   
//尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false  
public boolean tryAcquire(int permits) { };   
//尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true  
public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { };  
//得到当前可用的许可数目  
public int availablePermits(); 
```

### 示例

假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：

```java
public class Test {  
    public static void main(String[] args) {  
        int N = 8; //工人数  
        Semaphore semaphore = new Semaphore(5); //机器数目  
        for(int i=0;i<N;i++)  
            new Worker(i,semaphore).start();  
    }      
    static class Worker extends Thread{  
        private int num;  
        private Semaphore semaphore;  
        public Worker(int num,Semaphore semaphore){  
            this.num = num;  
            this.semaphore = semaphore;  
        }          
        @Override  
        public void run() {  
            try {  
                semaphore.acquire();  
                System.out.println("工人"+this.num+"占用一个机器在生产...");  
                Thread.sleep(2000);  
                System.out.println("工人"+this.num+"释放出机器");  
                semaphore.release();              
            } catch (InterruptedException e) {  
                e.printStackTrace();  
            }  
        }  
    }  
} 
```

运行结果：

```python
工人0占用一个机器在生产...  
工人1占用一个机器在生产...  
工人2占用一个机器在生产...  
工人4占用一个机器在生产...  
工人5占用一个机器在生产...  
工人0释放出机器  
工人2释放出机器  
工人3占用一个机器在生产...  
工人7占用一个机器在生产...  
工人4释放出机器  
工人5释放出机器  
工人1释放出机器  
工人6占用一个机器在生产...  
工人3释放出机器  
工人7释放出机器  
工人6释放出机器
```

# Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。

它的优势有：

- 可以使锁更公平
- 可以使线程在等待锁的时候响应中断
- 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
- 可以在不同的范围，以不同的顺序获取和释放锁

# Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？

同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。

**而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性**

# ConcurrentHashMap的并发度是什么？

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势

# ReentrantReadWriteLock读写锁的使用

Lock比传统线程模型中的synchronized方式更加面向对象，与生活中的锁类似，锁本身也应该是一个对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个Lock对象。

**读写锁**：**分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可**。**如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁**；

如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！

**ReentrantReadWriteLock会使用两把锁来解决问题，一个读锁，一个写锁**

**线程进入读锁的前提条件**：

- **没有其他线程的写锁**
- **没有写请求或者有写请求，但调用线程和持有锁的线程是同一个**

**线程进入写锁的前提条件**：

- **没有其他线程的读锁**
- **没有其他线程的写锁**
- 读锁的重入是允许多个申请读操作的线程的，而写锁同时只允许单个线程占有，该线程的写操作可以重入。
- 如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。
- 对于同时占有读锁和写锁的线程，如果完全释放了写锁，那么它就完全转换成了读锁，以后的写操作无法重入，在写锁未完全释放时写操作是可以重入的。
- 公平模式下无论读锁还是写锁的申请都必须按照AQS锁等待队列先进先出的顺序。非公平模式下读操作插队的条件是锁等待队列head节点后的下一个节点是SHARED型节点，写锁则无条件插队。
- 读锁不允许newConditon获取Condition接口，而写锁的newCondition接口实现方法同ReentrantLock。

# 同步编程与异步编程

Java异步编程极大的节省了主程序执行时间，提升了计算资源利用效率，是Java高级工程师的必备技能之一。本文围绕什么是异步，异步解决了什么问题，怎么异步编程来展开。

![img](https://pic1.zhimg.com/80/v2-dfcc9d2fc1750a29820811396d85af0c_720w.jpg)

## **什么是异步**

在解释异步编程之前，我们先来看同步编程的定义。同步编程，即是一种典型的请求-响应模型，当请求调用一个函数或方法后，需等待其响应返回，然后执行后续代码。同步的最大特征便是「**有序**」，当各个过程都执行完毕，最后返回结果。如图

![img](https://pic2.zhimg.com/80/v2-f2784dd82159fd16e2896602a2303ded_720w.jpg)

异步编程则是只发送了调用的指令，调用者无需等待被调用的方法执行完毕，而是继续执行下面的流程。在一个多处理器或多核的环境中，异步调用是真正的并行执行。如图

![img](https://pic3.zhimg.com/80/v2-a1efa71ee1e605b1249c2ab28e254e7a_720w.jpg)

## **异步解决了什么问题**

Java异步编程的目的是充分利用计算机CPU资源，不让主程序阻塞在某个长时间运行的任务上，从而优化主程序的执行时间。这类耗时的任务可以是 IO操作、远程调用以及高密度计算任务。

如果不使用多线程异步编程，我们的系统就会阻塞在耗时的子任务上，会导致极大延长完成主函数任务的时间。Java以及提供了丰富的API，来完成多线程异步编程。从NIO、Future，CompletableFuture、Fork/Join以及parrallelStream。另外google的guava框架提供了ListenableFuture和Spring的@Async来简化异步编程。

## **怎么异步编程**

本文会使用最常用的 Spring @Async说明异步编程。

![img](https://pic3.zhimg.com/80/v2-e6211095a8fa59f3d132f06da035d2d2_720w.jpg)

### **@Async异步调用**

- @Async也是通过AOP（切面）实现的，与@Transactional相同
- 添加@Async注释的方法必须是public。因为AOP的本质是动态代理，动态代理要求方法必须是public
- @Async必须是跨类调用，原因也是同类直接调用无法被动态代理
- 需要添加@EnableAsync注解

@Async异步调用分为两种，一种是无返回值调用，一种是有返回值调用。我们先来看最简单的无返回值调用。

TestAsyncService 调用 AsyncService中的 testAsyncSimple函数

```java
public class TestAsyncService {
    private final AsyncService asyncService;

    public TestAsyncService(AsyncService asyncService) {
        this.asyncService = asyncService;
    }

    public void testAsyncSimple() throws InterruptedException {
        System.out.println("-----start-----");
        asyncService.testAsyncSimple();
        System.out.println("-----end-----");
    }
}

    @Async
    public void testAsyncSimple() throws InterruptedException {
        Thread.sleep(1000);
        System.out.println("async success");
    }
```

单元测试

```java
@SpringBootTest
@RunWith(SpringRunner.class)
@Slf4j
class TestAsyncServiceTest {

    @Autowired
    private TestAsyncService testAsyncService;

    @Test
    void testAsyncSimple() throws InterruptedException {
        testAsyncService.testAsyncSimple();

        Thread.sleep(5000); //阻塞测试用例，等待异步调用结束
    }
}
```

测试结果, end被打印出来说明主程序已经跑完。而 end在 async success之前打印出来，说明 testAsyncSimple函数确实是异步完成。

```text
-----start-----
-----end-----
-----async success-----
```

有返回值调用需要用到`Future`类。简单地说，Future类表示异步计算的未来结果 - 这个结果最终将在处理完成后出现在Future中。换句话说，Future表示**在未来某个时间点获取执行结果**，返回数据类型可以自定义。

我们先定义一个异步函数，它在3秒后将返回一个「hello world」字符串。

```java
    @Async
    public Future<String> testAsyncWithResult() throws InterruptedException {
        Thread.sleep(3000);
        return new AsyncResult<String>("hello world !!!!");
    }
```

在测试函数中定义 `Future` 接受未来某个时间点返回的「hello world」。`while (true)`阻塞线程等待`Future`返回，`future.isDone()`确认异步线程是否结束，如果结束，通过`future.get()`获取返回值。当然，你也有可能会获得一个`exception`异常。

```java
public String testAsyncWithResult() throws ExecutionException, InterruptedException {
        Future<String> future = asyncService.testAsyncWithResult();
        while (true) {
            if (future.isDone()) {
                System.out.println("Result from asynchronous process - " + future.get());
                return future.get();
            }
            System.out.println("Continue doing something else. ");
        }
    }
```

### **@Async线程池**

默认情况下，Spring 使用 `SimpleAsyncTaskExecutor`初始化线程池。每次执行客户提交给它的任务时，它会启动新的线程，并允许开发者控制并发线程的上限（concurrencyLimit），从而起到一定的资源节流作用。默认时，concurrencyLimit取值为-1，即不启用资源节流。

```java
    @Async
    public void testAsyncSimple() {}
```

@Async也支持使用指定线程池，你可以指定线程池的各项参数，如下。

```java
@Configuration
@EnableAsync
public class ThreadPoolConfig {

    @Bean(ConfigConstant.TEST_EXECUTOR)
    @Primary
    public TaskExecutor testTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        initTaskExecutor(ConfigConstant.TEST_EXECUTOR, executor);
        return executor;
    }

    private ThreadPoolTaskExecutor initTaskExecutor(String name, ThreadPoolTaskExecutor executor) {
        executor.setThreadNamePrefix(name + "-task-");
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(20);
        executor.setQueueCapacity(1000);
        /* 60 seconds */
        executor.setKeepAliveSeconds(60);
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.initialize();
        return executor;
    }
}
```

@Async使用指定线程池示例

```java
    @Async(ConfigConstant.TEST_EXECUTOR)
    public void testAsyncWithExecutor() {}
```

### **@Async事务**

- **@Transactional 调用具有 @Async 的子函数，事务不生效**
- **@Async 调用具有 @Transactional 的子函数，事务生效**

先说第一点，如果@Transactional先于@Async切面执行，但由于spring事务管理依赖的是`ThreadLocal`，所以在开启的异步线程里面感知不到事务，说细点就是在Spring开启事务之后，会设置一个连接到当前线程，但这个时候又开启了一个新线程，执行实际的SQL代码时，通过ThreadLocal获取不到连接就会开启新连接，也不会设置`autoCommit`，所以这个函数整体将没有事务。

这样第二点也就很容易理解，@Async先执行，@Transactional使用的ThreadLocal依然是@Async开启的新线程中的ThreadLocal，所以事务生效。

### **@Async异常处理**

异常处理分为无返回值和有返回值两种。

- 无返回值通过实现`AsyncConfigurer`接口来处理异常
- 有返回值通过`Future.get()`返回异常，通过正常的try...catch捕获异常即可

先来看无返回值的情况，定义异常捕获配置类`AsyncExceptionConfig`，配置类里面定义SpringAsyncExceptionHandler 方法实现`AsyncUncaughtExceptionHandler` 接口。

```java
@Configuration
public class AsyncExceptionConfig implements AsyncConfigurer {

    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return new SpringAsyncExceptionHandler();
    }

    class SpringAsyncExceptionHandler implements AsyncUncaughtExceptionHandler {
        @Override
        public void handleUncaughtException(Throwable throwable, Method method, Object... objects) {
            System.out.println("------我是Async无返回方法的异常处理方法---------");
        }
    }
}
```

我们在异步代码中抛出RuntimeException()测试

```java
    @Async
    public void testAsyncWithException() throws InterruptedException {
        Thread.sleep(1000);
        throw new RuntimeException();
    }
```

测试结果

```text
-----start-----
-----end-----
------我是Async无返回方法的异常处理方法---------
```

有返回值通过Future.get()返回异常，TestService调用上面的异常代码

```java
public void testAsyncWithException() throws ExecutionException, InterruptedException {
        System.out.println("start");
        Future<String> future = asyncService.testAsyncWithException();
        while (true) {
            if (future.isDone()) {
                System.out.println("Result from asynchronous process - " + future.get());
                System.out.println("end");
            }
            System.out.println("Continue doing something else. ");
        }
    }
```

测试结果，异常抛出，通过正常的try...catch捕获处理即可。

```text
Continue doing something else. 
Continue doing something else. 
Continue doing something else. 
Continue doing something else. 

java.util.concurrent.ExecutionException: java.lang.RuntimeException

 at java.util.concurrent.FutureTask.report(FutureTask.java:122)
 at java.util.concurrent.FutureTask.get(FutureTask.java:192)
 at com.example.springbootexample.service.AsyncService.TestAsyncService.testAsyncWithException(TestAsyncService.java:54)
 at com.example.springbootexample.service.AsyncService.TestAsyncServiceTest.testAsyncWithException(TestAsyncServiceTest.java:50)
```

## **总结**

Java异步编程极大的节省了主程序执行时间，不让主程序阻塞在某个长时间运行的任务上，从而优化主程序的执行时间。本文从最常用的Spring @Async来介绍Java异步编程。

异步函数必须是public，被跨类调用才能生效。调用分为无返回值与有返回值两种情况。有返回值通过Future类来接受返回值。通过Future.isDone()来确认异步线程是否结束。

异步线程池可以使用默认线程池，也可以初始化一个自定义线程池。

异步事务方面，@Async 调用具有 @Transactional 的子函数，事务生效。@Transactional 调用具有 @Async 的子函数，事务不生效。

异常处理方面，同样分为无返回值与有返回值两种情况。无返回值可以定义异常捕获配置类AsyncExceptionConfig处理异常。有返回值可以通过Future.get()抛出异常，随后try...catch正常捕获处理即可。

# 什么是死锁？

什么是死锁？
所谓死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 因此我们举个例子来描述，如果此时有一个线程A，按照先锁a再获得锁b的的顺序获得锁，而在此同时又有另外一个线程B，按照先锁b再锁a的顺序获得锁。如下图所示：

![img](https://img-blog.csdn.net/20180922173936964?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



产生死锁的原因？
可归结为如下两点：

a. 竞争资源

系统中的资源可以分为两类：
1.可剥夺资源，是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺，CPU和主存均属于可剥夺性资源；
2.另一类资源是不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。

> 产生死锁中的竞争资源之一指的是竞争不可剥夺资源（例如：系统中只有一台打印机，可供进程P1使用，假定P1已占用了打印机，若P2继续要求打印机打印将阻塞）

> 产生死锁中的竞争资源另外一种资源指的是竞争临时资源（临时资源包括硬件中断、信号、消息、缓冲区内的消息等），通常消息通信顺序进行不当，则会产生死锁
> b. 进程间推进顺序非法

> 若P1保持了资源R1,P2保持了资源R2，系统处于不安全状态，因为这两个进程再向前推进，便可能发生死锁

> 例如，当P1运行到P1：Request（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2：Request（R1）时，也将因R1已被P1占用而阻塞，于是发生进程死锁

#### 死锁产生的4个必要条件？

产生死锁的必要条件：

1.互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
2.请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
3.不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
4.环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链。

#### 解决死锁的基本方法

预防死锁：
资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）

只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请保持条件）

可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）

资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）
1、以确定的顺序获得锁

如果必须获取多个锁，那么在设计的时候需要充分考虑不同线程之前获得锁的顺序。按照上面的例子，两个线程获得锁的时序图如下：

![img](https://img-blog.csdn.net/20180922174807514?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

 如果此时把获得锁的时序改成：

![img](https://img-blog.csdn.net/20180922174829303?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

 那么死锁就永远不会发生。 针对两个特定的锁，开发者可以尝试按照锁对象的hashCode值大小的顺序，分别获得两个锁，这样锁总是会以特定的顺序获得锁，那么死锁也不会发生。问题变得更加复杂一些，如果此时有多个线程，都在竞争不同的锁，简单按照锁对象的hashCode进行排序（单纯按照hashCode顺序排序会出现“环路等待”），可能就无法满足要求了，这个时候开发者可以使用银行家算法，所有的锁都按照特定的顺序获取，同样可以防止死锁的发生，该算法在这里就不再赘述了，有兴趣的可以自行了解一下。

2、超时放弃

当使用synchronized关键词提供的内置锁时，只要线程没有获得锁，那么就会永远等待下去，然而Lock接口提供了boolean tryLock(long time, TimeUnit unit) throws InterruptedException方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。 还是按照之前的例子，时序图如下：

![img](https://img-blog.csdn.net/20180922174924551?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hkMTIzNzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



避免死锁:

预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全的状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。

银行家算法：首先需要定义状态和安全状态的概念。系统的状态是当前给进程分配的资源情况。因此，状态包含两个向量Resource（系统中每种资源的总量）和Available（未分配给进程的每种资源的总量）及两个矩阵Claim（表示进程对资源的需求）和Allocation（表示当前分配给进程的资源）。安全状态是指至少有一个资源分配序列不会导致死锁。**当进程请求一组资源时，假设同意该请求，确定其结果是否还处于安全状态。如果是，同意这个请求；如果不是，阻塞该进程直到同意该请求后系统状态仍然是安全的**。
检测死锁
首先为每个进程和每个资源指定一个唯一的号码；
然后建立资源分配表和进程等待表。
解除死锁:
当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：

剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；
撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。
死锁检测
1、Jstack命令

jstack是java虚拟机自带的一种堆栈跟踪工具。jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。 Jstack工具可以用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。

2、JConsole工具

Jconsole是JDK自带的监控工具，在JDK/bin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在Java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗。


# ConcurrentHashMap 既保证了线程安全，又兼顾了性能，它做了哪方面的工作



## **线程不安全的HashMap**

  **因为多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。**

 

## 效率低下的HashTable容器

   HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。

 

## 锁分段技术

  HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，**这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储**，**然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问**。有**些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。这里“按顺序”是很重要的，否则极有可能出现死锁**，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。

![img](https://img-blog.csdnimg.cn/20191007231729225.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tlZXAxMm1vdmluZw==,size_16,color_FFFFFF,t_70)

 

**ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成**。Segment是一种**可重入锁ReentrantLock**，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap**里包含一个Segment数组**，**Segment的结构和HashMap类似，是一种数组和链表结构**， **一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。**

 

# 二、应用场景

  当有一个大数组时需要在多个线程共享时就可以考虑是否把它给分层多个节点了，避免大锁。并可以考虑通过hash算法进行一些模块定位。

其实不止用于线程，当设计数据表的事务时（事务某种意义上也是同步机制的体现），可以把一个表看成一个需要同步的数组，如果操作的表数据太多时就可以考虑事务分离了（这也是为什么要避免大表的出现），比如把数据进行字段拆分，水平分表等.





# 高频面试题：Java程序占用 CPU 过高怎么排查



这个问题可以说是 Java 面试的高频面试题了，有很多面试官都喜欢问这个问题，问题可能是下面这样的。

线上一台服务器 CPU 使用率100% 了，如果你碰到这样的情况，如何排查并找到问题原因？

这就是一个套路题，所谓套路题就是有标准的套路解法的，掌握了套路，不仅能解决面试官，还能解决问题。不然真的就掉进套路里了。

当我们真碰到这个问题的时候应该怎么排查呢？

模拟一个高 CPU 场景
先用一段程序创建几个线程，将其中一个线程设置成高 CPU 使用率的。

```java
public static void main(String[] args)  {
  for (int i = 0; i < 10; i++) {
    Thread thread = new Thread(() -> {
      System.out.println(Thread.currentThread().getName());
      try {
        Thread.sleep(30 * 60 * 1000);
      }catch (Exception e){
        e.printStackTrace();
      }
    });
    thread.setName("thread-" + i);
    thread.start();
  }

  Thread highCpuThread = new Thread(() -> {
    int i = 0;
    while (true) {
      i++;
    }
  });
  highCpuThread.setName("HighCpu");
  highCpuThread.start();
}

```





运行这段程序后，前面 10 个线程都处于休眠状态，只有最后一个线程会持续的占用 CPU 。

运行这段程序，然后就可以开始一些列的操作来发现问题原因了。

排查步骤
**第一步，使用 top 找到占用 CPU 最高的 Java 进程**
在真实环境中，首先要确认是不是 Java 程序造成的，如果有系统监控工具，可能会直接在预警信息里告诉你是有哪个进程造成的，但也有可能不知道，需要我们手动排查。

如果是在面试场景中，这个问题可能不需要确认，毕竟 Java 面试，面试官可能直接就告诉你是 Java 占用的 CPU 过高。

这一步也非常简单，就是一个 top命令而已，基本上所有同学都用过这个命令吧。

![img](https://img-blog.csdnimg.cn/img_convert/8aba5a1048152f8aecc8ced960f6dee4.png)



使用 top命令发现占用 CPU 99.7% 的线程是 Java 进程，进程 PID 为 13731。

**第二步，用 top -Hp 命令查看占用 CPU 最高的线程**
上一步用 top命令找到了那个 Java 进程。那一个进程中有那么多线程，不可能所有线程都一直占着 CPU 不放，这一步要做的就是揪出这个罪魁祸首，当然有可能不止一个。

执行top -Hp pid命令，pid 就是前面的 Java 进程，我这个例子中就是 13731 ，完整命令为：

top -Hp 13731，执行之后的效果如下

![img](https://img-blog.csdnimg.cn/img_convert/c67f03a2de66654a5fafeae402d66e28.png)



可以看到占用 CPU 最高的那个线程 PID 为 13756。

然后将 13756转换为 16 进制的，后面会用到，可以用在线进制转换的网站直接转换，转换结果为 0x35bc

**第三步，保存线程栈信息**
当前 Java 程序的所有线程信息都可以通过 jstack命令查看，我们用jstack命令将第一步找到的 Java 进程的线程栈保存下来。

```python
jstack 13731 > thread_stack.log
```

第四步，在线程栈中查找最贵祸首的线程
第二步已经找到了这个罪魁祸首的线程 PID，并把它转换成了 16 进制的，第三步保存下来的线程栈中有所有线程的 PID 16 进制信息，我们在线程栈中查找这个16进制的线程 id （0x35bc）。

![img](https://img-blog.csdnimg.cn/img_convert/30f3c16bb3bb16fb5b7278f33294f1d6.png)

怎么样，现在一目了然了，线程名称、线程状态、以及哪行代码消耗了最多的 CPU 都很清楚了。
7084